From c8ff310fbe88c87c8e0ac6692b9eea661219f417 Mon Sep 17 00:00:00 2001
From: David Vernet <void@manifault.com>
Date: Thu, 21 Dec 2023 18:59:28 -0600
Subject: [PATCH 060/150] scx: Remove SCX_ENQ_LOCAL flag

Now that we support dispatching directly from ops.select_cpu(), the
SCX_ENQ_LOCAL flag isn't needed. The last place it was used was on the
SCX_ENQ_LAST path to control whether a task would be dispatched locally
if ops.enqueue() wasn't defined. It doesn't really make sense to define
SCX_OPS_ENQ_LAST but not ops.enqueue(), so let's remove SCX_ENQ_LOCAL
and validate that SCX_OPS_ENQ_LAST is never passed if ops.enqueue()
isn't defined.

Signed-off-by: David Vernet <void@manifault.com>
---
 Documentation/scheduler/sched-ext.rst |  5 +----
 kernel/sched/ext.c                    | 28 ++++++++++++++++++++-------
 kernel/sched/ext.h                    | 11 ++---------
 3 files changed, 24 insertions(+), 20 deletions(-)

diff --git a/Documentation/scheduler/sched-ext.rst b/Documentation/scheduler/sched-ext.rst
index fc45366b7..c2b8dca57 100644
--- a/Documentation/scheduler/sched-ext.rst
+++ b/Documentation/scheduler/sched-ext.rst
@@ -86,10 +86,7 @@ optional. The following modified excerpt is from
 
     void BPF_STRUCT_OPS(simple_enqueue, struct task_struct *p, u64 enq_flags)
     {
-            if (enq_flags & SCX_ENQ_LOCAL)
-                    scx_bpf_dispatch(p, SCX_DSQ_LOCAL, SCX_SLICE_DFL, enq_flags);
-            else
-                    scx_bpf_dispatch(p, SCX_DSQ_GLOBAL, SCX_SLICE_DFL, enq_flags);
+            scx_bpf_dispatch(p, SCX_DSQ_GLOBAL, SCX_SLICE_DFL, enq_flags);
     }
 
     void BPF_STRUCT_OPS(simple_exit, struct scx_exit_info *ei)
diff --git a/kernel/sched/ext.c b/kernel/sched/ext.c
index 1882d1ccc..796713aaf 100644
--- a/kernel/sched/ext.c
+++ b/kernel/sched/ext.c
@@ -886,12 +886,8 @@ static void do_enqueue_task(struct rq *rq, struct task_struct *p, u64 enq_flags,
 	    (enq_flags & SCX_ENQ_LAST))
 		goto local;
 
-	if (!SCX_HAS_OP(enqueue)) {
-		if (enq_flags & SCX_ENQ_LOCAL)
-			goto local;
-		else
-			goto global;
-	}
+	if (!SCX_HAS_OP(enqueue))
+		goto global;
 
 	/* DSQ bypass didn't trigger, enqueue on the BPF scheduler */
 	qseq = rq->scx.ops_qseq++ << SCX_OPSS_QSEQ_SHIFT;
@@ -1793,7 +1789,7 @@ static void put_prev_task_scx(struct rq *rq, struct task_struct *p)
 		 * follow-up scheduling event.
 		 */
 		if (list_empty(&rq->scx.local_dsq.fifo))
-			do_enqueue_task(rq, p, SCX_ENQ_LAST | SCX_ENQ_LOCAL, -1);
+			do_enqueue_task(rq, p, SCX_ENQ_LAST, -1);
 		else
 			do_enqueue_task(rq, p, 0, -1);
 	}
@@ -3217,6 +3213,20 @@ static struct kthread_worker *scx_create_rt_helper(const char *name)
 	return helper;
 }
 
+static int validate_ops(const struct sched_ext_ops *ops)
+{
+	/*
+	 * It doesn't make sense to specify the SCX_OPS_ENQ_LAST flag if the
+	 * ops.enqueue() callback isn't implemented.
+	 */
+	if ((ops->flags & SCX_OPS_ENQ_LAST) && !ops->enqueue) {
+		scx_ops_error("SCX_OPS_ENQ_LAST requires ops.enqueue() to be implemented");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
 static int scx_ops_enable(struct sched_ext_ops *ops)
 {
 	struct scx_task_iter sti;
@@ -3280,6 +3290,10 @@ static int scx_ops_enable(struct sched_ext_ops *ops)
 			goto err_disable;
 	}
 
+	ret = validate_ops(ops);
+	if (ret)
+		goto err_disable;
+
 	WARN_ON_ONCE(scx_dsp_buf);
 	scx_dsp_max_batch = ops->dispatch_max_batch ?: SCX_DSP_DFL_MAX_BATCH;
 	scx_dsp_buf = __alloc_percpu(sizeof(scx_dsp_buf[0]) * scx_dsp_max_batch,
diff --git a/kernel/sched/ext.h b/kernel/sched/ext.h
index 27248760f..a8f72efe3 100644
--- a/kernel/sched/ext.h
+++ b/kernel/sched/ext.h
@@ -43,8 +43,8 @@ enum scx_enq_flags {
 	/*
 	 * The task being enqueued is the only task available for the cpu. By
 	 * default, ext core keeps executing such tasks but when
-	 * %SCX_OPS_ENQ_LAST is specified, they're ops.enqueue()'d with
-	 * %SCX_ENQ_LAST and %SCX_ENQ_LOCAL flags set.
+	 * %SCX_OPS_ENQ_LAST is specified, they're ops.enqueue()'d with the
+	 * %SCX_ENQ_LAST flag set.
 	 *
 	 * If the BPF scheduler wants to continue executing the task,
 	 * ops.enqueue() should dispatch the task to %SCX_DSQ_LOCAL immediately.
@@ -54,13 +54,6 @@ enum scx_enq_flags {
 	 */
 	SCX_ENQ_LAST		= 1LLU << 41,
 
-	/*
-	 * A hint indicating that it's advisable to enqueue the task on the
-	 * local dsq of the currently selected CPU. Currently used by
-	 * select_cpu_dfl() and together with %SCX_ENQ_LAST.
-	 */
-	SCX_ENQ_LOCAL		= 1LLU << 42,
-
 	/* high 8 bits are internal */
 	__SCX_ENQ_INTERNAL_MASK	= 0xffLLU << 56,
 
-- 
2.43.0.232.ge79552d197

