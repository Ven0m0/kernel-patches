From 21030c64a3206800f6e5de9e6b719bfe335c260d Mon Sep 17 00:00:00 2001
From: Tejun Heo <tj@kernel.org>
Date: Wed, 6 Mar 2024 11:18:41 -1000
Subject: [PATCH 162/167] scx: Add sched_ext_ops.exit_dump_len and add
 userspace plumbing

Actual feature is not implemented yet.
---
 include/linux/sched/ext.h                |  6 ++++
 kernel/sched/ext.c                       |  3 ++
 tools/sched_ext/include/scx/compat.bpf.h | 40 ++++++++++++++++++++++++
 tools/sched_ext/include/scx/compat.h     | 33 ++++++++++++++++++-
 tools/sched_ext/scx_qmap.bpf.c           | 33 ++++++++++++-------
 tools/sched_ext/scx_qmap.c               | 26 +++++++++++++--
 6 files changed, 125 insertions(+), 16 deletions(-)

diff --git a/include/linux/sched/ext.h b/include/linux/sched/ext.h
index 048a68899..a2de73136 100644
--- a/include/linux/sched/ext.h
+++ b/include/linux/sched/ext.h
@@ -598,6 +598,12 @@ struct sched_ext_ops {
 	 */
 	u32 timeout_ms;
 
+	/**
+	 * exit_dump_len - scx_exit_info.dump buffer length. If 0, the default
+	 * value of 32768 is used.
+	 */
+	u32 exit_dump_len;
+
 	/**
 	 * name - BPF scheduler's name
 	 *
diff --git a/kernel/sched/ext.c b/kernel/sched/ext.c
index 07e6d71a3..9ca195f53 100644
--- a/kernel/sched/ext.c
+++ b/kernel/sched/ext.c
@@ -4086,6 +4086,9 @@ static int bpf_scx_init_member(const struct btf_type *t,
 			return -E2BIG;
 		ops->timeout_ms = *(u32 *)(udata + moff);
 		return 1;
+	case offsetof(struct sched_ext_ops, exit_dump_len):
+		ops->exit_dump_len = *(u32 *)(udata + moff);
+		return 1;
 	}
 
 	return 0;
diff --git a/tools/sched_ext/include/scx/compat.bpf.h b/tools/sched_ext/include/scx/compat.bpf.h
index 01b804848..46a40ae37 100644
--- a/tools/sched_ext/include/scx/compat.bpf.h
+++ b/tools/sched_ext/include/scx/compat.bpf.h
@@ -35,3 +35,43 @@ static inline void __COMPAT_scx_bpf_switch_all(void)
 }
 
 #endif
+
+/*
+ * sched_ext_ops.exit_dump_len is a recent addition. Use the following
+ * definition to support older kernels. See scx_qmap for usage example.
+ */
+struct sched_ext_ops___no_exit_dump_len {
+	s32 (*select_cpu)(struct task_struct *, s32, u64);
+	void (*enqueue)(struct task_struct *, u64);
+	void (*dequeue)(struct task_struct *, u64);
+	void (*dispatch)(s32, struct task_struct *);
+	void (*runnable)(struct task_struct *, u64);
+	void (*running)(struct task_struct *);
+	void (*stopping)(struct task_struct *, bool);
+	void (*quiescent)(struct task_struct *, u64);
+	bool (*yield)(struct task_struct *, struct task_struct *);
+	bool (*core_sched_before)(struct task_struct *, struct task_struct *);
+	void (*set_weight)(struct task_struct *, u32);
+	void (*set_cpumask)(struct task_struct *, const struct cpumask *);
+	void (*update_idle)(s32, bool);
+	void (*cpu_acquire)(s32, struct scx_cpu_acquire_args *);
+	void (*cpu_release)(s32, struct scx_cpu_release_args *);
+	s32 (*init_task)(struct task_struct *, struct scx_init_task_args *);
+	void (*exit_task)(struct task_struct *, struct scx_exit_task_args *);
+	void (*enable)(struct task_struct *);
+	void (*disable)(struct task_struct *);
+	s32 (*cgroup_init)(struct cgroup *, struct scx_cgroup_init_args *);
+	void (*cgroup_exit)(struct cgroup *);
+	s32 (*cgroup_prep_move)(struct task_struct *, struct cgroup *, struct cgroup *);
+	void (*cgroup_move)(struct task_struct *, struct cgroup *, struct cgroup *);
+	void (*cgroup_cancel_move)(struct task_struct *, struct cgroup *, struct cgroup *);
+	void (*cgroup_set_weight)(struct cgroup *, u32);
+	void (*cpu_online)(s32);
+	void (*cpu_offline)(s32);
+	s32 (*init)();
+	void (*exit)(struct scx_exit_info *);
+	u32 dispatch_max_batch;
+	u64 flags;
+	u32 timeout_ms;
+	char name[128];
+};
diff --git a/tools/sched_ext/include/scx/compat.h b/tools/sched_ext/include/scx/compat.h
index 1e6e3cbe9..e962b18bf 100644
--- a/tools/sched_ext/include/scx/compat.h
+++ b/tools/sched_ext/include/scx/compat.h
@@ -69,6 +69,34 @@ static inline bool __COMPAT_read_enum(const char *type, const char *name, u64 *v
 	__val;									\
 })
 
+static inline bool __COMPAT_struct_has_field(const char *type, const char *field)
+{
+	const struct btf_type *t;
+	const struct btf_member *m;
+	const char *n;
+	s32 tid;
+	int i;
+
+	__COMPAT_load_vmlinux_btf();
+	tid = btf__find_by_name_kind(__COMPAT_vmlinux_btf, type, BTF_KIND_STRUCT);
+	if (tid < 0)
+		return false;
+
+	t = btf__type_by_id(__COMPAT_vmlinux_btf, tid);
+	SCX_BUG_ON(!t, "btf__type_by_id(%d)", tid);
+
+	m = btf_members(t);
+
+	for (i = 0; i < BTF_INFO_VLEN(t->info); i++) {
+		n = btf__name_by_offset(__COMPAT_vmlinux_btf, m[i].name_off);
+		SCX_BUG_ON(!n, "btf__name_by_offset()");
+			if (!strcmp(n, field))
+				return true;
+	}
+
+	return false;
+}
+
 /*
  * An ops flag, %SCX_OPS_SWITCH_PARTIAL, replaced scx_bpf_switch_all() which had
  * to be called from ops.init(). To support both before and after, use both
@@ -78,4 +106,7 @@ static inline bool __COMPAT_read_enum(const char *type, const char *name, u64 *v
 #define __COMPAT_SCX_OPS_SWITCH_PARTIAL						\
 	__COMPAT_ENUM_OR_ZERO("scx_ops_flags", "SCX_OPS_SWITCH_PARTIAL")
 
-#endif
+#define __COMPAT_KERNEL_HAS_OPS_EXIT_DUMP_LEN					\
+	__COMPAT_struct_has_field("sched_ext_ops", "exit_dump_len")
+
+#endif	/* __SCX_COMPAT_H */
diff --git a/tools/sched_ext/scx_qmap.bpf.c b/tools/sched_ext/scx_qmap.bpf.c
index a7b0b385c..b621a5f79 100644
--- a/tools/sched_ext/scx_qmap.bpf.c
+++ b/tools/sched_ext/scx_qmap.bpf.c
@@ -383,18 +383,27 @@ void BPF_STRUCT_OPS(qmap_exit, struct scx_exit_info *ei)
 	uei_record(&uei, ei);
 }
 
+#define QMAP_OPS_INIT_COMMON							\
+	.select_cpu		= (void *)qmap_select_cpu,			\
+	.enqueue		= (void *)qmap_enqueue,				\
+	.dequeue		= (void *)qmap_dequeue,				\
+	.dispatch		= (void *)qmap_dispatch,			\
+	.core_sched_before	= (void *)qmap_core_sched_before,		\
+	.cpu_release		= (void *)qmap_cpu_release,			\
+	.init_task		= (void *)qmap_init_task,			\
+	.init			= (void *)qmap_init,				\
+	.exit			= (void *)qmap_exit,				\
+	.flags			= SCX_OPS_ENQ_LAST,				\
+	.timeout_ms		= 5000U,					\
+	.name			= "qmap",
+
 SEC(".struct_ops.link")
 struct sched_ext_ops qmap_ops = {
-	.select_cpu		= (void *)qmap_select_cpu,
-	.enqueue		= (void *)qmap_enqueue,
-	.dequeue		= (void *)qmap_dequeue,
-	.dispatch		= (void *)qmap_dispatch,
-	.core_sched_before	= (void *)qmap_core_sched_before,
-	.cpu_release		= (void *)qmap_cpu_release,
-	.init_task		= (void *)qmap_init_task,
-	.init			= (void *)qmap_init,
-	.exit			= (void *)qmap_exit,
-	.flags			= SCX_OPS_ENQ_LAST,
-	.timeout_ms		= 5000U,
-	.name			= "qmap",
+	QMAP_OPS_INIT_COMMON
+	/* .exit_dump_len will be set while loading */
+};
+
+SEC(".struct_ops.link")
+struct sched_ext_ops___no_exit_dump_len qmap_ops___no_exit_dump_len = {
+	QMAP_OPS_INIT_COMMON
 };
diff --git a/tools/sched_ext/scx_qmap.c b/tools/sched_ext/scx_qmap.c
index 1a71bee00..af586ed73 100644
--- a/tools/sched_ext/scx_qmap.c
+++ b/tools/sched_ext/scx_qmap.c
@@ -19,7 +19,8 @@ const char help_fmt[] =
 "\n"
 "See the top-level comment in .bpf.c for more details.\n"
 "\n"
-"Usage: %s [-s SLICE_US] [-e COUNT] [-t COUNT] [-T COUNT] [-l COUNT] [-d PID] [-p]\n"
+"Usage: %s [-s SLICE_US] [-e COUNT] [-t COUNT] [-T COUNT] [-l COUNT] [-d PID]\n"
+"       [-D LEN] [-p]\n"
 "\n"
 "  -s SLICE_US   Override slice duration\n"
 "  -e COUNT      Trigger scx_bpf_error() after COUNT enqueues\n"
@@ -27,6 +28,7 @@ const char help_fmt[] =
 "  -T COUNT      Stall every COUNT'th kernel thread\n"
 "  -l COUNT      Trigger dispatch infinite looping after COUNT dispatches\n"
 "  -d PID        Disallow a process from switching into SCHED_EXT (-1 for self)\n"
+"  -D LEN        Set scx_exit_info.dump buffer length\n"
 "  -p            Switch only tasks on SCHED_EXT policy intead of all\n"
 "  -h            Display this help and exit\n";
 
@@ -39,6 +41,7 @@ static void sigint_handler(int dummy)
 
 int main(int argc, char **argv)
 {
+	bool has_ops_exit_dump_len = __COMPAT_KERNEL_HAS_OPS_EXIT_DUMP_LEN;
 	struct scx_qmap *skel;
 	struct bpf_link *link;
 	int opt;
@@ -51,7 +54,15 @@ int main(int argc, char **argv)
 	skel = scx_qmap__open();
 	SCX_BUG_ON(!skel, "Failed to open skel");
 
-	while ((opt = getopt(argc, argv, "s:e:t:T:l:d:ph")) != -1) {
+	if (has_ops_exit_dump_len) {
+		bpf_map__set_autocreate(skel->maps.qmap_ops, true);
+		bpf_map__set_autocreate(skel->maps.qmap_ops___no_exit_dump_len, false);
+	} else {
+		bpf_map__set_autocreate(skel->maps.qmap_ops, false);
+		bpf_map__set_autocreate(skel->maps.qmap_ops___no_exit_dump_len, true);
+	}
+
+	while ((opt = getopt(argc, argv, "s:e:t:T:l:d:D:ph")) != -1) {
 		switch (opt) {
 		case 's':
 			skel->rodata->slice_ns = strtoull(optarg, NULL, 0) * 1000;
@@ -73,6 +84,11 @@ int main(int argc, char **argv)
 			if (skel->rodata->disallow_tgid < 0)
 				skel->rodata->disallow_tgid = getpid();
 			break;
+		case 'D':
+			if (!has_ops_exit_dump_len)
+				fprintf(stderr, "WARNING: kernel doesn't support setting exit dump len\n");
+			skel->struct_ops.qmap_ops->exit_dump_len = strtoul(optarg, NULL, 0);
+			break;
 		case 'p':
 			skel->rodata->switch_partial = true;
 			skel->struct_ops.qmap_ops->flags |= __COMPAT_SCX_OPS_SWITCH_PARTIAL;
@@ -85,7 +101,11 @@ int main(int argc, char **argv)
 
 	SCX_BUG_ON(scx_qmap__load(skel), "Failed to load skel");
 
-	link = bpf_map__attach_struct_ops(skel->maps.qmap_ops);
+	if (has_ops_exit_dump_len)
+		link = bpf_map__attach_struct_ops(skel->maps.qmap_ops);
+	else
+		link = bpf_map__attach_struct_ops(skel->maps.qmap_ops___no_exit_dump_len);
+
 	SCX_BUG_ON(!link, "Failed to attach struct_ops");
 
 	while (!exit_req && !uei_exited(&skel->bss->uei)) {
-- 
2.43.0.232.ge79552d197

