From ff51a3b1ae1fca255d5cab5ff1b8112898127d4a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 13 Mar 2023 11:57:23 -0400
Subject: [PATCH 57/59] fixup! mm: enable page allocation tagging

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 include/linux/gfp.h | 9 ++++++---
 mm/page_alloc.c     | 8 ++++----
 2 files changed, 10 insertions(+), 7 deletions(-)

diff --git a/include/linux/gfp.h b/include/linux/gfp.h
index 17019b3e3..445d40b73 100644
--- a/include/linux/gfp.h
+++ b/include/linux/gfp.h
@@ -251,7 +251,7 @@ _alloc_pages_node2(int nid, gfp_t gfp_mask, unsigned int order)
 	VM_BUG_ON(nid < 0 || nid >= MAX_NUMNODES);
 	warn_if_node_offline(nid, gfp_mask);
 
-	return __alloc_pages(gfp_mask, order, nid, NULL);
+	return _alloc_pages2(gfp_mask, order, nid, NULL);
 }
 
 #define  __alloc_pages_node(_nid, _gfp_mask, _order) \
@@ -264,7 +264,7 @@ struct folio *__folio_alloc_node(gfp_t gfp, unsigned int order, int nid)
 	VM_BUG_ON(nid < 0 || nid >= MAX_NUMNODES);
 	warn_if_node_offline(nid, gfp);
 
-	return __folio_alloc(gfp, order, nid, NULL);
+	return _folio_alloc2(gfp, order, nid, NULL);
 }
 
 /*
@@ -331,7 +331,10 @@ void *_alloc_pages_exact(size_t size, gfp_t gfp_mask) __alloc_size(1);
 #define alloc_pages_exact(_size, _gfp_mask) \
 		alloc_hooks(_alloc_pages_exact(_size, _gfp_mask), void *, NULL)
 void free_pages_exact(void *virt, size_t size);
-__meminit void *alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask) __alloc_size(2);
+
+__meminit void *_alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask) __alloc_size(2);
+#define alloc_pages_exact_nid(_nid, _size, _gfp_mask) \
+		alloc_hooks(_alloc_pages_exact_nid(_nid, _size, _gfp_mask), void *, NULL)
 
 #define __get_free_page(gfp_mask) \
 		__get_free_pages((gfp_mask), 0)
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 13a43d7c8..a64c66d5a 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -5592,7 +5592,7 @@ EXPORT_SYMBOL(_alloc_pages2);
 struct folio *_folio_alloc2(gfp_t gfp, unsigned int order, int preferred_nid,
 		nodemask_t *nodemask)
 {
-	struct page *page = __alloc_pages(gfp | __GFP_COMP, order,
+	struct page *page = _alloc_pages2(gfp | __GFP_COMP, order,
 			preferred_nid, nodemask);
 
 	if (page && order > 1)
@@ -5842,7 +5842,7 @@ void *_alloc_pages_exact(size_t size, gfp_t gfp_mask)
 EXPORT_SYMBOL(_alloc_pages_exact);
 
 /**
- * alloc_pages_exact_nid - allocate an exact number of physically-contiguous
+ * _alloc_pages_exact_nid - allocate an exact number of physically-contiguous
  *			   pages on a node.
  * @nid: the preferred node ID where memory should be allocated
  * @size: the number of bytes to allocate
@@ -5853,7 +5853,7 @@ EXPORT_SYMBOL(_alloc_pages_exact);
  *
  * Return: pointer to the allocated area or %NULL in case of error.
  */
-void * __meminit alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask)
+void * __meminit _alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask)
 {
 	unsigned int order = get_order(size);
 	struct page *p;
@@ -5861,7 +5861,7 @@ void * __meminit alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask)
 	if (WARN_ON_ONCE(gfp_mask & (__GFP_COMP | __GFP_HIGHMEM)))
 		gfp_mask &= ~(__GFP_COMP | __GFP_HIGHMEM);
 
-	p = alloc_pages_node(nid, gfp_mask, order);
+	p = _alloc_pages_node(nid, gfp_mask, order);
 	if (!p)
 		return NULL;
 	return make_alloc_exact((unsigned long)page_address(p), order, size);
-- 
2.40.0.71.g950264636c

