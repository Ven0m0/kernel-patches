From 8d939971eba38105e5b35d61d1626c96d2f008c3 Mon Sep 17 00:00:00 2001
From: Piotr Gorski <lucjan.lucjanov@gmail.com>
Date: Tue, 9 May 2023 10:20:39 +0200
Subject: [PATCH] xfs-6.3: merge changes from dev tree

Signed-off-by: Piotr Gorski <lucjan.lucjanov@gmail.com>
---
 fs/xfs/libxfs/xfs_ag.c    |   1 +
 fs/xfs/libxfs/xfs_ag.h    |   5 ++
 fs/xfs/libxfs/xfs_bmap.c  |   1 -
 fs/xfs/xfs_extfree_item.c | 111 +++++++++++++++++++++++++++++++++++++-
 fs/xfs/xfs_icache.c       |  38 ++++++++++---
 fs/xfs/xfs_log_cil.c      |  24 ++++++++-
 6 files changed, 169 insertions(+), 11 deletions(-)

diff --git a/fs/xfs/libxfs/xfs_ag.c b/fs/xfs/libxfs/xfs_ag.c
index 86696a1c6..61ef61e05 100644
--- a/fs/xfs/libxfs/xfs_ag.c
+++ b/fs/xfs/libxfs/xfs_ag.c
@@ -378,6 +378,7 @@ xfs_initialize_perag(
 		pag->pagb_tree = RB_ROOT;
 #endif /* __KERNEL__ */
 
+		atomic_set(&pag->pag_nr_pending_extents, 0);
 		error = xfs_buf_hash_init(pag);
 		if (error)
 			goto out_remove_pag;
diff --git a/fs/xfs/libxfs/xfs_ag.h b/fs/xfs/libxfs/xfs_ag.h
index 5e18536df..5950bc36a 100644
--- a/fs/xfs/libxfs/xfs_ag.h
+++ b/fs/xfs/libxfs/xfs_ag.h
@@ -82,6 +82,11 @@ struct xfs_perag {
 	uint16_t	pag_sick;
 	spinlock_t	pag_state_lock;
 
+	/*
+	 * Number of concurrent extent freeings (not committed to CIL yet)
+	 * on this AG.
+	 */
+	atomic_t	pag_nr_pending_extents;
 	spinlock_t	pagb_lock;	/* lock for pagb_tree */
 	struct rb_root	pagb_tree;	/* ordered tree of busy extents */
 	unsigned int	pagb_gen;	/* generation count for pagb_tree */
diff --git a/fs/xfs/libxfs/xfs_bmap.c b/fs/xfs/libxfs/xfs_bmap.c
index 34de6e689..3ce43068d 100644
--- a/fs/xfs/libxfs/xfs_bmap.c
+++ b/fs/xfs/libxfs/xfs_bmap.c
@@ -3505,7 +3505,6 @@ xfs_bmap_btalloc_at_eof(
 	 * original non-aligned state so the caller can proceed on allocation
 	 * failure as if this function was never called.
 	 */
-	args->fsbno = ap->blkno;
 	args->alignment = 1;
 	return 0;
 }
diff --git a/fs/xfs/xfs_extfree_item.c b/fs/xfs/xfs_extfree_item.c
index 011b50469..1dbf36d9c 100644
--- a/fs/xfs/xfs_extfree_item.c
+++ b/fs/xfs/xfs_extfree_item.c
@@ -336,6 +336,75 @@ xfs_trans_get_efd(
 	return efdp;
 }
 
+/*
+ * Fill the EFD with all extents from the EFI and set the counter.
+ * Note: the EFD should comtain at least one extents already.
+ */
+static void xfs_fill_efd_with_efi(struct xfs_efd_log_item *efdp)
+{
+	struct xfs_efi_log_item	*efip = efdp->efd_efip;
+	uint			i;
+
+	i = efdp->efd_next_extent;
+	ASSERT(i > 0);
+	for (; i < efip->efi_format.efi_nextents; i++) {
+		efdp->efd_format.efd_extents[i] =
+			efip->efi_format.efi_extents[i];
+	}
+	efdp->efd_next_extent = i;
+}
+
+/*
+ * Check if xefi is the first in the efip.
+ * Returns true if so, ad false otherwise
+ */
+static bool xfs_is_first_extent_in_efi(struct xfs_efi_log_item *efip,
+				  struct xfs_extent_free_item *xefi)
+{
+	return efip->efi_format.efi_extents[0].ext_start ==
+					xefi->xefi_startblock;
+}
+
+/*
+ * Check if the xefi needs to be in a new transaction.
+ * efip is the containing EFI of xefi.
+ * Return true if so, false otherwise.
+ */
+static bool xfs_extent_free_need_new_trans(struct xfs_mount *mp,
+				    struct xfs_efi_log_item *efip,
+				    struct xfs_extent_free_item *xefi)
+{
+	bool			ret = true;
+	int			nr_pre;
+	xfs_agnumber_t		agno;
+	struct xfs_perag	*pag;
+
+	agno = XFS_FSB_TO_AGNO(mp, xefi->xefi_startblock);
+	pag = xfs_perag_get(mp, agno);
+	/* The first extent in EFI is always OK to go */
+	if (xfs_is_first_extent_in_efi(efip, xefi)) {
+		atomic_inc(&pag->pag_nr_pending_extents);
+		ret = false;
+		goto out_put;
+	}
+
+	/*
+	 * Now the extent is the 2nd or subsequent in the efip. We need
+	 * new transaction if the AG already has busy extents pending.
+	 */
+	nr_pre = atomic_inc_return(&pag->pag_nr_pending_extents) - 1;
+	/* No prevoius pending extent freeing to this AG */
+	if (nr_pre == 0) {
+		ret = false;
+		goto out_put;
+	}
+
+	atomic_dec(&pag->pag_nr_pending_extents);
+out_put:
+	xfs_perag_put(pag);
+	return ret;
+}
+
 /*
  * Free an extent and log it to the EFD. Note that the transaction is marked
  * dirty regardless of whether the extent free succeeds or fails to support the
@@ -356,6 +425,28 @@ xfs_trans_free_extent(
 	xfs_agblock_t			agbno = XFS_FSB_TO_AGBNO(mp,
 							xefi->xefi_startblock);
 	int				error;
+	struct xfs_efi_log_item		*efip = efdp->efd_efip;
+
+	if (xfs_extent_free_need_new_trans(mp, efip, xefi)) {
+		/*
+		 * This should be the 2nd+ extent, we don't have to mark the
+		 * transaction and efd dirty, those are already done with the
+		 * first extent.
+		 */
+		ASSERT(tp->t_flags & XFS_TRANS_DIRTY);
+		ASSERT(tp->t_flags & XFS_TRANS_HAS_INTENT_DONE);
+		ASSERT(test_bit(XFS_LI_DIRTY, &efdp->efd_item.li_flags));
+
+		xfs_fill_efd_with_efi(efdp);
+
+		/*
+		 * A preious extent in same AG is processed with the current
+		 * transaction. To avoid possible AGFL allocation deadlock,
+		 * we roll the transaction and then restart with this extent
+		 * with new transaction.
+		 */
+		return -EAGAIN;
+	}
 
 	oinfo.oi_owner = xefi->xefi_owner;
 	if (xefi->xefi_flags & XFS_EFI_ATTR_FORK)
@@ -369,6 +460,13 @@ xfs_trans_free_extent(
 	error = __xfs_free_extent(tp, xefi->xefi_startblock,
 			xefi->xefi_blockcount, &oinfo, XFS_AG_RESV_NONE,
 			xefi->xefi_flags & XFS_EFI_SKIP_DISCARD);
+	if (error) {
+		struct xfs_perag	*pag;
+
+		pag = xfs_perag_get(mp, agno);
+		atomic_dec(&pag->pag_nr_pending_extents);
+		xfs_perag_put(pag);
+	}
 	/*
 	 * Mark the transaction dirty, even on error. This ensures the
 	 * transaction is aborted, which:
@@ -476,7 +574,8 @@ xfs_extent_free_finish_item(
 	xefi = container_of(item, struct xfs_extent_free_item, xefi_list);
 
 	error = xfs_trans_free_extent(tp, EFD_ITEM(done), xefi);
-	kmem_cache_free(xfs_extfree_item_cache, xefi);
+	if (error != -EAGAIN)
+		kmem_cache_free(xfs_extfree_item_cache, xefi);
 	return error;
 }
 
@@ -632,7 +731,15 @@ xfs_efi_item_recover(
 		fake.xefi_startblock = extp->ext_start;
 		fake.xefi_blockcount = extp->ext_len;
 
-		error = xfs_trans_free_extent(tp, efdp, &fake);
+		if (error == 0)
+			error = xfs_trans_free_extent(tp, efdp, &fake);
+
+		if (error == -EAGAIN) {
+			ASSERT(i > 0);
+			xfs_free_extent_later(tp, fake.xefi_startblock,
+			fake.xefi_blockcount, &XFS_RMAP_OINFO_ANY_OWNER);
+			continue;
+		}
 		if (error == -EFSCORRUPTED)
 			XFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp,
 					extp, sizeof(*extp));
diff --git a/fs/xfs/xfs_icache.c b/fs/xfs/xfs_icache.c
index c9a7e270a..54d97687f 100644
--- a/fs/xfs/xfs_icache.c
+++ b/fs/xfs/xfs_icache.c
@@ -435,18 +435,23 @@ xfs_iget_check_free_state(
 }
 
 /* Make all pending inactivation work start immediately. */
-static void
+static bool
 xfs_inodegc_queue_all(
 	struct xfs_mount	*mp)
 {
 	struct xfs_inodegc	*gc;
 	int			cpu;
+	bool			ret = false;
 
 	for_each_online_cpu(cpu) {
 		gc = per_cpu_ptr(mp->m_inodegc, cpu);
-		if (!llist_empty(&gc->list))
+		if (!llist_empty(&gc->list)) {
 			mod_delayed_work_on(cpu, mp->m_inodegc_wq, &gc->work, 0);
+			ret = true;
+		}
 	}
+
+	return ret;
 }
 
 /*
@@ -1908,24 +1913,41 @@ xfs_inodegc_flush(
 
 /*
  * Flush all the pending work and then disable the inode inactivation background
- * workers and wait for them to stop.
+ * workers and wait for them to stop.  Caller must hold sb->s_umount to
+ * coordinate changes in the inodegc_enabled state.
  */
 void
 xfs_inodegc_stop(
 	struct xfs_mount	*mp)
 {
+	bool			rerun;
+
 	if (!xfs_clear_inodegc_enabled(mp))
 		return;
 
+	/*
+	 * Drain all pending inodegc work, including inodes that could be
+	 * queued by racing xfs_inodegc_queue or xfs_inodegc_shrinker_scan
+	 * threads that sample the inodegc state just prior to us clearing it.
+	 * The inodegc flag state prevents new threads from queuing more
+	 * inodes, so we queue pending work items and flush the workqueue until
+	 * all inodegc lists are empty.  IOWs, we cannot use drain_workqueue
+	 * here because it does not allow other unserialized mechanisms to
+	 * reschedule inodegc work while this draining is in progress.
+	 */
 	xfs_inodegc_queue_all(mp);
-	drain_workqueue(mp->m_inodegc_wq);
+	do {
+		flush_workqueue(mp->m_inodegc_wq);
+		rerun = xfs_inodegc_queue_all(mp);
+	} while (rerun);
 
 	trace_xfs_inodegc_stop(mp, __return_address);
 }
 
 /*
  * Enable the inode inactivation background workers and schedule deferred inode
- * inactivation work if there is any.
+ * inactivation work if there is any.  Caller must hold sb->s_umount to
+ * coordinate changes in the inodegc_enabled state.
  */
 void
 xfs_inodegc_start(
@@ -2068,7 +2090,8 @@ xfs_inodegc_queue(
 		queue_delay = 0;
 
 	trace_xfs_inodegc_queue(mp, __return_address);
-	mod_delayed_work(mp->m_inodegc_wq, &gc->work, queue_delay);
+	mod_delayed_work_on(current_cpu(), mp->m_inodegc_wq, &gc->work,
+			queue_delay);
 	put_cpu_ptr(gc);
 
 	if (xfs_inodegc_want_flush_work(ip, items, shrinker_hits)) {
@@ -2112,7 +2135,8 @@ xfs_inodegc_cpu_dead(
 
 	if (xfs_is_inodegc_enabled(mp)) {
 		trace_xfs_inodegc_queue(mp, __return_address);
-		mod_delayed_work(mp->m_inodegc_wq, &gc->work, 0);
+		mod_delayed_work_on(current_cpu(), mp->m_inodegc_wq, &gc->work,
+				0);
 	}
 	put_cpu_ptr(gc);
 }
diff --git a/fs/xfs/xfs_log_cil.c b/fs/xfs/xfs_log_cil.c
index eccbfb99e..97eda4487 100644
--- a/fs/xfs/xfs_log_cil.c
+++ b/fs/xfs/xfs_log_cil.c
@@ -16,6 +16,7 @@
 #include "xfs_log.h"
 #include "xfs_log_priv.h"
 #include "xfs_trace.h"
+#include "xfs_ag.h"
 
 struct workqueue_struct *xfs_discard_wq;
 
@@ -643,8 +644,29 @@ xlog_cil_insert_items(
 		cilpcp->space_used += len;
 	}
 	/* attach the transaction to the CIL if it has any busy extents */
-	if (!list_empty(&tp->t_busy))
+	if (!list_empty(&tp->t_busy)) {
+		struct xfs_perag	*last_pag = NULL;
+		xfs_agnumber_t		last_agno = -1;
+		struct xfs_extent_busy	*ebp;
+
+		/*
+		 * Pending extent freeings are committed to CIL, now it's
+		 * to let other extent freeing on same AG go.
+		 */
+		list_for_each_entry(ebp, &tp->t_busy, list) {
+			if (ebp->agno != last_agno) {
+				last_agno = ebp->agno;
+				if (last_pag)
+					xfs_perag_put(last_pag);
+				last_pag = xfs_perag_get(tp->t_mountp, last_agno);
+			}
+			atomic_dec(&last_pag->pag_nr_pending_extents);
+		}
+		if (last_pag)
+			xfs_perag_put(last_pag);
+
 		list_splice_init(&tp->t_busy, &cilpcp->busy_extents);
+	}
 
 	/*
 	 * Now update the order of everything modified in the transaction
-- 
2.40.1.445.gf85cd430b1

