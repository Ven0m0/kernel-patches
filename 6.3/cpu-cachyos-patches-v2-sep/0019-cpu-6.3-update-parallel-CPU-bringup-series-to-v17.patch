From e9992ab9dd0507a6fdfb8e719473b88e1813d8a6 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Wed, 29 Mar 2023 15:43:44 +0200
Subject: [PATCH 19/26] cpu-6.3: update parallel CPU bringup series to v17

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 arch/x86/kernel/smpboot.c  |  5 ++--
 include/linux/cpuhotplug.h | 24 +++++++++++++--
 kernel/cpu.c               | 61 ++++++++++++++++----------------------
 3 files changed, 51 insertions(+), 39 deletions(-)

diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index ef37356ab..6ef040fd2 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -252,7 +252,8 @@ static void notrace start_secondary(void *unused)
 	/*
 	 * Sync point with do_wait_cpu_callin(). The AP doesn't wait here
 	 * but just sets the bit to let the controlling CPU (BSP) know that
-	 * it's got this far.
+	 * it's got this far. The notify_cpu_starting() function is called
+	 * from smp_callin(), which advances the AP state to CPUHP_AP_ONLINE.
 	 */
 	smp_callin();
 
@@ -1568,7 +1569,7 @@ static bool prepare_parallel_bringup(void)
 		smpboot_control = STARTUP_APICID_CPUID_01;
 	}
 
-	cpuhp_setup_state_nocalls(CPUHP_BP_PARALLEL_DYN, "x86/cpu:kick",
+	cpuhp_setup_state_nocalls(CPUHP_BP_PARALLEL_STARTUP, "x86/cpu:kick",
 				  native_cpu_kick, NULL);
 	return true;
 }
diff --git a/include/linux/cpuhotplug.h b/include/linux/cpuhotplug.h
index 3f351c7d6..d2d82c653 100644
--- a/include/linux/cpuhotplug.h
+++ b/include/linux/cpuhotplug.h
@@ -133,8 +133,28 @@ enum cpuhp_state {
 	CPUHP_MIPS_SOC_PREPARE,
 	CPUHP_BP_PREPARE_DYN,
 	CPUHP_BP_PREPARE_DYN_END		= CPUHP_BP_PREPARE_DYN + 20,
-	CPUHP_BP_PARALLEL_DYN,
-	CPUHP_BP_PARALLEL_DYN_END		= CPUHP_BP_PARALLEL_DYN + 4,
+	/*
+	 * This is an optional state if the architecture supports parallel
+	 * startup. It's used to start bringing the CPU online (e.g. send
+	 * the startup IPI) so that the APs can run in parallel through
+	 * the low level startup code instead of waking them one by one in
+	 * CPUHP_BRINGUP_CPU. This avoids waiting for the AP to react and
+	 * shortens the serialized phase of the bringup.
+	 *
+	 * If the architecture registers this state, all APs will be taken
+	 * to it (and thus through all prior states) before any is taken
+	 * to the subsequent CPUHP_BRINGUP_CPU state.
+	 */
+	CPUHP_BP_PARALLEL_STARTUP,
+
+	/*
+	 * This step brings the AP online and takes it to the point where it
+	 * manages its own state from here on. For the time being, the rest
+	 * of the AP bringup is fully serialized despite running on the AP.
+	 * If the architecture doesn't use the CPUHP_BP_PARALLEL_STARTUP
+	 * state, this step also does all the work of bringing the CPU
+	 * online.
+	 */
 	CPUHP_BRINGUP_CPU,
 
 	/*
diff --git a/kernel/cpu.c b/kernel/cpu.c
index cf3c1c6f0..6be5b60db 100644
--- a/kernel/cpu.c
+++ b/kernel/cpu.c
@@ -1504,48 +1504,44 @@ int bringup_hibernate_cpu(unsigned int sleep_cpu)
 
 void bringup_nonboot_cpus(unsigned int setup_max_cpus)
 {
-	unsigned int n = setup_max_cpus - num_online_cpus();
-	unsigned int cpu;
+	unsigned int cpu, n = num_online_cpus();
 
 	/*
-	 * An architecture may have registered parallel pre-bringup states to
-	 * which each CPU may be brought in parallel. For each such state,
-	 * bring N CPUs to it in turn before the final round of bringing them
-	 * online.
+	 * On architectures which have setup the CPUHP_BP_PARALLEL_STARTUP
+	 * state, this invokes all BP prepare states and the parallel
+	 * startup state sends the startup IPI to each of the to be onlined
+	 * APs. This avoids waiting for each AP to respond to the startup
+	 * IPI in CPUHP_BRINGUP_CPU. The APs proceed through the low level
+	 * bringup code and then wait for the control CPU to release them
+	 * one by one for the final onlining procedure in the loop below.
+	 *
+	 * For architectures which do not support parallel bringup all
+	 * states are fully serialized in the loop below.
 	 */
-	if (n > 0) {
-		enum cpuhp_state st = CPUHP_BP_PARALLEL_DYN;
-
-		while (st <= CPUHP_BP_PARALLEL_DYN_END && cpuhp_hp_states[st].name) {
-			int i = n;
-
-			for_each_present_cpu(cpu) {
-				cpu_up(cpu, st);
-				if (!--i)
-					break;
-			}
-			st++;
+	if (!cpuhp_step_empty(true, CPUHP_BP_PARALLEL_STARTUP)) {
+		for_each_present_cpu(cpu) {
+			if (n++ >= setup_max_cpus)
+				break;
+			cpu_up(cpu, CPUHP_BP_PARALLEL_STARTUP);
 		}
 	}
 
+	/* Do the per CPU serialized bringup to ONLINE state */
 	for_each_present_cpu(cpu) {
 		if (num_online_cpus() >= setup_max_cpus)
 			break;
+
 		if (!cpu_online(cpu)) {
+			struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 			int ret = cpu_up(cpu, CPUHP_ONLINE);
 
 			/*
-			 * For the parallel bringup case, roll all the way back
-			 * to CPUHP_OFFLINE on failure; don't leave them in the
-			 * parallel stages. This happens in the nosmt case for
-			 * non-primary threads.
+			 * Due to the above preparation loop a failed online attempt
+			 * might have only rolled back to CPUHP_BP_PARALLEL_STARTUP. Do the
+			 * remaining cleanups. NOOP for the non parallel case.
 			 */
-			if (ret && cpuhp_hp_states[CPUHP_BP_PARALLEL_DYN].name) {
-				struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
-				if (can_rollback_cpu(st))
-					WARN_ON(cpuhp_invoke_callback_range(false, cpu, st,
-									    CPUHP_OFFLINE));
-			}
+			if (ret && can_rollback_cpu(st))
+				WARN_ON(cpuhp_invoke_callback_range(false, cpu, st, CPUHP_OFFLINE));
 		}
 	}
 }
@@ -1918,10 +1914,6 @@ static int cpuhp_reserve_state(enum cpuhp_state state)
 		step = cpuhp_hp_states + CPUHP_BP_PREPARE_DYN;
 		end = CPUHP_BP_PREPARE_DYN_END;
 		break;
-	case CPUHP_BP_PARALLEL_DYN:
-		step = cpuhp_hp_states + CPUHP_BP_PARALLEL_DYN;
-		end = CPUHP_BP_PARALLEL_DYN_END;
-		break;
 	default:
 		return -EINVAL;
 	}
@@ -1946,15 +1938,14 @@ static int cpuhp_store_callbacks(enum cpuhp_state state, const char *name,
 	/*
 	 * If name is NULL, then the state gets removed.
 	 *
-	 * CPUHP_AP_ONLINE_DYN and CPUHP_BP_P*_DYN are handed out on
+	 * CPUHP_AP_ONLINE_DYN and CPUHP_BP_PREPARE_DYN are handed out on
 	 * the first allocation from these dynamic ranges, so the removal
 	 * would trigger a new allocation and clear the wrong (already
 	 * empty) state, leaving the callbacks of the to be cleared state
 	 * dangling, which causes wreckage on the next hotplug operation.
 	 */
 	if (name && (state == CPUHP_AP_ONLINE_DYN ||
-		     state == CPUHP_BP_PREPARE_DYN ||
-		     state == CPUHP_BP_PARALLEL_DYN)) {
+		     state == CPUHP_BP_PREPARE_DYN)) {
 		ret = cpuhp_reserve_state(state);
 		if (ret < 0)
 			return ret;
-- 
2.40.1.445.gf85cd430b1

