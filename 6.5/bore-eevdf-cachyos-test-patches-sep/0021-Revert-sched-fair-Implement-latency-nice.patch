From 697a96ef2d10790542255cd65e1db57843646708 Mon Sep 17 00:00:00 2001
From: Peter Jung <admin@ptr1337.dev>
Date: Wed, 27 Sep 2023 20:28:07 +0200
Subject: [PATCH 21/23] Revert "sched/fair: Implement latency-nice"

This reverts commit 64fa136ec7c9aeae754420ae78db88edc97ebd6a.
---
 kernel/sched/core.c  | 14 ++++----------
 kernel/sched/fair.c  | 22 +++++++---------------
 kernel/sched/sched.h |  2 --
 3 files changed, 11 insertions(+), 27 deletions(-)

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 53eaa9a19..43c134242 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -1305,12 +1305,6 @@ static void set_load_weight(struct task_struct *p, bool update_load)
 	}
 }
 
-static inline void set_latency_prio(struct task_struct *p, int prio)
-{
-	p->latency_prio = prio;
-	set_latency_fair(&p->se, prio - MAX_RT_PRIO);
-}
-
 #ifdef CONFIG_UCLAMP_TASK
 /*
  * Serializes updates of utilization clamp values
@@ -4508,10 +4502,9 @@ static void __sched_fork(unsigned long clone_flags, struct task_struct *p)
 	p->se.nr_migrations		= 0;
 	p->se.vruntime			= 0;
 	p->se.vlag			= 0;
+	p->se.slice			= sysctl_sched_base_slice;
 	INIT_LIST_HEAD(&p->se.group_node);
 
-	set_latency_prio(p, p->latency_prio);
-
 #ifdef CONFIG_FAIR_GROUP_SCHED
 	p->se.cfs_rq			= NULL;
 #endif
@@ -4763,7 +4756,8 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 
 		p->prio = p->normal_prio = p->static_prio;
 		set_load_weight(p, false);
-		set_latency_prio(p, NICE_TO_PRIO(0));
+
+		p->latency_prio = NICE_TO_PRIO(0);
 
 		/*
 		 * We don't need the reset flag anymore after the fork. It has
@@ -7554,7 +7548,7 @@ static void __setscheduler_latency(struct task_struct *p,
 				   const struct sched_attr *attr)
 {
 	if (attr->sched_flags & SCHED_FLAG_LATENCY_NICE)
-		set_latency_prio(p, NICE_TO_PRIO(attr->sched_latency_nice));
+		p->latency_prio = NICE_TO_PRIO(attr->sched_latency_nice);
 }
 
 /*
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 2cbf7f789..41077604d 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -965,21 +965,6 @@ int sched_update_scaling(void)
 }
 #endif
 
-void set_latency_fair(struct sched_entity *se, int prio)
-{
-	u32 weight = sched_prio_to_weight[prio];
-	u64 base = sysctl_sched_base_slice;
-
-	/*
-	 * For EEVDF the virtual time slope is determined by w_i (iow.
-	 * nice) while the request time r_i is determined by
-	 * latency-nice.
-	 *
-	 * Smaller request gets better latency.
-	 */
-	se->slice = div_u64(base << SCHED_FIXEDPOINT_SHIFT, weight);
-}
-
 static void clear_buddies(struct cfs_rq *cfs_rq, struct sched_entity *se);
 
 /*
@@ -991,6 +976,13 @@ static void update_deadline(struct cfs_rq *cfs_rq, struct sched_entity *se)
 	if ((s64)(se->vruntime - se->deadline) < 0)
 		return;
 
+	/*
+	 * For EEVDF the virtual time slope is determined by w_i (iow.
+	 * nice) while the request time r_i is determined by
+	 * sysctl_sched_base_slice.
+	 */
+	se->slice = sysctl_sched_base_slice;
+
 	/*
 	 * EEVDF: vd_i = ve_i + r_i / w_i
 	 */
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index df86407a1..576d371c8 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -2516,8 +2516,6 @@ extern unsigned int sysctl_numa_balancing_scan_size;
 extern unsigned int sysctl_numa_balancing_hot_threshold;
 #endif
 
-extern void set_latency_fair(struct sched_entity *se, int prio);
-
 #ifdef CONFIG_SCHED_HRTICK
 
 /*
-- 
2.42.0

