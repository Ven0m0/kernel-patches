From 18212dd9cca5fadb36ae0c09673191f913991036 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Sun, 5 Jun 2022 15:09:03 +0000
Subject: [PATCH 287/288] sched/alt: Watermark preempt fix

Schedule watermark based preempt is not wokring properly. Typical
scenario is running low priority tasks on all CPUs, then run kernel
compilation with normal prioority, kernel compilation will spread only
on cpu0. Here is the fix.

1) Fix the size of sched_rq_watermark, IDLE_TASK_SCHED_PRIO doesn't need
   a watermark.
2) Remove sched_exec() implementation. It tends scheduling on cpu 0.
3) For BMQ, children task runs at lowest boost priority.
---
 kernel/sched/alt_core.c | 30 ++++++------------------------
 kernel/sched/bmq.h      |  3 +--
 2 files changed, 7 insertions(+), 26 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index d7a5c2fc15e6..a181fd36c3b7 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -147,14 +147,14 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
 #ifdef CONFIG_SCHED_SMT
 static cpumask_t sched_sg_idle_mask ____cacheline_aligned_in_smp;
 #endif
-static cpumask_t sched_rq_watermark[SCHED_BITS] ____cacheline_aligned_in_smp;
+static cpumask_t sched_rq_watermark[SCHED_QUEUE_BITS] ____cacheline_aligned_in_smp;
 
 /* sched_queue related functions */
 static inline void sched_queue_init(struct sched_queue *q)
 {
 	int i;
 
-	bitmap_zero(q->bitmap, SCHED_BITS);
+	bitmap_zero(q->bitmap, SCHED_QUEUE_BITS);
 	for(i = 0; i < SCHED_BITS; i++)
 		INIT_LIST_HEAD(&q->heads[i]);
 }
@@ -186,7 +186,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 	cpu = cpu_of(rq);
 	if (watermark < last_wm) {
 		for (i = last_wm; i > watermark; i--)
-			cpumask_clear_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - i);
+			cpumask_clear_cpu(cpu, sched_rq_watermark + SCHED_QUEUE_BITS - i);
 #ifdef CONFIG_SCHED_SMT
 		if (static_branch_likely(&sched_smt_present) &&
 		    IDLE_TASK_SCHED_PRIO == last_wm)
@@ -197,7 +197,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 	}
 	/* last_wm < watermark */
 	for (i = watermark; i > last_wm; i--)
-		cpumask_set_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - i);
+		cpumask_set_cpu(cpu, sched_rq_watermark + SCHED_QUEUE_BITS - i);
 #ifdef CONFIG_SCHED_SMT
 	if (static_branch_likely(&sched_smt_present) &&
 	    IDLE_TASK_SCHED_PRIO == watermark) {
@@ -1905,7 +1905,7 @@ static inline int select_task_rq(struct task_struct *p)
 #endif
 	    cpumask_and(&tmp, &chk_mask, sched_rq_watermark) ||
 	    cpumask_and(&tmp, &chk_mask,
-			sched_rq_watermark + SCHED_BITS - task_sched_prio(p)))
+			sched_rq_watermark + SCHED_QUEUE_BITS - 1 - task_sched_prio(p)))
 		return best_mask_cpu(task_cpu(p), &tmp);
 
 	return best_mask_cpu(task_cpu(p), &chk_mask);
@@ -3696,24 +3696,6 @@ unsigned int nr_iowait(void)
  */
 void sched_exec(void)
 {
-	struct task_struct *p = current;
-	unsigned long flags;
-	int dest_cpu;
-
-	raw_spin_lock_irqsave(&p->pi_lock, flags);
-	dest_cpu = cpumask_any(p->cpus_ptr);
-	if (dest_cpu == smp_processor_id())
-		goto unlock;
-
-	if (likely(cpu_active(dest_cpu))) {
-		struct migration_arg arg = { p, dest_cpu };
-
-		raw_spin_unlock_irqrestore(&p->pi_lock, flags);
-		stop_one_cpu(task_cpu(p), migration_cpu_stop, &arg);
-		return;
-	}
-unlock:
-	raw_spin_unlock_irqrestore(&p->pi_lock, flags);
 }
 
 #endif
@@ -7246,7 +7228,7 @@ void __init sched_init(void)
 	wait_bit_init();
 
 #ifdef CONFIG_SMP
-	for (i = 0; i < SCHED_BITS; i++)
+	for (i = 0; i < SCHED_QUEUE_BITS; i++)
 		cpumask_copy(sched_rq_watermark + i, cpu_present_mask);
 #endif
 
diff --git a/kernel/sched/bmq.h b/kernel/sched/bmq.h
index bf7ac80ec242..66b77291b9d0 100644
--- a/kernel/sched/bmq.h
+++ b/kernel/sched/bmq.h
@@ -85,8 +85,7 @@ inline int task_running_nice(struct task_struct *p)
 
 static void sched_task_fork(struct task_struct *p, struct rq *rq)
 {
-	p->boost_prio = (p->boost_prio < 0) ?
-		p->boost_prio + MAX_PRIORITY_ADJ : MAX_PRIORITY_ADJ;
+	p->boost_prio = MAX_PRIORITY_ADJ;
 }
 
 static inline void do_sched_yield_type_1(struct task_struct *p, struct rq *rq)
-- 
2.37.0.rc0.15.g3b9a5a33c2

