From 4089ffcccf9f14864b721b263fd1b2c6a08f7963 Mon Sep 17 00:00:00 2001
From: Tejun Heo <tj@kernel.org>
Date: Tue, 28 Nov 2023 20:45:42 -1000
Subject: [PATCH 43/50] scx_{rusty|layered}: Make naming and build consistent
 between the two rust userland schedulers

- NAME_sys and NAME was used to refer to rust wrapper of the
  bindgen-generated header file and the bpf skeleton, respectively. The NAME
  part is self-referential and thus doesn't really signify anything and _sys
  suffix is arbitrary too. Let's use bpf_intf and bpf_skel instead.

- The env vars that are used during build are a bit unusual and the
  SCX_RUST_CLANG name is a bit confusing as it doesn't indicate it's for
  compiling BPF. Let's use the names BPF_CLANG and BPF_CFLAGS instead.

- build.rs is now identical between the two schedulers.
---
 tools/sched_ext/Makefile                      |  4 +-
 tools/sched_ext/scx_layered/build.rs          | 23 ++---
 .../scx_layered/src/bpf/{layered.h => intf.h} |  6 +-
 .../src/bpf/{layered.bpf.c => main.bpf.c}     |  2 +-
 .../src/bpf_intf.rs}                          |  2 +-
 .../rusty.rs => scx_layered/src/bpf_skel.rs}  |  2 +-
 tools/sched_ext/scx_layered/src/main.rs       | 84 +++++++++----------
 tools/sched_ext/scx_rusty/Cargo.toml          |  1 +
 tools/sched_ext/scx_rusty/build.rs            | 32 ++++---
 .../scx_rusty/src/bpf/{rusty.h => intf.h}     |  6 +-
 .../src/bpf/{rusty.bpf.c => main.bpf.c}       |  2 +-
 .../src/bpf_intf.rs}                          |  2 +-
 .../layered.rs => scx_rusty/src/bpf_skel.rs}  |  2 +-
 tools/sched_ext/scx_rusty/src/main.rs         | 77 +++++++++--------
 14 files changed, 126 insertions(+), 119 deletions(-)
 rename tools/sched_ext/scx_layered/src/bpf/{layered.h => intf.h} (96%)
 rename tools/sched_ext/scx_layered/src/bpf/{layered.bpf.c => main.bpf.c} (99%)
 rename tools/sched_ext/{scx_rusty/src/rusty_sys.rs => scx_layered/src/bpf_intf.rs} (84%)
 rename tools/sched_ext/{scx_rusty/src/rusty.rs => scx_layered/src/bpf_skel.rs} (89%)
 rename tools/sched_ext/scx_rusty/src/bpf/{rusty.h => intf.h} (97%)
 rename tools/sched_ext/scx_rusty/src/bpf/{rusty.bpf.c => main.bpf.c} (99%)
 rename tools/sched_ext/{scx_layered/src/layered_sys.rs => scx_rusty/src/bpf_intf.rs} (83%)
 rename tools/sched_ext/{scx_layered/src/layered.rs => scx_rusty/src/bpf_skel.rs} (89%)

diff --git a/tools/sched_ext/Makefile b/tools/sched_ext/Makefile
index 2380cbe58..43926befe 100644
--- a/tools/sched_ext/Makefile
+++ b/tools/sched_ext/Makefile
@@ -216,8 +216,8 @@ $(addsuffix _deps,$(rust-sched-targets)):
 
 $(rust-sched-targets): %: $(INCLUDE_DIR)/vmlinux.h $(SCX_COMMON_DEPS)
 	$(eval export RUSTFLAGS = -C link-args=-lzstd -C link-args=-lz -C link-args=-lelf -L $(BPFOBJ_DIR))
-	$(eval export SCX_RUST_CLANG = $(CLANG))
-	$(eval export SCX_RUST_BPF_CFLAGS= $(BPF_CFLAGS))
+	$(eval export BPF_CLANG = $(CLANG))
+	$(eval export BPF_CFLAGS = $(BPF_CFLAGS))
 	$(eval sched=$(notdir $@))
 	$(Q)cargo build --manifest-path=$(sched)/Cargo.toml $(CARGOFLAGS)
 	$(Q)cp $(OUTPUT_DIR)/release/$(sched) $(BINDIR)/$@
diff --git a/tools/sched_ext/scx_layered/build.rs b/tools/sched_ext/scx_layered/build.rs
index 0f113716d..4f240bfbc 100644
--- a/tools/sched_ext/scx_layered/build.rs
+++ b/tools/sched_ext/scx_layered/build.rs
@@ -10,9 +10,10 @@
 use glob::glob;
 use libbpf_cargo::SkeletonBuilder;
 
-const HEADER_PATH: &str = "src/bpf/layered.h";
+const HEADER_PATH: &str = "src/bpf/intf.h";
+const SKEL_NAME: &str = "bpf";
 
-fn bindgen_layered() {
+fn bindgen_bpf_intf() {
     // Tell cargo to invalidate the built crate whenever the wrapper changes
     println!("cargo:rerun-if-changed={}", HEADER_PATH);
 
@@ -34,17 +35,17 @@ fn bindgen_layered() {
     // Write the bindings to the $OUT_DIR/bindings.rs file.
     let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
     bindings
-        .write_to_file(out_path.join("layered_sys.rs"))
+        .write_to_file(out_path.join("bpf_intf.rs"))
         .expect("Couldn't write bindings!");
 }
 
-fn gen_bpf_sched(name: &str) {
-    let bpf_cflags = env::var("SCX_RUST_BPF_CFLAGS").unwrap();
-    let clang = env::var("SCX_RUST_CLANG").unwrap();
-    let src = format!("./src/bpf/{}.bpf.c", name);
+fn gen_bpf_skel() {
+    let bpf_cflags = env::var("BPF_CFLAGS").unwrap();
+    let clang = env::var("BPF_CLANG").unwrap();
+    let src = format!("./src/bpf/main.bpf.c");
     let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
-    let skel_path = out_path.join(format!("{}.bpf.skel.rs", name));
-    let obj = out_path.join(format!("{}.bpf.o", name));
+    let skel_path = out_path.join(format!("{}_skel.rs", SKEL_NAME));
+    let obj = out_path.join(format!("{}.bpf.o", SKEL_NAME));
     SkeletonBuilder::new()
         .source(&src)
         .obj(&obj)
@@ -60,6 +61,6 @@ fn gen_bpf_sched(name: &str) {
 }
 
 fn main() {
-    bindgen_layered();
-    gen_bpf_sched("layered");
+    bindgen_bpf_intf();
+    gen_bpf_skel();
 }
diff --git a/tools/sched_ext/scx_layered/src/bpf/layered.h b/tools/sched_ext/scx_layered/src/bpf/intf.h
similarity index 96%
rename from tools/sched_ext/scx_layered/src/bpf/layered.h
rename to tools/sched_ext/scx_layered/src/bpf/intf.h
index bedfa0650..9b9e6cb90 100644
--- a/tools/sched_ext/scx_layered/src/bpf/layered.h
+++ b/tools/sched_ext/scx_layered/src/bpf/intf.h
@@ -2,8 +2,8 @@
 
 // This software may be used and distributed according to the terms of the
 // GNU General Public License version 2.
-#ifndef __LAYERED_H
-#define __LAYERED_H
+#ifndef __INTF_H
+#define __INTF_H
 
 #include <stdbool.h>
 #ifndef __kptr
@@ -97,4 +97,4 @@ struct layer {
 	unsigned int		nr_cpus;	// managed from BPF side
 };
 
-#endif /* __LAYERED_H */
+#endif /* __INTF_H */
diff --git a/tools/sched_ext/scx_layered/src/bpf/layered.bpf.c b/tools/sched_ext/scx_layered/src/bpf/main.bpf.c
similarity index 99%
rename from tools/sched_ext/scx_layered/src/bpf/layered.bpf.c
rename to tools/sched_ext/scx_layered/src/bpf/main.bpf.c
index b0a27f3c7..4b3330785 100644
--- a/tools/sched_ext/scx_layered/src/bpf/layered.bpf.c
+++ b/tools/sched_ext/scx_layered/src/bpf/main.bpf.c
@@ -1,6 +1,6 @@
 /* Copyright (c) Meta Platforms, Inc. and affiliates. */
 #include "../../../scx_common.bpf.h"
-#include "layered.h"
+#include "intf.h"
 
 #include <errno.h>
 #include <stdbool.h>
diff --git a/tools/sched_ext/scx_rusty/src/rusty_sys.rs b/tools/sched_ext/scx_layered/src/bpf_intf.rs
similarity index 84%
rename from tools/sched_ext/scx_rusty/src/rusty_sys.rs
rename to tools/sched_ext/scx_layered/src/bpf_intf.rs
index e948d81e7..0ed31f8e0 100644
--- a/tools/sched_ext/scx_rusty/src/rusty_sys.rs
+++ b/tools/sched_ext/scx_layered/src/bpf_intf.rs
@@ -7,4 +7,4 @@
 #![allow(non_snake_case)]
 #![allow(dead_code)]
 
-include!(concat!(env!("OUT_DIR"), "/rusty_sys.rs"));
+include!(concat!(env!("OUT_DIR"), "/bpf_intf.rs"));
diff --git a/tools/sched_ext/scx_rusty/src/rusty.rs b/tools/sched_ext/scx_layered/src/bpf_skel.rs
similarity index 89%
rename from tools/sched_ext/scx_rusty/src/rusty.rs
rename to tools/sched_ext/scx_layered/src/bpf_skel.rs
index 485ad5150..063ccf896 100644
--- a/tools/sched_ext/scx_rusty/src/rusty.rs
+++ b/tools/sched_ext/scx_layered/src/bpf_skel.rs
@@ -9,4 +9,4 @@
 // "/bpf.skel.rs")` does not work inside the path attribute yet (see
 // https://github.com/rust-lang/rust/pull/83366).
 
-include!(concat!(env!("OUT_DIR"), "/rusty.bpf.skel.rs"));
+include!(concat!(env!("OUT_DIR"), "/bpf_skel.rs"));
diff --git a/tools/sched_ext/scx_layered/src/main.rs b/tools/sched_ext/scx_layered/src/main.rs
index 3562fb8bb..8f4d77db0 100644
--- a/tools/sched_ext/scx_layered/src/main.rs
+++ b/tools/sched_ext/scx_layered/src/main.rs
@@ -2,9 +2,9 @@
 
 // This software may be used and distributed according to the terms of the
 // GNU General Public License version 2.
-mod layered;
-pub use layered::*;
-pub mod layered_sys;
+mod bpf_skel;
+pub use bpf_skel::*;
+pub mod bpf_intf;
 
 use std::collections::BTreeMap;
 use std::collections::BTreeSet;
@@ -37,17 +37,17 @@
 use serde::Deserialize;
 use serde::Serialize;
 
-const RAVG_FRAC_BITS: u32 = layered_sys::ravg_consts_RAVG_FRAC_BITS;
-const MAX_CPUS: usize = layered_sys::consts_MAX_CPUS as usize;
-const MAX_PATH: usize = layered_sys::consts_MAX_PATH as usize;
-const MAX_COMM: usize = layered_sys::consts_MAX_COMM as usize;
-const MAX_LAYER_MATCH_ORS: usize = layered_sys::consts_MAX_LAYER_MATCH_ORS as usize;
-const MAX_LAYERS: usize = layered_sys::consts_MAX_LAYERS as usize;
-const USAGE_HALF_LIFE: u32 = layered_sys::consts_USAGE_HALF_LIFE;
+const RAVG_FRAC_BITS: u32 = bpf_intf::ravg_consts_RAVG_FRAC_BITS;
+const MAX_CPUS: usize = bpf_intf::consts_MAX_CPUS as usize;
+const MAX_PATH: usize = bpf_intf::consts_MAX_PATH as usize;
+const MAX_COMM: usize = bpf_intf::consts_MAX_COMM as usize;
+const MAX_LAYER_MATCH_ORS: usize = bpf_intf::consts_MAX_LAYER_MATCH_ORS as usize;
+const MAX_LAYERS: usize = bpf_intf::consts_MAX_LAYERS as usize;
+const USAGE_HALF_LIFE: u32 = bpf_intf::consts_USAGE_HALF_LIFE;
 const USAGE_HALF_LIFE_F64: f64 = USAGE_HALF_LIFE as f64 / 1_000_000_000.0;
-const NR_GSTATS: usize = layered_sys::global_stat_idx_NR_GSTATS as usize;
-const NR_LSTATS: usize = layered_sys::layer_stat_idx_NR_LSTATS as usize;
-const NR_LAYER_MATCH_KINDS: usize = layered_sys::layer_match_kind_NR_LAYER_MATCH_KINDS as usize;
+const NR_GSTATS: usize = bpf_intf::global_stat_idx_NR_GSTATS as usize;
+const NR_LSTATS: usize = bpf_intf::layer_stat_idx_NR_LSTATS as usize;
+const NR_LAYER_MATCH_KINDS: usize = bpf_intf::layer_match_kind_NR_LAYER_MATCH_KINDS as usize;
 const CORE_CACHE_LEVEL: u32 = 2;
 
 lazy_static::lazy_static! {
@@ -408,7 +408,7 @@ fn format_bitvec(bitvec: &BitVec) -> String {
     output
 }
 
-fn read_cpu_ctxs(skel: &LayeredSkel) -> Result<Vec<layered_sys::cpu_ctx>> {
+fn read_cpu_ctxs(skel: &BpfSkel) -> Result<Vec<bpf_intf::cpu_ctx>> {
     let mut cpu_ctxs = vec![];
     let cpu_ctxs_vec = skel
         .maps()
@@ -418,7 +418,7 @@ fn read_cpu_ctxs(skel: &LayeredSkel) -> Result<Vec<layered_sys::cpu_ctx>> {
         .unwrap();
     for cpu in 0..*NR_POSSIBLE_CPUS {
         cpu_ctxs.push(*unsafe {
-            &*(cpu_ctxs_vec[cpu].as_slice().as_ptr() as *const layered_sys::cpu_ctx)
+            &*(cpu_ctxs_vec[cpu].as_slice().as_ptr() as *const bpf_intf::cpu_ctx)
         });
     }
     Ok(cpu_ctxs)
@@ -432,7 +432,7 @@ struct BpfStats {
 }
 
 impl BpfStats {
-    fn read(cpu_ctxs: &[layered_sys::cpu_ctx], nr_layers: usize) -> Self {
+    fn read(cpu_ctxs: &[bpf_intf::cpu_ctx], nr_layers: usize) -> Self {
         let mut gstats = vec![0u64; NR_GSTATS];
         let mut lstats = vec![vec![0u64; NR_LSTATS]; nr_layers];
 
@@ -501,7 +501,7 @@ struct Stats {
 }
 
 impl Stats {
-    fn read_layer_loads(skel: &mut LayeredSkel, nr_layers: usize) -> (f64, Vec<f64>) {
+    fn read_layer_loads(skel: &mut BpfSkel, nr_layers: usize) -> (f64, Vec<f64>) {
         let now_mono = now_monotonic();
         let layer_loads: Vec<f64> = skel
             .bss()
@@ -524,7 +524,7 @@ fn read_layer_loads(skel: &mut LayeredSkel, nr_layers: usize) -> (f64, Vec<f64>)
         (layer_loads.iter().sum(), layer_loads)
     }
 
-    fn read_layer_cycles(cpu_ctxs: &[layered_sys::cpu_ctx], nr_layers: usize) -> Vec<u64> {
+    fn read_layer_cycles(cpu_ctxs: &[bpf_intf::cpu_ctx], nr_layers: usize) -> Vec<u64> {
         let mut layer_cycles = vec![0u64; nr_layers];
 
         for cpu in 0..*NR_POSSIBLE_CPUS {
@@ -536,7 +536,7 @@ fn read_layer_cycles(cpu_ctxs: &[layered_sys::cpu_ctx], nr_layers: usize) -> Vec
         layer_cycles
     }
 
-    fn new(skel: &mut LayeredSkel, proc_reader: &procfs::ProcReader) -> Result<Self> {
+    fn new(skel: &mut BpfSkel, proc_reader: &procfs::ProcReader) -> Result<Self> {
         let nr_layers = skel.rodata().nr_layers as usize;
         let bpf_stats = BpfStats::read(&read_cpu_ctxs(skel)?, nr_layers);
 
@@ -563,7 +563,7 @@ fn new(skel: &mut LayeredSkel, proc_reader: &procfs::ProcReader) -> Result<Self>
 
     fn refresh(
         &mut self,
-        skel: &mut LayeredSkel,
+        skel: &mut BpfSkel,
         proc_reader: &procfs::ProcReader,
         now: Instant,
     ) -> Result<()> {
@@ -632,7 +632,7 @@ struct UserExitInfo {
 }
 
 impl UserExitInfo {
-    fn read(bpf_uei: &layered_bss_types::user_exit_info) -> Result<Self> {
+    fn read(bpf_uei: &bpf_bss_types::user_exit_info) -> Result<Self> {
         let kind = unsafe { std::ptr::read_volatile(&bpf_uei.kind as *const _) };
 
         let (reason, msg) = if kind != 0 {
@@ -659,7 +659,7 @@ fn read(bpf_uei: &layered_bss_types::user_exit_info) -> Result<Self> {
         Ok(Self { kind, reason, msg })
     }
 
-    fn exited(bpf_uei: &layered_bss_types::user_exit_info) -> Result<bool> {
+    fn exited(bpf_uei: &bpf_bss_types::user_exit_info) -> Result<bool> {
         Ok(Self::read(bpf_uei)?.kind != 0)
     }
 
@@ -1100,7 +1100,7 @@ fn resize_confined_or_grouped(
 }
 
 struct Scheduler<'a> {
-    skel: LayeredSkel<'a>,
+    skel: BpfSkel<'a>,
     struct_ops: Option<libbpf_rs::Link>,
     layer_specs: Vec<LayerSpec>,
 
@@ -1121,7 +1121,7 @@ struct Scheduler<'a> {
 }
 
 impl<'a> Scheduler<'a> {
-    fn init_layers(skel: &mut OpenLayeredSkel, specs: &Vec<LayerSpec>) -> Result<()> {
+    fn init_layers(skel: &mut OpenBpfSkel, specs: &Vec<LayerSpec>) -> Result<()> {
         skel.rodata().nr_layers = specs.len() as u32;
 
         for (spec_i, spec) in specs.iter().enumerate() {
@@ -1132,19 +1132,19 @@ fn init_layers(skel: &mut OpenLayeredSkel, specs: &Vec<LayerSpec>) -> Result<()>
                     let mt = &mut layer.matches[or_i].matches[and_i];
                     match and {
                         LayerMatch::CgroupPrefix(prefix) => {
-                            mt.kind = layered_sys::layer_match_kind_MATCH_CGROUP_PREFIX as i32;
+                            mt.kind = bpf_intf::layer_match_kind_MATCH_CGROUP_PREFIX as i32;
                             copy_into_cstr(&mut mt.cgroup_prefix, prefix.as_str());
                         }
                         LayerMatch::CommPrefix(prefix) => {
-                            mt.kind = layered_sys::layer_match_kind_MATCH_COMM_PREFIX as i32;
+                            mt.kind = bpf_intf::layer_match_kind_MATCH_COMM_PREFIX as i32;
                             copy_into_cstr(&mut mt.comm_prefix, prefix.as_str());
                         }
                         LayerMatch::NiceAbove(nice) => {
-                            mt.kind = layered_sys::layer_match_kind_MATCH_NICE_ABOVE as i32;
+                            mt.kind = bpf_intf::layer_match_kind_MATCH_NICE_ABOVE as i32;
                             mt.nice_above_or_below = *nice;
                         }
                         LayerMatch::NiceBelow(nice) => {
-                            mt.kind = layered_sys::layer_match_kind_MATCH_NICE_BELOW as i32;
+                            mt.kind = bpf_intf::layer_match_kind_MATCH_NICE_BELOW as i32;
                             mt.nice_above_or_below = *nice;
                         }
                     }
@@ -1171,7 +1171,7 @@ fn init(opts: &Opts, layer_specs: Vec<LayerSpec>) -> Result<Self> {
         let mut cpu_pool = CpuPool::new()?;
 
         // Open the BPF prog first for verification.
-        let mut skel_builder = LayeredSkelBuilder::default();
+        let mut skel_builder = BpfSkelBuilder::default();
         skel_builder.obj_builder.debug(opts.verbose > 1);
         let mut skel = skel_builder.open().context("Failed to open BPF program")?;
 
@@ -1227,7 +1227,7 @@ fn init(opts: &Opts, layer_specs: Vec<LayerSpec>) -> Result<Self> {
         })
     }
 
-    fn update_bpf_layer_cpumask(layer: &Layer, bpf_layer: &mut layered_bss_types::layer) {
+    fn update_bpf_layer_cpumask(layer: &Layer, bpf_layer: &mut bpf_bss_types::layer) {
         for bit in 0..layer.cpus.len() {
             if layer.cpus[bit] {
                 bpf_layer.cpus[bit / 8] |= 1 << (bit % 8);
@@ -1323,8 +1323,8 @@ fn report(&mut self) -> Result<()> {
         self.prev_processing_dur = self.processing_dur;
 
         let lsum = |idx| stats.bpf_stats.lstats_sums[idx as usize];
-        let total = lsum(layered_sys::layer_stat_idx_LSTAT_LOCAL)
-            + lsum(layered_sys::layer_stat_idx_LSTAT_GLOBAL);
+        let total = lsum(bpf_intf::layer_stat_idx_LSTAT_LOCAL)
+            + lsum(bpf_intf::layer_stat_idx_LSTAT_GLOBAL);
         let lsum_pct = |idx| {
             if total != 0 {
                 lsum(idx) as f64 / total as f64 * 100.0
@@ -1336,11 +1336,11 @@ fn report(&mut self) -> Result<()> {
         info!(
             "tot={:7} local={:5.2} open_idle={:5.2} affn_viol={:5.2} tctx_err={} proc={:?}ms",
             total,
-            lsum_pct(layered_sys::layer_stat_idx_LSTAT_LOCAL),
-            lsum_pct(layered_sys::layer_stat_idx_LSTAT_OPEN_IDLE),
-            lsum_pct(layered_sys::layer_stat_idx_LSTAT_AFFN_VIOL),
+            lsum_pct(bpf_intf::layer_stat_idx_LSTAT_LOCAL),
+            lsum_pct(bpf_intf::layer_stat_idx_LSTAT_OPEN_IDLE),
+            lsum_pct(bpf_intf::layer_stat_idx_LSTAT_AFFN_VIOL),
             stats.prev_bpf_stats.gstats
-                [layered_sys::global_stat_idx_GSTAT_TASK_CTX_FREE_FAILED as usize],
+                [bpf_intf::global_stat_idx_GSTAT_TASK_CTX_FREE_FAILED as usize],
             processing_dur.as_millis(),
         );
 
@@ -1366,8 +1366,8 @@ fn report(&mut self) -> Result<()> {
 
         for (lidx, (spec, layer)) in self.layer_specs.iter().zip(self.layers.iter()).enumerate() {
             let lstat = |sidx| stats.bpf_stats.lstats[lidx][sidx as usize];
-            let ltotal = lstat(layered_sys::layer_stat_idx_LSTAT_LOCAL)
-                + lstat(layered_sys::layer_stat_idx_LSTAT_GLOBAL);
+            let ltotal = lstat(bpf_intf::layer_stat_idx_LSTAT_LOCAL)
+                + lstat(bpf_intf::layer_stat_idx_LSTAT_GLOBAL);
             let lstat_pct = |sidx| {
                 if ltotal != 0 {
                     lstat(sidx) as f64 / ltotal as f64 * 100.0
@@ -1390,10 +1390,10 @@ fn report(&mut self) -> Result<()> {
                 "  {:<width$}  tot={:7} local={:5.2} open_idle={:5.2} preempt={:5.2} affn_viol={:5.2}",
                 "",
                 ltotal,
-                lstat_pct(layered_sys::layer_stat_idx_LSTAT_LOCAL),
-                lstat_pct(layered_sys::layer_stat_idx_LSTAT_OPEN_IDLE),
-                lstat_pct(layered_sys::layer_stat_idx_LSTAT_PREEMPT),
-                lstat_pct(layered_sys::layer_stat_idx_LSTAT_AFFN_VIOL),
+                lstat_pct(bpf_intf::layer_stat_idx_LSTAT_LOCAL),
+                lstat_pct(bpf_intf::layer_stat_idx_LSTAT_OPEN_IDLE),
+                lstat_pct(bpf_intf::layer_stat_idx_LSTAT_PREEMPT),
+                lstat_pct(bpf_intf::layer_stat_idx_LSTAT_AFFN_VIOL),
                 width = header_width,
             );
             info!(
diff --git a/tools/sched_ext/scx_rusty/Cargo.toml b/tools/sched_ext/scx_rusty/Cargo.toml
index 77c0205c2..68db432c5 100644
--- a/tools/sched_ext/scx_rusty/Cargo.toml
+++ b/tools/sched_ext/scx_rusty/Cargo.toml
@@ -24,6 +24,7 @@ simplelog = "0.12.0"
 [build-dependencies]
 bindgen = { version = "0.61.0" }
 libbpf-cargo = "0.21.0"
+glob = "0.3"
 
 [features]
 enable_backtrace = []
diff --git a/tools/sched_ext/scx_rusty/build.rs b/tools/sched_ext/scx_rusty/build.rs
index 6397a1ed0..4f240bfbc 100644
--- a/tools/sched_ext/scx_rusty/build.rs
+++ b/tools/sched_ext/scx_rusty/build.rs
@@ -7,11 +7,13 @@
 use std::env;
 use std::path::PathBuf;
 
+use glob::glob;
 use libbpf_cargo::SkeletonBuilder;
 
-const HEADER_PATH: &str = "src/bpf/rusty.h";
+const HEADER_PATH: &str = "src/bpf/intf.h";
+const SKEL_NAME: &str = "bpf";
 
-fn bindgen_rusty() {
+fn bindgen_bpf_intf() {
     // Tell cargo to invalidate the built crate whenever the wrapper changes
     println!("cargo:rerun-if-changed={}", HEADER_PATH);
 
@@ -33,28 +35,32 @@ fn bindgen_rusty() {
     // Write the bindings to the $OUT_DIR/bindings.rs file.
     let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
     bindings
-        .write_to_file(out_path.join("rusty_sys.rs"))
+        .write_to_file(out_path.join("bpf_intf.rs"))
         .expect("Couldn't write bindings!");
 }
 
-fn gen_bpf_sched(name: &str) {
-    let bpf_cflags = env::var("SCX_RUST_BPF_CFLAGS").unwrap();
-    let clang = env::var("SCX_RUST_CLANG").unwrap();
-    let src = format!("./src/bpf/{}.bpf.c", name);
+fn gen_bpf_skel() {
+    let bpf_cflags = env::var("BPF_CFLAGS").unwrap();
+    let clang = env::var("BPF_CLANG").unwrap();
+    let src = format!("./src/bpf/main.bpf.c");
     let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
-    let skel_path = out_path.join(format!("{}.bpf.skel.rs", name));
-    let obj = out_path.join(format!("{}.bpf.o", name));
+    let skel_path = out_path.join(format!("{}_skel.rs", SKEL_NAME));
+    let obj = out_path.join(format!("{}.bpf.o", SKEL_NAME));
     SkeletonBuilder::new()
         .source(&src)
-	.obj(&obj)
+        .obj(&obj)
         .clang(clang)
         .clang_args(bpf_cflags)
         .build_and_generate(&skel_path)
         .unwrap();
-    println!("cargo:rerun-if-changed={}", src);
+
+    // Trigger rebuild if any .[hc] files are changed in the directory.
+    for path in glob("./src/bpf/*.[hc]").unwrap().filter_map(Result::ok) {
+        println!("cargo:rerun-if-changed={}", path.to_str().unwrap());
+    }
 }
 
 fn main() {
-    bindgen_rusty();
-    gen_bpf_sched("rusty");
+    bindgen_bpf_intf();
+    gen_bpf_skel();
 }
diff --git a/tools/sched_ext/scx_rusty/src/bpf/rusty.h b/tools/sched_ext/scx_rusty/src/bpf/intf.h
similarity index 97%
rename from tools/sched_ext/scx_rusty/src/bpf/rusty.h
rename to tools/sched_ext/scx_rusty/src/bpf/intf.h
index 8a7487cf4..34e2e5af7 100644
--- a/tools/sched_ext/scx_rusty/src/bpf/rusty.h
+++ b/tools/sched_ext/scx_rusty/src/bpf/intf.h
@@ -2,8 +2,8 @@
 
 // This software may be used and distributed according to the terms of the
 // GNU General Public License version 2.
-#ifndef __RUSTY_H
-#define __RUSTY_H
+#ifndef __INTF_H
+#define __INTF_H
 
 #include <stdbool.h>
 #ifndef __kptr
@@ -94,4 +94,4 @@ struct dom_ctx {
 	u64 dbg_load_printed_at;
 };
 
-#endif /* __RUSTY_H */
+#endif /* __INTF_H */
diff --git a/tools/sched_ext/scx_rusty/src/bpf/rusty.bpf.c b/tools/sched_ext/scx_rusty/src/bpf/main.bpf.c
similarity index 99%
rename from tools/sched_ext/scx_rusty/src/bpf/rusty.bpf.c
rename to tools/sched_ext/scx_rusty/src/bpf/main.bpf.c
index 7a8b27cea..befd8d4c6 100644
--- a/tools/sched_ext/scx_rusty/src/bpf/rusty.bpf.c
+++ b/tools/sched_ext/scx_rusty/src/bpf/main.bpf.c
@@ -37,7 +37,7 @@
  */
 #include "../../../scx_common.bpf.h"
 #include "../../../ravg_impl.bpf.h"
-#include "rusty.h"
+#include "intf.h"
 
 #include <errno.h>
 #include <stdbool.h>
diff --git a/tools/sched_ext/scx_layered/src/layered_sys.rs b/tools/sched_ext/scx_rusty/src/bpf_intf.rs
similarity index 83%
rename from tools/sched_ext/scx_layered/src/layered_sys.rs
rename to tools/sched_ext/scx_rusty/src/bpf_intf.rs
index afc821d38..0ed31f8e0 100644
--- a/tools/sched_ext/scx_layered/src/layered_sys.rs
+++ b/tools/sched_ext/scx_rusty/src/bpf_intf.rs
@@ -7,4 +7,4 @@
 #![allow(non_snake_case)]
 #![allow(dead_code)]
 
-include!(concat!(env!("OUT_DIR"), "/layered_sys.rs"));
+include!(concat!(env!("OUT_DIR"), "/bpf_intf.rs"));
diff --git a/tools/sched_ext/scx_layered/src/layered.rs b/tools/sched_ext/scx_rusty/src/bpf_skel.rs
similarity index 89%
rename from tools/sched_ext/scx_layered/src/layered.rs
rename to tools/sched_ext/scx_rusty/src/bpf_skel.rs
index 660499863..063ccf896 100644
--- a/tools/sched_ext/scx_layered/src/layered.rs
+++ b/tools/sched_ext/scx_rusty/src/bpf_skel.rs
@@ -9,4 +9,4 @@
 // "/bpf.skel.rs")` does not work inside the path attribute yet (see
 // https://github.com/rust-lang/rust/pull/83366).
 
-include!(concat!(env!("OUT_DIR"), "/layered.bpf.skel.rs"));
+include!(concat!(env!("OUT_DIR"), "/bpf_skel.rs"));
diff --git a/tools/sched_ext/scx_rusty/src/main.rs b/tools/sched_ext/scx_rusty/src/main.rs
index 57c568b3e..3d802e27d 100644
--- a/tools/sched_ext/scx_rusty/src/main.rs
+++ b/tools/sched_ext/scx_rusty/src/main.rs
@@ -2,9 +2,9 @@
 
 // This software may be used and distributed according to the terms of the
 // GNU General Public License version 2.
-mod rusty;
-pub use rusty::*;
-pub mod rusty_sys;
+mod bpf_skel;
+pub use bpf_skel::*;
+pub mod bpf_intf;
 
 use std::cell::Cell;
 use std::collections::BTreeMap;
@@ -35,9 +35,9 @@
 use ordered_float::OrderedFloat;
 use scx_utils::ravg::ravg_read;
 
-const RAVG_FRAC_BITS: u32 = rusty_sys::ravg_consts_RAVG_FRAC_BITS;
-const MAX_DOMS: usize = rusty_sys::consts_MAX_DOMS as usize;
-const MAX_CPUS: usize = rusty_sys::consts_MAX_CPUS as usize;
+const RAVG_FRAC_BITS: u32 = bpf_intf::ravg_consts_RAVG_FRAC_BITS;
+const MAX_DOMS: usize = bpf_intf::consts_MAX_DOMS as usize;
+const MAX_CPUS: usize = bpf_intf::consts_MAX_CPUS as usize;
 
 /// scx_rusty: A multi-domain BPF / userspace hybrid scheduler
 ///
@@ -420,7 +420,7 @@ fn new(top: Arc<Topology>, opts: &Opts) -> Result<Self> {
         })
     }
 
-    fn step(&mut self, skel: &mut RustySkel) -> Result<()> {
+    fn step(&mut self, skel: &mut BpfSkel) -> Result<()> {
         let curr_cpu_stats = self
             .proc_reader
             .read_stat()?
@@ -496,7 +496,7 @@ struct TaskInfo {
 }
 
 struct LoadBalancer<'a, 'b, 'c> {
-    skel: &'a mut RustySkel<'b>,
+    skel: &'a mut BpfSkel<'b>,
     top: Arc<Topology>,
     skip_kworkers: bool,
 
@@ -531,7 +531,7 @@ impl<'a, 'b, 'c> LoadBalancer<'a, 'b, 'c> {
     const LOAD_IMBAL_PUSH_MAX_RATIO: f64 = 0.50;
 
     fn new(
-        skel: &'a mut RustySkel<'b>,
+        skel: &'a mut BpfSkel<'b>,
         top: Arc<Topology>,
         skip_kworkers: bool,
         nr_lb_data_errors: &'c mut u64,
@@ -568,9 +568,8 @@ fn read_dom_loads(&mut self) -> Result<()> {
                 .lookup(&key, libbpf_rs::MapFlags::ANY)
                 .context("Failed to lookup dom_ctx")?
             {
-                let dom_ctx = unsafe {
-                    &*(dom_ctx_map_elem.as_slice().as_ptr() as *const rusty_sys::dom_ctx)
-                };
+                let dom_ctx =
+                    unsafe { &*(dom_ctx_map_elem.as_slice().as_ptr() as *const bpf_intf::dom_ctx) };
 
                 let rd = &dom_ctx.load_rd;
                 self.dom_loads[i] = ravg_read(
@@ -620,7 +619,7 @@ fn populate_tasks_by_load(&mut self, dom: u32) -> Result<()> {
         //
         // XXX - We can't read task_ctx inline because self.skel.bss()
         // borrows mutably and thus conflicts with self.skel.maps().
-        const MAX_PIDS: u64 = rusty_sys::consts_MAX_DOM_ACTIVE_PIDS as u64;
+        const MAX_PIDS: u64 = bpf_intf::consts_MAX_DOM_ACTIVE_PIDS as u64;
         let active_pids = &mut self.skel.bss().dom_active_pids[dom as usize];
         let mut pids = vec![];
 
@@ -649,7 +648,7 @@ fn populate_tasks_by_load(&mut self, dom: u32) -> Result<()> {
 
             if let Some(task_data_elem) = task_data.lookup(&key, libbpf_rs::MapFlags::ANY)? {
                 let task_ctx =
-                    unsafe { &*(task_data_elem.as_slice().as_ptr() as *const rusty_sys::task_ctx) };
+                    unsafe { &*(task_data_elem.as_slice().as_ptr() as *const bpf_intf::task_ctx) };
 
                 if task_ctx.dom_id != dom {
                     continue;
@@ -860,7 +859,7 @@ fn load_balance(&mut self) -> Result<()> {
 }
 
 struct Scheduler<'a> {
-    skel: RustySkel<'a>,
+    skel: BpfSkel<'a>,
     struct_ops: Option<libbpf_rs::Link>,
 
     sched_interval: Duration,
@@ -882,7 +881,7 @@ struct Scheduler<'a> {
 impl<'a> Scheduler<'a> {
     fn init(opts: &Opts) -> Result<Self> {
         // Open the BPF prog first for verification.
-        let mut skel_builder = RustySkelBuilder::default();
+        let mut skel_builder = BpfSkelBuilder::default();
         skel_builder.obj_builder.debug(opts.verbose > 0);
         let mut skel = skel_builder.open().context("Failed to open BPF program")?;
 
@@ -1024,7 +1023,7 @@ fn read_bpf_stats(&mut self) -> Result<Vec<u64>> {
         let mut stats: Vec<u64> = Vec::new();
         let zero_vec = vec![vec![0u8; stats_map.value_size() as usize]; self.top.nr_cpus];
 
-        for stat in 0..rusty_sys::stat_idx_RUSTY_NR_STATS {
+        for stat in 0..bpf_intf::stat_idx_RUSTY_NR_STATS {
             let cpu_stat_vec = stats_map
                 .lookup_percpu(&stat.to_ne_bytes(), libbpf_rs::MapFlags::ANY)
                 .with_context(|| format!("Failed to lookup stat {}", stat))?
@@ -1057,22 +1056,22 @@ fn report(
         imbal: &[f64],
     ) {
         let stat = |idx| stats[idx as usize];
-        let total = stat(rusty_sys::stat_idx_RUSTY_STAT_WAKE_SYNC)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_PREV_IDLE)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_GREEDY_IDLE)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_PINNED)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_DISPATCH)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_GREEDY)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_GREEDY_FAR)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_DSQ_DISPATCH)
-            + stat(rusty_sys::stat_idx_RUSTY_STAT_GREEDY);
+        let total = stat(bpf_intf::stat_idx_RUSTY_STAT_WAKE_SYNC)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_PREV_IDLE)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_GREEDY_IDLE)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_PINNED)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_DISPATCH)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_GREEDY)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_GREEDY_FAR)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_DSQ_DISPATCH)
+            + stat(bpf_intf::stat_idx_RUSTY_STAT_GREEDY);
 
         info!(
             "cpu={:7.2} bal={} load_avg={:8.2} task_err={} lb_data_err={} proc={:?}ms",
             cpu_busy * 100.0,
-            stats[rusty_sys::stat_idx_RUSTY_STAT_LOAD_BALANCE as usize],
+            stats[bpf_intf::stat_idx_RUSTY_STAT_LOAD_BALANCE as usize],
             load_avg,
-            stats[rusty_sys::stat_idx_RUSTY_STAT_TASK_GET_ERR as usize],
+            stats[bpf_intf::stat_idx_RUSTY_STAT_TASK_GET_ERR as usize],
             self.nr_lb_data_errors,
             processing_dur.as_millis(),
         );
@@ -1082,25 +1081,25 @@ fn report(
         info!(
             "tot={:7} wsync={:5.2} prev_idle={:5.2} greedy_idle={:5.2} pin={:5.2}",
             total,
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_WAKE_SYNC),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_PREV_IDLE),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_GREEDY_IDLE),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_PINNED),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_WAKE_SYNC),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_PREV_IDLE),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_GREEDY_IDLE),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_PINNED),
         );
 
         info!(
             "dir={:5.2} dir_greedy={:5.2} dir_greedy_far={:5.2}",
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_DISPATCH),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_GREEDY),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_DIRECT_GREEDY_FAR),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_DISPATCH),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_GREEDY),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_DIRECT_GREEDY_FAR),
         );
 
         info!(
             "dsq={:5.2} greedy={:5.2} kick_greedy={:5.2} rep={:5.2}",
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_DSQ_DISPATCH),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_GREEDY),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_KICK_GREEDY),
-            stat_pct(rusty_sys::stat_idx_RUSTY_STAT_REPATRIATE),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_DSQ_DISPATCH),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_GREEDY),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_KICK_GREEDY),
+            stat_pct(bpf_intf::stat_idx_RUSTY_STAT_REPATRIATE),
         );
 
         let ti = &self.skel.bss().tune_input;
-- 
2.43.0.rc2

