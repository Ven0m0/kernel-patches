From b9e351d2d045d5aad817ea11f90c579c2e73220d Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@redhat.com>
Date: Fri, 10 May 2019 08:28:07 +0200
Subject: [PATCH 01/12] mm/ksm: introduce ksm_madvise_merge() helper

Move MADV_MERGEABLE part of ksm_madvise() into a dedicated helper since
it will be further used for marking VMAs to be merged forcibly.

This does not bring any functional changes.

Signed-off-by: Oleksandr Natalenko <oleksandr@redhat.com>
---
 include/linux/ksm.h |  2 ++
 mm/ksm.c            | 56 +++++++++++++++++++++++++++------------------
 2 files changed, 36 insertions(+), 22 deletions(-)

diff --git a/include/linux/ksm.h b/include/linux/ksm.h
index 0b4f17418..dde5c9310 100644
--- a/include/linux/ksm.h
+++ b/include/linux/ksm.h
@@ -19,6 +19,8 @@ struct stable_node;
 struct mem_cgroup;
 
 #ifdef CONFIG_KSM
+int ksm_madvise_merge(struct mm_struct *mm, struct vm_area_struct *vma,
+		unsigned long *vm_flags);
 int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
 		unsigned long end, int advice, unsigned long *vm_flags);
 int __ksm_enter(struct mm_struct *mm);
diff --git a/mm/ksm.c b/mm/ksm.c
index 54f78c9ee..6b6eeb806 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -2438,41 +2438,53 @@ static int ksm_scan_thread(void *nothing)
 	return 0;
 }
 
-int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
-		unsigned long end, int advice, unsigned long *vm_flags)
+int ksm_madvise_merge(struct mm_struct *mm, struct vm_area_struct *vma,
+		unsigned long *vm_flags)
 {
-	struct mm_struct *mm = vma->vm_mm;
 	int err;
 
-	switch (advice) {
-	case MADV_MERGEABLE:
-		/*
-		 * Be somewhat over-protective for now!
-		 */
-		if (*vm_flags & (VM_MERGEABLE | VM_SHARED  | VM_MAYSHARE   |
-				 VM_PFNMAP    | VM_IO      | VM_DONTEXPAND |
-				 VM_HUGETLB | VM_MIXEDMAP))
-			return 0;		/* just ignore the advice */
+	/*
+	 * Be somewhat over-protective for now!
+	 */
+	if (*vm_flags & (VM_MERGEABLE | VM_SHARED  | VM_MAYSHARE   |
+			 VM_PFNMAP    | VM_IO      | VM_DONTEXPAND |
+			 VM_HUGETLB | VM_MIXEDMAP))
+		return 0;		/* just ignore the advice */
 
-		if (vma_is_dax(vma))
-			return 0;
+	if (vma_is_dax(vma))
+		return 0;
 
 #ifdef VM_SAO
 		if (*vm_flags & VM_SAO)
 			return 0;
 #endif
 #ifdef VM_SPARC_ADI
-		if (*vm_flags & VM_SPARC_ADI)
-			return 0;
+	if (*vm_flags & VM_SPARC_ADI)
+		return 0;
 #endif
 
-		if (!test_bit(MMF_VM_MERGEABLE, &mm->flags)) {
-			err = __ksm_enter(mm);
-			if (err)
-				return err;
-		}
+	if (!test_bit(MMF_VM_MERGEABLE, &mm->flags)) {
+		err = __ksm_enter(mm);
+		if (err)
+			return err;
+	}
+
+	*vm_flags |= VM_MERGEABLE;
+
+	return 0;
+}
+
+int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
+		unsigned long end, int advice, unsigned long *vm_flags)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	int err;
 
-		*vm_flags |= VM_MERGEABLE;
+	switch (advice) {
+	case MADV_MERGEABLE:
+		err = ksm_madvise_merge(mm, vma, vm_flags);
+		if (err)
+			return err;
 		break;
 
 	case MADV_UNMERGEABLE:
-- 
2.37.1.377.g679aad9e82


From cb63e1f43e84a9360db64e3f9598324d8022571d Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@redhat.com>
Date: Tue, 14 May 2019 10:40:56 +0200
Subject: [PATCH 02/12] mm/ksm: introduce ksm_madvise_unmerge() helper

Move MADV_UNMERGEABLE part of ksm_madvise() into a dedicated helper
since it will be further used for unmerging VMAs forcibly.

This does not bring any functional changes.

Signed-off-by: Oleksandr Natalenko <oleksandr@redhat.com>
---
 include/linux/ksm.h |  2 ++
 mm/ksm.c            | 32 ++++++++++++++++++++++----------
 2 files changed, 24 insertions(+), 10 deletions(-)

diff --git a/include/linux/ksm.h b/include/linux/ksm.h
index dde5c9310..e24cf9144 100644
--- a/include/linux/ksm.h
+++ b/include/linux/ksm.h
@@ -21,6 +21,8 @@ struct mem_cgroup;
 #ifdef CONFIG_KSM
 int ksm_madvise_merge(struct mm_struct *mm, struct vm_area_struct *vma,
 		unsigned long *vm_flags);
+int ksm_madvise_unmerge(struct vm_area_struct *vma, unsigned long start,
+		unsigned long end, unsigned long *vm_flags);
 int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
 		unsigned long end, int advice, unsigned long *vm_flags);
 int __ksm_enter(struct mm_struct *mm);
diff --git a/mm/ksm.c b/mm/ksm.c
index 6b6eeb806..e4a4b3d2b 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -2474,6 +2474,25 @@ int ksm_madvise_merge(struct mm_struct *mm, struct vm_area_struct *vma,
 	return 0;
 }
 
+int ksm_madvise_unmerge(struct vm_area_struct *vma, unsigned long start,
+		unsigned long end, unsigned long *vm_flags)
+{
+	int err;
+
+	if (!(*vm_flags & VM_MERGEABLE))
+		return 0;		/* just ignore the advice */
+
+	if (vma->anon_vma) {
+		err = unmerge_ksm_pages(vma, start, end);
+		if (err)
+			return err;
+	}
+
+	*vm_flags &= ~VM_MERGEABLE;
+
+	return 0;
+}
+
 int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
 		unsigned long end, int advice, unsigned long *vm_flags)
 {
@@ -2488,16 +2507,9 @@ int ksm_madvise(struct vm_area_struct *vma, unsigned long start,
 		break;
 
 	case MADV_UNMERGEABLE:
-		if (!(*vm_flags & VM_MERGEABLE))
-			return 0;		/* just ignore the advice */
-
-		if (vma->anon_vma) {
-			err = unmerge_ksm_pages(vma, start, end);
-			if (err)
-				return err;
-		}
-
-		*vm_flags &= ~VM_MERGEABLE;
+		err = ksm_madvise_unmerge(vma, start, end, vm_flags);
+		if (err)
+			return err;
 		break;
 	}
 
-- 
2.37.1.377.g679aad9e82


From 151887c4f59ae4416c257321114f0385aebf3239 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Mon, 4 Oct 2021 22:45:46 +0200
Subject: [PATCH 03/12] mm: introduce pmadv_ksm system call

Yes, I know, this looks like a duplicate of `process_madvise()`. There
are two reasons to do this, however:

1. implementing a new syscall is exceptionally easy and takes less code
   lines than ugly `/proc`-based API, although it imposes slightly more
   difficult usage onto userspace

2. the code gets actually much closer to be merged with `process_madvise()`,
   and this is a small step in that direction.

So, basically, the `pmadv_ksm()` syscall is a twin of
`process_madvise()`, but with two differences:

1. it works with MADV\_(UN)\?MERGEABLE hints only

2. it affects the whole address space of the target task

The second difference is likely to disappear in case two syscalls are
merged, but that's up to either me or to someone else to re-think how to
do it.

uksmd is already able to use this syscall.

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 mm/madvise.c | 86 ++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 86 insertions(+)

diff --git a/mm/madvise.c b/mm/madvise.c
index 0316bbc64..cee32e86e 100644
--- a/mm/madvise.c
+++ b/mm/madvise.c
@@ -1493,3 +1493,89 @@ SYSCALL_DEFINE5(process_madvise, int, pidfd, const struct iovec __user *, vec,
 out:
 	return ret;
 }
+
+SYSCALL_DEFINE3(pmadv_ksm, int, pidfd, int, behaviour, unsigned int, flags)
+{
+#ifdef CONFIG_KSM
+	ssize_t ret;
+	struct pid *pid;
+	struct task_struct *task;
+	struct mm_struct *mm;
+	unsigned int f_flags;
+	struct vm_area_struct *vma;
+
+	if (flags != 0) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	switch (behaviour) {
+		case MADV_MERGEABLE:
+		case MADV_UNMERGEABLE:
+			break;
+		default:
+			ret = -EINVAL;
+			goto out;
+			break;
+	}
+
+	pid = pidfd_get_pid(pidfd, &f_flags);
+	if (IS_ERR(pid)) {
+		ret = PTR_ERR(pid);
+		goto out;
+	}
+
+	task = get_pid_task(pid, PIDTYPE_PID);
+	if (!task) {
+		ret = -ESRCH;
+		goto put_pid;
+	}
+
+	/* Require PTRACE_MODE_READ to avoid leaking ASLR metadata. */
+	mm = mm_access(task, PTRACE_MODE_READ_FSCREDS);
+	if (IS_ERR_OR_NULL(mm)) {
+		ret = IS_ERR(mm) ? PTR_ERR(mm) : -ESRCH;
+		goto release_task;
+	}
+
+	/* Require CAP_SYS_NICE for influencing process performance. */
+	if (!capable(CAP_SYS_NICE)) {
+		ret = -EPERM;
+		goto release_mm;
+	}
+
+	if (mmap_write_lock_killable(mm)) {
+		ret = -EINTR;
+		goto release_mm;
+	}
+
+	for (vma = mm->mmap; vma; vma = vma->vm_next) {
+		switch (behaviour) {
+			case MADV_MERGEABLE:
+				ret = ksm_madvise_merge(vma->vm_mm, vma, &vma->vm_flags);
+				break;
+			case MADV_UNMERGEABLE:
+				ret = ksm_madvise_unmerge(vma, vma->vm_start, vma->vm_end, &vma->vm_flags);
+				break;
+			default:
+				/* look, ma, no brain */
+				break;
+		}
+		if (ret)
+			break;
+	}
+
+	mmap_write_unlock(mm);
+
+release_mm:
+	mmput(mm);
+release_task:
+	put_task_struct(task);
+put_pid:
+	put_pid(pid);
+out:
+	return ret;
+#else /* CONFIG_KSM */
+	return -ENOSYS;
+#endif /* CONFIG_KSM */
+}
-- 
2.37.1.377.g679aad9e82


From ef5fc1fb7f13f03137273250b8cdd1b17f9220b5 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Mon, 4 Oct 2021 22:58:59 +0200
Subject: [PATCH 04/12] mm: wire up pmadv_ksm system call

Present `pmadv_ksm()` syscall for all the arches.

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 arch/alpha/kernel/syscalls/syscall.tbl      | 1 +
 arch/arm/tools/syscall.tbl                  | 1 +
 arch/arm64/include/asm/unistd.h             | 2 +-
 arch/arm64/include/asm/unistd32.h           | 2 ++
 arch/ia64/kernel/syscalls/syscall.tbl       | 1 +
 arch/m68k/kernel/syscalls/syscall.tbl       | 1 +
 arch/microblaze/kernel/syscalls/syscall.tbl | 1 +
 arch/mips/kernel/syscalls/syscall_n32.tbl   | 1 +
 arch/mips/kernel/syscalls/syscall_n64.tbl   | 1 +
 arch/mips/kernel/syscalls/syscall_o32.tbl   | 1 +
 arch/parisc/kernel/syscalls/syscall.tbl     | 1 +
 arch/powerpc/kernel/syscalls/syscall.tbl    | 1 +
 arch/s390/kernel/syscalls/syscall.tbl       | 1 +
 arch/sh/kernel/syscalls/syscall.tbl         | 1 +
 arch/sparc/kernel/syscalls/syscall.tbl      | 1 +
 arch/x86/entry/syscalls/syscall_32.tbl      | 1 +
 arch/x86/entry/syscalls/syscall_64.tbl      | 1 +
 arch/xtensa/kernel/syscalls/syscall.tbl     | 1 +
 include/linux/syscalls.h                    | 1 +
 include/uapi/asm-generic/unistd.h           | 5 ++++-
 kernel/sys_ni.c                             | 1 +
 21 files changed, 25 insertions(+), 2 deletions(-)

diff --git a/arch/alpha/kernel/syscalls/syscall.tbl b/arch/alpha/kernel/syscalls/syscall.tbl
index 3515bc4f1..00ff721da 100644
--- a/arch/alpha/kernel/syscalls/syscall.tbl
+++ b/arch/alpha/kernel/syscalls/syscall.tbl
@@ -490,3 +490,4 @@
 558	common	process_mrelease		sys_process_mrelease
 559	common  futex_waitv                     sys_futex_waitv
 560	common	set_mempolicy_home_node		sys_ni_syscall
+561	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/arm/tools/syscall.tbl b/arch/arm/tools/syscall.tbl
index ac964612d..90933eabe 100644
--- a/arch/arm/tools/syscall.tbl
+++ b/arch/arm/tools/syscall.tbl
@@ -464,3 +464,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common	futex_waitv			sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/arm64/include/asm/unistd.h b/arch/arm64/include/asm/unistd.h
index 037feba03..64a514f90 100644
--- a/arch/arm64/include/asm/unistd.h
+++ b/arch/arm64/include/asm/unistd.h
@@ -39,7 +39,7 @@
 #define __ARM_NR_compat_set_tls		(__ARM_NR_COMPAT_BASE + 5)
 #define __ARM_NR_COMPAT_END		(__ARM_NR_COMPAT_BASE + 0x800)
 
-#define __NR_compat_syscalls		451
+#define __NR_compat_syscalls		452
 #endif
 
 #define __ARCH_WANT_SYS_CLONE
diff --git a/arch/arm64/include/asm/unistd32.h b/arch/arm64/include/asm/unistd32.h
index 604a2053d..91f2bb719 100644
--- a/arch/arm64/include/asm/unistd32.h
+++ b/arch/arm64/include/asm/unistd32.h
@@ -907,6 +907,8 @@ __SYSCALL(__NR_process_mrelease, sys_process_mrelease)
 __SYSCALL(__NR_futex_waitv, sys_futex_waitv)
 #define __NR_set_mempolicy_home_node 450
 __SYSCALL(__NR_set_mempolicy_home_node, sys_set_mempolicy_home_node)
+#define __NR_pmadv_ksm 451
+__SYSCALL(__NR_pmadv_ksm, sys_pmadv_ksm)
 
 /*
  * Please add new compat syscalls above this comment and update
diff --git a/arch/ia64/kernel/syscalls/syscall.tbl b/arch/ia64/kernel/syscalls/syscall.tbl
index 78b1d03e8..79ad5a568 100644
--- a/arch/ia64/kernel/syscalls/syscall.tbl
+++ b/arch/ia64/kernel/syscalls/syscall.tbl
@@ -371,3 +371,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/m68k/kernel/syscalls/syscall.tbl b/arch/m68k/kernel/syscalls/syscall.tbl
index b1f3940bc..5ccf92556 100644
--- a/arch/m68k/kernel/syscalls/syscall.tbl
+++ b/arch/m68k/kernel/syscalls/syscall.tbl
@@ -450,3 +450,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/microblaze/kernel/syscalls/syscall.tbl b/arch/microblaze/kernel/syscalls/syscall.tbl
index 820145e47..6b7620859 100644
--- a/arch/microblaze/kernel/syscalls/syscall.tbl
+++ b/arch/microblaze/kernel/syscalls/syscall.tbl
@@ -456,3 +456,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/mips/kernel/syscalls/syscall_n32.tbl b/arch/mips/kernel/syscalls/syscall_n32.tbl
index 253ff994e..e4aeedb17 100644
--- a/arch/mips/kernel/syscalls/syscall_n32.tbl
+++ b/arch/mips/kernel/syscalls/syscall_n32.tbl
@@ -389,3 +389,4 @@
 448	n32	process_mrelease		sys_process_mrelease
 449	n32	futex_waitv			sys_futex_waitv
 450	n32	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	n32	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/mips/kernel/syscalls/syscall_n64.tbl b/arch/mips/kernel/syscalls/syscall_n64.tbl
index 3f1886ad9..fe88db51e 100644
--- a/arch/mips/kernel/syscalls/syscall_n64.tbl
+++ b/arch/mips/kernel/syscalls/syscall_n64.tbl
@@ -365,3 +365,4 @@
 448	n64	process_mrelease		sys_process_mrelease
 449	n64	futex_waitv			sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	n64	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/mips/kernel/syscalls/syscall_o32.tbl b/arch/mips/kernel/syscalls/syscall_o32.tbl
index 8f243e35a..674cb940b 100644
--- a/arch/mips/kernel/syscalls/syscall_o32.tbl
+++ b/arch/mips/kernel/syscalls/syscall_o32.tbl
@@ -438,3 +438,4 @@
 448	o32	process_mrelease		sys_process_mrelease
 449	o32	futex_waitv			sys_futex_waitv
 450	o32	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	o32	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/parisc/kernel/syscalls/syscall.tbl b/arch/parisc/kernel/syscalls/syscall.tbl
index 8a99c998d..429b129d5 100644
--- a/arch/parisc/kernel/syscalls/syscall.tbl
+++ b/arch/parisc/kernel/syscalls/syscall.tbl
@@ -448,3 +448,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common	futex_waitv			sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/powerpc/kernel/syscalls/syscall.tbl b/arch/powerpc/kernel/syscalls/syscall.tbl
index 2600b4237..bb2f71a36 100644
--- a/arch/powerpc/kernel/syscalls/syscall.tbl
+++ b/arch/powerpc/kernel/syscalls/syscall.tbl
@@ -530,3 +530,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450 	nospu	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/s390/kernel/syscalls/syscall.tbl b/arch/s390/kernel/syscalls/syscall.tbl
index 799147658..1cd523748 100644
--- a/arch/s390/kernel/syscalls/syscall.tbl
+++ b/arch/s390/kernel/syscalls/syscall.tbl
@@ -453,3 +453,4 @@
 448  common	process_mrelease	sys_process_mrelease		sys_process_mrelease
 449  common	futex_waitv		sys_futex_waitv			sys_futex_waitv
 450  common	set_mempolicy_home_node	sys_set_mempolicy_home_node	sys_set_mempolicy_home_node
+451  common	pmadv_ksm		sys_pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/sh/kernel/syscalls/syscall.tbl b/arch/sh/kernel/syscalls/syscall.tbl
index 2de85c977..cfc75fa43 100644
--- a/arch/sh/kernel/syscalls/syscall.tbl
+++ b/arch/sh/kernel/syscalls/syscall.tbl
@@ -453,3 +453,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/sparc/kernel/syscalls/syscall.tbl b/arch/sparc/kernel/syscalls/syscall.tbl
index 4398cc6fb..d2c0a6426 100644
--- a/arch/sparc/kernel/syscalls/syscall.tbl
+++ b/arch/sparc/kernel/syscalls/syscall.tbl
@@ -496,3 +496,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/arch/x86/entry/syscalls/syscall_32.tbl b/arch/x86/entry/syscalls/syscall_32.tbl
index 320480a8d..331aaf1a7 100644
--- a/arch/x86/entry/syscalls/syscall_32.tbl
+++ b/arch/x86/entry/syscalls/syscall_32.tbl
@@ -455,3 +455,4 @@
 448	i386	process_mrelease	sys_process_mrelease
 449	i386	futex_waitv		sys_futex_waitv
 450	i386	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	i386	pmadv_ksm		sys_pmadv_ksm
diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index c84d12608..14902db4c 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -372,6 +372,7 @@
 448	common	process_mrelease	sys_process_mrelease
 449	common	futex_waitv		sys_futex_waitv
 450	common	set_mempolicy_home_node	sys_set_mempolicy_home_node
+451	common	pmadv_ksm		sys_pmadv_ksm
 
 #
 # Due to a historical design error, certain syscalls are numbered differently
diff --git a/arch/xtensa/kernel/syscalls/syscall.tbl b/arch/xtensa/kernel/syscalls/syscall.tbl
index 52c94ab5c..1518e261d 100644
--- a/arch/xtensa/kernel/syscalls/syscall.tbl
+++ b/arch/xtensa/kernel/syscalls/syscall.tbl
@@ -421,3 +421,4 @@
 448	common	process_mrelease		sys_process_mrelease
 449	common  futex_waitv                     sys_futex_waitv
 450	common	set_mempolicy_home_node		sys_set_mempolicy_home_node
+451	common	pmadv_ksm			sys_pmadv_ksm
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index a34b0f9a9..82afad91d 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -917,6 +917,7 @@ asmlinkage long sys_madvise(unsigned long start, size_t len, int behavior);
 asmlinkage long sys_process_madvise(int pidfd, const struct iovec __user *vec,
 			size_t vlen, int behavior, unsigned int flags);
 asmlinkage long sys_process_mrelease(int pidfd, unsigned int flags);
+asmlinkage long sys_pmadv_ksm(int pidfd, int behavior, unsigned int flags);
 asmlinkage long sys_remap_file_pages(unsigned long start, unsigned long size,
 			unsigned long prot, unsigned long pgoff,
 			unsigned long flags);
diff --git a/include/uapi/asm-generic/unistd.h b/include/uapi/asm-generic/unistd.h
index 45fa180cc..40f7e6d04 100644
--- a/include/uapi/asm-generic/unistd.h
+++ b/include/uapi/asm-generic/unistd.h
@@ -886,8 +886,11 @@ __SYSCALL(__NR_futex_waitv, sys_futex_waitv)
 #define __NR_set_mempolicy_home_node 450
 __SYSCALL(__NR_set_mempolicy_home_node, sys_set_mempolicy_home_node)
 
+#define __NR_pmadv_ksm 451
+__SYSCALL(__NR_pmadv_ksm, sys_pmadv_ksm)
+
 #undef __NR_syscalls
-#define __NR_syscalls 451
+#define __NR_syscalls 452
 
 /*
  * 32 bit systems traditionally used different
diff --git a/kernel/sys_ni.c b/kernel/sys_ni.c
index a492f1596..dc765f3ef 100644
--- a/kernel/sys_ni.c
+++ b/kernel/sys_ni.c
@@ -291,6 +291,7 @@ COND_SYSCALL(mincore);
 COND_SYSCALL(madvise);
 COND_SYSCALL(process_madvise);
 COND_SYSCALL(process_mrelease);
+COND_SYSCALL(pmadv_ksm);
 COND_SYSCALL(remap_file_pages);
 COND_SYSCALL(mbind);
 COND_SYSCALL(get_mempolicy);
-- 
2.37.1.377.g679aad9e82


From 3bcd0b445aef75b730361cb371ab26260014c2ed Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Mon, 4 Oct 2021 22:59:38 +0200
Subject: [PATCH 05/12] mm: add sysfs entry for pmadv_ksm syscall number

As `pmadv_ksm()` syscall is out-of-tree, maintain a separate
`/sys/kernel/pmadv/ksm` file with a syscall number so that userspace
tools can always know what to use in runtime even if the syscall number
shifts after adding another in-tree syscall.

The idea is borrowed from futex2 submission.

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 mm/madvise.c | 25 +++++++++++++++++++++++++
 1 file changed, 25 insertions(+)

diff --git a/mm/madvise.c b/mm/madvise.c
index cee32e86e..ddf112fbf 100644
--- a/mm/madvise.c
+++ b/mm/madvise.c
@@ -1579,3 +1579,28 @@ SYSCALL_DEFINE3(pmadv_ksm, int, pidfd, int, behaviour, unsigned int, flags)
 	return -ENOSYS;
 #endif /* CONFIG_KSM */
 }
+
+#ifdef CONFIG_KSM
+static ssize_t ksm_show(struct kobject *kobj, struct kobj_attribute *attr,
+			 char *buf)
+{
+	return sprintf(buf, "%u\n", __NR_pmadv_ksm);
+}
+static struct kobj_attribute pmadv_ksm_attr = __ATTR_RO(ksm);
+
+static struct attribute *pmadv_sysfs_attrs[] = {
+	&pmadv_ksm_attr.attr,
+	NULL,
+};
+
+static const struct attribute_group pmadv_sysfs_attr_group = {
+	.attrs = pmadv_sysfs_attrs,
+	.name = "pmadv",
+};
+
+static int __init pmadv_sysfs_init(void)
+{
+	return sysfs_create_group(kernel_kobj, &pmadv_sysfs_attr_group);
+}
+subsys_initcall(pmadv_sysfs_init);
+#endif /* CONFIG_KSM */
-- 
2.37.1.377.g679aad9e82


From e05c43862fbcb97f72bd06ec969186155807de15 Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 1 Jul 2022 08:43:23 +0000
Subject: [PATCH 06/12] mm/madvise: allow KSM hints for process_madvise

The benefits of doing this are obvious because using madvise in user code
is the only current way to enable KSM, which is inconvenient for those
compiled app without marking MERGEABLE wanting to enable KSM.

Since we already have the syscall of process_madvise(), then reusing the
interface to allow external KSM hints is more acceptable [1].

Although this patch was released by Oleksandr Natalenko, but it was
unfortunately terminated without any conclusions because there was debate
on whether it should use signal_pending() to check the target task besides
the task of current() when calling unmerge_ksm_pages of other task [2].

I think it's unneeded to check the target task. For example, when we set
the klob /sys/kernel/mm/ksm/run from 1 to 2,
unmerge_and_remove_all_rmap_items() doesn't use signal_pending() to check
all other target tasks either.

I hope this patch can get attention again.

[1] https://lore.kernel.org/lkml/YoOrdh85+AqJH8w1@dhcp22.suse.cz/
[2] https://lore.kernel.org/lkml/2a66abd8-4103-f11b-06d1-07762667eee6@suse.cz/

Signed-off-by: Oleksandr Natalenko <oleksandr@redhat.com>
Signed-off-by: xu xin <xu.xin16@zte.com.cn>
---
 mm/madvise.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/mm/madvise.c b/mm/madvise.c
index ddf112fbf..b71963da6 100644
--- a/mm/madvise.c
+++ b/mm/madvise.c
@@ -1173,6 +1173,10 @@ process_madvise_behavior_valid(int behavior)
 	case MADV_COLD:
 	case MADV_PAGEOUT:
 	case MADV_WILLNEED:
+#ifdef CONFIG_KSM
+	case MADV_MERGEABLE:
+	case MADV_UNMERGEABLE:
+#endif
 		return true;
 	default:
 		return false;
-- 
2.37.1.377.g679aad9e82


From 4eb1b1aa2567edc3858b0f45abcef3fae2e342b1 Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 12 Aug 2022 10:11:52 +0000
Subject: [PATCH 07/12] ksm: add a auto-run mode of ksm

Add a new running state auto-mode to ksm. This is to pave the way
for subsequent real optimization features.

Use it by: echo 8 > /sys/kernel/mm/ksm/run

Signed-off-by: xu xin <xu.xin16@zte.com.cn>
Signed-off-by: CGEL <cgel.zte@gmail.com>
---
 mm/ksm.c | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/mm/ksm.c b/mm/ksm.c
index e4a4b3d2b..294feb276 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -290,6 +290,7 @@ static int ksm_nr_node_ids = 1;
 #define KSM_RUN_MERGE	1
 #define KSM_RUN_UNMERGE	2
 #define KSM_RUN_OFFLINE	4
+#define KSM_RUN_AUTO	8
 static unsigned long ksm_run = KSM_RUN_STOP;
 static void wait_while_offlining(void);
 
@@ -2406,7 +2407,9 @@ static void ksm_do_scan(unsigned int scan_npages)
 
 static int ksmd_should_run(void)
 {
-	return (ksm_run & KSM_RUN_MERGE) && !list_empty(&ksm_mm_head.mm_list);
+	if (!list_empty(&ksm_mm_head.mm_list))
+		return ksm_run & KSM_RUN_AUTO || ksm_run & KSM_RUN_MERGE;
+	return 0;
 }
 
 static int ksm_scan_thread(void *nothing)
@@ -2930,7 +2933,7 @@ static ssize_t run_store(struct kobject *kobj, struct kobj_attribute *attr,
 	err = kstrtouint(buf, 10, &flags);
 	if (err)
 		return -EINVAL;
-	if (flags > KSM_RUN_UNMERGE)
+	if (flags > KSM_RUN_UNMERGE && flags != KSM_RUN_AUTO)
 		return -EINVAL;
 
 	/*
@@ -2956,7 +2959,7 @@ static ssize_t run_store(struct kobject *kobj, struct kobj_attribute *attr,
 	}
 	mutex_unlock(&ksm_thread_mutex);
 
-	if (flags & KSM_RUN_MERGE)
+	if (flags & KSM_RUN_MERGE || flags & KSM_RUN_AUTO)
 		wake_up_interruptible(&ksm_thread_wait);
 
 	return count;
-- 
2.37.1.377.g679aad9e82


From b585e956d067aebac11fa4865dfc5615bf85596e Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 12 Aug 2022 10:12:02 +0000
Subject: [PATCH 08/12] ksm: implement scan-enhanced algorithm

Implement the scan-enhanced algorithm of auto mode. In this algorithm,
after every time of scanning, if new ksm pages are obtained, it will
double pages_to_scan for the next scanning until the general
multiplying factor is not less than max_scanning_factor. If no new ksm
pages are obtained, then reset pages_to_scan to the default value.

We add the sysfs klob of max_scanning_factor to limit scanning factor's
excessive growth.

Signed-off-by: CGEL <cgel.zte@gmail.com>
Signed-off-by: xu xin <xu.xin16@zte.com.cn>
---
 mm/ksm.c | 100 +++++++++++++++++++++++++++++++++++++++++++++++++++++--
 1 file changed, 98 insertions(+), 2 deletions(-)

diff --git a/mm/ksm.c b/mm/ksm.c
index 294feb276..160972fe4 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -131,6 +131,10 @@ struct mm_slot {
  * @address: the next address inside that to be scanned
  * @rmap_list: link to the next rmap to be scanned in the rmap_list
  * @seqnr: count of completed full scans (needed when removing unstable node)
+ * @new_ksmpages: count of the new merged KSM pages in the current scanning
+ *	              of mm_lists (cleared after every turn of ksm_do_scan() ends)
+ * @prev_ksmpages: the record of the new merged KSM pages in the last turn of
+ *	               scanning by ksm_do_scan().
  *
  * There is only the one ksm_scan instance of this cursor structure.
  */
@@ -139,6 +143,8 @@ struct ksm_scan {
 	unsigned long address;
 	struct rmap_item **rmap_list;
 	unsigned long seqnr;
+	unsigned long new_ksmpages;
+	unsigned long prev_ksmpages;
 };
 
 /**
@@ -277,6 +283,19 @@ static unsigned int zero_checksum __read_mostly;
 /* Whether to merge empty (zeroed) pages with actual zero pages */
 static bool ksm_use_zero_pages __read_mostly;
 
+/*
+ * Work in auto-mode.
+ * The multiplicative factor of pages_to_scan.
+ * Real pages to scan equals to the product of scanning_factor
+ * and pages_to_scan
+ */
+#define INIT_SCANNING_FACTOR	1
+static unsigned int scanning_factor = INIT_SCANNING_FACTOR;
+
+/* The upper limit of scanning_factor */
+#define DEFAULT_MAX_SCANNING_FACTOR	16
+static unsigned int max_scanning_factor	= DEFAULT_MAX_SCANNING_FACTOR;
+
 #ifdef CONFIG_NUMA
 /* Zeroed when merging across nodes is not allowed */
 static unsigned int ksm_merge_across_nodes = 1;
@@ -2021,6 +2040,8 @@ static void stable_tree_append(struct rmap_item *rmap_item,
 	rmap_item->address |= STABLE_FLAG;
 	hlist_add_head(&rmap_item->hlist, &stable_node->hlist);
 
+	ksm_scan.new_ksmpages++;
+
 	if (rmap_item->hlist.next)
 		ksm_pages_sharing++;
 	else
@@ -2412,6 +2433,41 @@ static int ksmd_should_run(void)
 	return 0;
 }
 
+/*
+ * Work in auto mode, the scan-enhanced algorithm.
+ * current_factor: the current scanning_factor.
+ * return: the scanning_factor caculated by scan-enhanced algorithm.
+ */
+static unsigned int scan_enhanced_algorithm(unsigned int current_factor)
+{
+	unsigned int next_factor;
+	unsigned int max, min;
+
+	/*
+	 * The calculation is divied into three cases as follows:
+	 *
+	 * Case 1: when new_ksmpages > prev_ksmpages * 1/2, get the
+	 *         next factor by double the current factor.
+	 * Case 2: when 0 < new_ksmpages < prev_ksmpages * 1/2, keep
+	 *         the factor unchanged.
+	 * Case 3: when new_ksmpages equals 0, then get the next
+	 *         factor by halfing the current factor.
+	 */
+	max = READ_ONCE(max_scanning_factor);
+	min = INIT_SCANNING_FACTOR;
+	if (ksm_scan.new_ksmpages * 2 > ksm_scan.prev_ksmpages) {
+		next_factor = current_factor << 1; /* Doubling */
+		if (next_factor > max)
+			next_factor = max;
+	} else if (ksm_scan.new_ksmpages == 0) {
+		next_factor = current_factor >> 1; /* Halfing */
+		next_factor = next_factor < min ? min : next_factor;
+	} else
+		next_factor = current_factor;
+
+	return next_factor;
+}
+
 static int ksm_scan_thread(void *nothing)
 {
 	unsigned int sleep_ms;
@@ -2422,8 +2478,19 @@ static int ksm_scan_thread(void *nothing)
 	while (!kthread_should_stop()) {
 		mutex_lock(&ksm_thread_mutex);
 		wait_while_offlining();
-		if (ksmd_should_run())
-			ksm_do_scan(ksm_thread_pages_to_scan);
+		if (ksmd_should_run()) {
+			if (ksm_run & KSM_RUN_AUTO) {
+				ksm_do_scan(ksm_thread_pages_to_scan * scanning_factor);
+
+				scanning_factor = scan_enhanced_algorithm(scanning_factor);
+				/*
+				 * Reset ksm_scan.new_ksmpages after
+				 * updating scanning_factor by scan_enhanced_algorithm.
+				 */
+				ksm_scan.new_ksmpages = 0;
+			} else
+				ksm_do_scan(ksm_thread_pages_to_scan);
+		}
 		mutex_unlock(&ksm_thread_mutex);
 
 		try_to_freeze();
@@ -2918,6 +2985,34 @@ static ssize_t pages_to_scan_store(struct kobject *kobj,
 }
 KSM_ATTR(pages_to_scan);
 
+static ssize_t max_scanning_factor_show(struct kobject *kobj,
+						struct kobj_attribute *attr, char *buf)
+{
+	return sysfs_emit(buf, "%u\n", max_scanning_factor);
+}
+
+static ssize_t max_scanning_factor_store(struct kobject *kobj,
+								struct kobj_attribute *attr,
+								const char *buf, size_t count)
+{
+		unsigned int value, max;
+		int err;
+
+		err = kstrtouint(buf, 10, &value);
+		if (err)
+			return -EINVAL;
+
+		max = totalram_pages() / ksm_thread_pages_to_scan;
+
+		if (value < 1 && value > max)
+			return -EINVAL;
+
+		max_scanning_factor = value;
+
+		return count;
+}
+KSM_ATTR(max_scanning_factor);
+
 static ssize_t run_show(struct kobject *kobj, struct kobj_attribute *attr,
 			char *buf)
 {
@@ -3175,6 +3270,7 @@ KSM_ATTR_RO(full_scans);
 static struct attribute *ksm_attrs[] = {
 	&sleep_millisecs_attr.attr,
 	&pages_to_scan_attr.attr,
+	&max_scanning_factor_attr.attr,
 	&run_attr.attr,
 	&pages_shared_attr.attr,
 	&pages_sharing_attr.attr,
-- 
2.37.1.377.g679aad9e82


From 8ca6ccb33987fbca03731547d8a3e97e46442efa Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 12 Aug 2022 10:12:12 +0000
Subject: [PATCH 09/12] ksm: let ksmd auto-work with memory threshold

When memory is sufficient, merging pages to save memory is not very
much needed, and it also inceases delays of COW for user application.

So set a memory threshold, when free memory is lower than the threshold,
ksmd will be triggered to compare and merge pages. And to avoid ping-pong
effect due to the threshold, ksmd needs to try to merge pages until free
memory is larger than (threshold + total_memory * 1/16).

Before free memory is lower than the threshold, ksmd will still scan pages
at a very low speed, to calculate their checksum but not to compare and
merge pages.

        |
        |       ----(Threshold + total_memory/16)--------
        |                              |
------Threshold------                  |
        |                              |
        |_____ksmd try to merge pages__|

We also add a new sysfs klob auto_threshold_percent for user to be able
to tune.

Signed-off-by: xu xin <xu.xin16@zte.com.cn>
Signed-off-by: CGEL <cgel.zte@gmail.com>
---
 mm/ksm.c | 103 +++++++++++++++++++++++++++++++++++++++++++++++++++++--
 1 file changed, 101 insertions(+), 2 deletions(-)

diff --git a/mm/ksm.c b/mm/ksm.c
index 160972fe4..5ee18824c 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -296,6 +296,17 @@ static unsigned int scanning_factor = INIT_SCANNING_FACTOR;
 #define DEFAULT_MAX_SCANNING_FACTOR	16
 static unsigned int max_scanning_factor	= DEFAULT_MAX_SCANNING_FACTOR;
 
+/*
+ * Work in auto mode.
+ * Value: 0~100. Default 20 means "20%". When free memory is lower
+ * than this total memory * ksm_auto_threshold/100, auto_triggered
+ * will be set true.
+ */
+unsigned int ksm_auto_threshold = 20;
+
+/* Work in auto-mode. Whether trigger ksmd to compare and merge pages */
+static bool auto_triggered;
+
 #ifdef CONFIG_NUMA
 /* Zeroed when merging across nodes is not allowed */
 static unsigned int ksm_merge_across_nodes = 1;
@@ -2421,11 +2432,61 @@ static void ksm_do_scan(unsigned int scan_npages)
 		rmap_item = scan_get_next_rmap_item(&page);
 		if (!rmap_item)
 			return;
-		cmp_and_merge_page(page, rmap_item);
+		if (ksm_run & KSM_RUN_AUTO  && !auto_triggered) {
+			/*
+			 * This should happens only when ksm_run is KSM_RUN_AUTO
+			 * and free memory threshold still not reached.
+			 * The reason to calculate it's checksum is to reduce the
+			 * waiting time the rmap_item is added to unstable tree.
+			 */
+			rmap_item->oldchecksum = calc_checksum(page);
+		} else
+			cmp_and_merge_page(page, rmap_item);
+
 		put_page(page);
 	}
 }
 
+#define RIGHT_SHIFT_FOUR_BIT	4
+/* Work in auto mode, should reset auto_triggered ? */
+static bool should_stop_ksmd_to_merge(void)
+{
+	unsigned long total_ram_pages, free_pages;
+	unsigned int threshold;
+
+	total_ram_pages = totalram_pages();
+	free_pages = global_zone_page_state(NR_FREE_PAGES);
+	threshold = READ_ONCE(ksm_auto_threshold);
+
+	return free_pages > (total_ram_pages * threshold / 100) +
+		        (total_ram_pages >> RIGHT_SHIFT_FOUR_BIT);
+}
+
+/* Work in auto mode, should ksmd start to merge ? */
+static bool should_trigger_ksmd_to_merge(void)
+{
+	unsigned long total_ram_pages, free_pages;
+	unsigned int threshold;
+
+	total_ram_pages = totalram_pages();
+	free_pages = global_zone_page_state(NR_FREE_PAGES);
+	threshold = READ_ONCE(ksm_auto_threshold);
+
+	return free_pages < (total_ram_pages * threshold / 100);
+}
+
+static inline void trigger_ksmd_to_merge(void)
+{
+	if (!auto_triggered)
+		auto_triggered = true;
+}
+
+static inline void stop_ksmd_to_merge(void)
+{
+	if (auto_triggered)
+		auto_triggered = false;
+}
+
 static int ksmd_should_run(void)
 {
 	if (!list_empty(&ksm_mm_head.mm_list))
@@ -2468,6 +2529,8 @@ static unsigned int scan_enhanced_algorithm(unsigned int current_factor)
 	return next_factor;
 }
 
+#define SLOW_SCAN_PAGES	5 /* Used when ksmd is not triggered to merge*/
+
 static int ksm_scan_thread(void *nothing)
 {
 	unsigned int sleep_ms;
@@ -2480,7 +2543,10 @@ static int ksm_scan_thread(void *nothing)
 		wait_while_offlining();
 		if (ksmd_should_run()) {
 			if (ksm_run & KSM_RUN_AUTO) {
-				ksm_do_scan(ksm_thread_pages_to_scan * scanning_factor);
+				if (!auto_triggered)
+					ksm_do_scan(SLOW_SCAN_PAGES);
+				else
+					ksm_do_scan(ksm_thread_pages_to_scan * scanning_factor);
 
 				scanning_factor = scan_enhanced_algorithm(scanning_factor);
 				/*
@@ -2488,6 +2554,11 @@ static int ksm_scan_thread(void *nothing)
 				 * updating scanning_factor by scan_enhanced_algorithm.
 				 */
 				ksm_scan.new_ksmpages = 0;
+
+				if (should_trigger_ksmd_to_merge())
+					trigger_ksmd_to_merge();
+				else if (should_stop_ksmd_to_merge())
+					stop_ksmd_to_merge();
 			} else
 				ksm_do_scan(ksm_thread_pages_to_scan);
 		}
@@ -3061,6 +3132,32 @@ static ssize_t run_store(struct kobject *kobj, struct kobj_attribute *attr,
 }
 KSM_ATTR(run);
 
+static ssize_t auto_threshold_show(struct kobject *kobj,
+						struct kobj_attribute *attr, char *buf)
+{
+	return sysfs_emit(buf, "%u\n", ksm_auto_threshold);
+}
+
+static ssize_t auto_threshold_store(struct kobject *kobj,
+								struct kobj_attribute *attr,
+								const char *buf, size_t count)
+{
+	unsigned int value;
+	int err;
+
+	err = kstrtouint(buf, 10, &value);
+	if (err)
+		return -EINVAL;
+
+	if (value > 100)
+		return -EINVAL;
+
+	ksm_auto_threshold = value;
+
+	return count;
+}
+KSM_ATTR(auto_threshold);
+
 #ifdef CONFIG_NUMA
 static ssize_t merge_across_nodes_show(struct kobject *kobj,
 				       struct kobj_attribute *attr, char *buf)
@@ -3272,6 +3369,7 @@ static struct attribute *ksm_attrs[] = {
 	&pages_to_scan_attr.attr,
 	&max_scanning_factor_attr.attr,
 	&run_attr.attr,
+	&auto_threshold_attr.attr,
 	&pages_shared_attr.attr,
 	&pages_sharing_attr.attr,
 	&pages_unshared_attr.attr,
@@ -3303,6 +3401,7 @@ static int __init ksm_init(void)
 	zero_checksum = calc_checksum(ZERO_PAGE(0));
 	/* Default to false for backwards compatibility */
 	ksm_use_zero_pages = false;
+	auto_triggered = false;
 
 	err = ksm_slab_init();
 	if (err)
-- 
2.37.1.377.g679aad9e82


From a37246e1a3aeb1217a96254acc6c3ef4718216a9 Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 12 Aug 2022 10:12:23 +0000
Subject: [PATCH 10/12] ksm: show ksmd status for auto mode

Add a sysfs interface of ksmd_status to show some details related
with auto-mode.

Signed-off-by: xu xin <xu.xin16@zte.com.cn>
Signed-off-by: CGEL <cgel.zte@gmail.com>
---
 mm/ksm.c | 42 +++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 41 insertions(+), 1 deletion(-)

diff --git a/mm/ksm.c b/mm/ksm.c
index 5ee18824c..d41733556 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -307,6 +307,9 @@ unsigned int ksm_auto_threshold = 20;
 /* Work in auto-mode. Whether trigger ksmd to compare and merge pages */
 static bool auto_triggered;
 
+/* Count of times that ksmd is triggered due to low free memory */
+static unsigned long triggered_times;
+
 #ifdef CONFIG_NUMA
 /* Zeroed when merging across nodes is not allowed */
 static unsigned int ksm_merge_across_nodes = 1;
@@ -2477,8 +2480,10 @@ static bool should_trigger_ksmd_to_merge(void)
 
 static inline void trigger_ksmd_to_merge(void)
 {
-	if (!auto_triggered)
+	if (!auto_triggered) {
+		triggered_times++;
 		auto_triggered = true;
+	}
 }
 
 static inline void stop_ksmd_to_merge(void)
@@ -3132,6 +3137,40 @@ static ssize_t run_store(struct kobject *kobj, struct kobj_attribute *attr,
 }
 KSM_ATTR(run);
 
+static ssize_t ksmd_status_show(struct kobject *kobj,
+				struct kobj_attribute *attr, char *buf)
+{
+	int len = 0;
+	unsigned int mergeable_mms = 0;
+	struct list_head *pos;
+
+	list_for_each(pos, &ksm_mm_head.mm_list)
+		mergeable_mms++;
+
+	if (ksm_run & KSM_RUN_AUTO) {
+		len += sysfs_emit_at(buf, len, "mode: auto\n");
+		len += sysfs_emit_at(buf, len, "auto_triggered: %d\n",
+						      auto_triggered);
+		len += sysfs_emit_at(buf, len, "mergeable_mms: %u\n",
+						       mergeable_mms);
+		len += sysfs_emit_at(buf, len, "scanning_factor: %u\n",
+						       scanning_factor);
+		len += sysfs_emit_at(buf, len, "triggered_times: %lu\n",
+						       triggered_times);
+	} else if (ksm_run & KSM_RUN_MERGE) {
+		len += sysfs_emit_at(buf, len, "mode: on\n");
+		len += sysfs_emit_at(buf, len, "mergeable_mms: %u\n",
+							mergeable_mms);
+	} else if (ksm_run & KSM_RUN_UNMERGE)
+		len += sysfs_emit_at(buf, len, "mode: unmerge\n");
+	else
+		len += sysfs_emit_at(buf, len, "mode: off\n");
+
+
+	return len;
+}
+KSM_ATTR_RO(ksmd_status);
+
 static ssize_t auto_threshold_show(struct kobject *kobj,
 						struct kobj_attribute *attr, char *buf)
 {
@@ -3369,6 +3408,7 @@ static struct attribute *ksm_attrs[] = {
 	&pages_to_scan_attr.attr,
 	&max_scanning_factor_attr.attr,
 	&run_attr.attr,
+	&ksmd_status_attr.attr,
 	&auto_threshold_attr.attr,
 	&pages_shared_attr.attr,
 	&pages_sharing_attr.attr,
-- 
2.37.1.377.g679aad9e82


From b3df5af0b10b20d37781304919b9eedcd892aa2d Mon Sep 17 00:00:00 2001
From: xu xin <xu.xin16@zte.com.cn>
Date: Fri, 12 Aug 2022 10:12:33 +0000
Subject: [PATCH 11/12] ksm: add tests of ksm auto mode

Add tests to verify the effectiveness and cpu consumption of auto
mode of KSM. The tests requires no other MERGEABLE-madvised vm areas
in system than the areas our testing process allocs.

Signed-off-by: xu xin <xu.xin16@zte.com.cn>
Signed-off-by: CGEL <cgel.zte@gmail.com>
---
 tools/testing/selftests/vm/.gitignore      |   1 +
 tools/testing/selftests/vm/Makefile        |   1 +
 tools/testing/selftests/vm/test-ksm-auto.c | 273 +++++++++++++++++++++
 3 files changed, 275 insertions(+)
 create mode 100644 tools/testing/selftests/vm/test-ksm-auto.c

diff --git a/tools/testing/selftests/vm/.gitignore b/tools/testing/selftests/vm/.gitignore
index 31e5eea2a..1cd8816c0 100644
--- a/tools/testing/selftests/vm/.gitignore
+++ b/tools/testing/selftests/vm/.gitignore
@@ -34,3 +34,4 @@ local_config.*
 soft-dirty
 split_huge_page_test
 ksm_tests
+test-ksm-auto
diff --git a/tools/testing/selftests/vm/Makefile b/tools/testing/selftests/vm/Makefile
index 44f25acfb..ca8a0331c 100644
--- a/tools/testing/selftests/vm/Makefile
+++ b/tools/testing/selftests/vm/Makefile
@@ -54,6 +54,7 @@ TEST_GEN_FILES += userfaultfd
 TEST_GEN_PROGS += soft-dirty
 TEST_GEN_PROGS += split_huge_page_test
 TEST_GEN_FILES += ksm_tests
+TEST_GEN_FILES += test-ksm-auto
 
 ifeq ($(MACHINE),x86_64)
 CAN_BUILD_I386 := $(shell ./../x86/check_cc.sh "$(CC)" ../x86/trivial_32bit_program.c -m32)
diff --git a/tools/testing/selftests/vm/test-ksm-auto.c b/tools/testing/selftests/vm/test-ksm-auto.c
new file mode 100644
index 000000000..0d71593e0
--- /dev/null
+++ b/tools/testing/selftests/vm/test-ksm-auto.c
@@ -0,0 +1,273 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <errno.h>
+#include <fcntl.h>
+#include <signal.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <ucontext.h>
+#include <sys/time.h>
+#include <sys/mman.h>
+
+#define KSM_CLEAR_MODE  "2\n"
+#define KSM_NORMAL_MODE "1\n"
+#define KSM_AUTO_MODE   "8\n"
+
+#define PAGESIZE	(4*1024)
+/* Don't change the value, it will afffect the result */
+#define TOTAL_MADVISE_SIZE	(300*1024*1024)
+
+char *ksm_run_file = "/sys/kernel/mm/ksm/run";
+char *ksm_auto_threshold_file = "/sys/kernel/mm/ksm/auto_threshold";
+char *ksm_pages_volatile_file = "/sys/kernel/mm/ksm/pages_volatile";
+char *ksm_pages_sharing_file = "/sys/kernel/mm/ksm/pages_sharing";
+
+#define SHAPE_FULL          1
+#define SHAPE_SPARSE        2
+/* They are related to the shape of memory */
+int final_pages[3] = {0, 76500, 42};
+
+static char *mmap_and_madvise(long long size, int advise)
+{
+	char *ptr;
+	int err;
+
+	err = 0;
+
+	ptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);
+	if (!ptr)
+		return NULL;
+
+	err = madvise(ptr, size, advise);
+	if (err) {
+		perror("Madvise failed\n");
+		free(ptr);
+		return NULL;
+	}
+
+	return ptr;
+}
+
+void make_samepage_ares(char *ptr, int size, int shape_type)
+{
+	int i, j;
+	char rnd_num;
+
+	switch (shape_type) {
+	case SHAPE_FULL:
+		for (i = 0; i < (size / PAGESIZE); i++)
+			memset(ptr + (i * PAGESIZE), 0x1, PAGESIZE);
+		break;
+	case SHAPE_SPARSE:
+		/* Make pages different */
+		j = 0;
+		for (i = 1; i < (size / PAGESIZE); i++) {
+			ptr[i * PAGESIZE + (j%PAGESIZE)] = j%127 + 1;
+			j++;
+		}
+		for (i = 0; i < (size / PAGESIZE); i += 1800)
+			memset(ptr + (i * PAGESIZE), -1, PAGESIZE);
+	}
+
+	return;
+}
+
+int read_file(char *file, char *buffer, int buf_len)
+{
+	FILE *fp;
+	size_t result;
+	long lSize;
+
+	fp = fopen(file, "r");
+	if (!fp)
+		return -1;
+
+	fseek(fp, 0, SEEK_END);
+	lSize = ftell(fp);
+	rewind(fp);
+
+	memset(buffer, 0, buf_len);
+	result = fread(buffer, 1, buf_len, fp);
+	if (result == 0)
+		return -1;
+
+	fclose(fp);
+
+	return 0;
+}
+
+int write_file(char *file, const char *buffer, int len)
+{
+	FILE *fp;
+	size_t result;
+
+	fp = fopen(file, "w+");
+	if (!fp)
+		return -1;
+
+	result = fwrite(buffer, len, 1, fp);
+	if (result == 0)
+		return -1;
+
+	fclose(fp);
+
+	return 0;
+}
+
+static inline void get_orig_info(int *run, int *auto_threshold)
+{
+	char buffer[50];
+
+	/* Read the original state of ksm/run */
+	if (read_file(ksm_run_file, buffer, sizeof(buffer))) {
+		printf("read file %s failed\n", ksm_run_file);
+		exit(1);
+	}
+	*run = atoi(buffer);
+
+	if (read_file(ksm_auto_threshold_file, buffer, sizeof(buffer))) {
+		printf("read file: %s failed\n", ksm_auto_threshold_file);
+		exit(1);
+	}
+	*auto_threshold = atoi(buffer);
+}
+
+static inline void restore_orig_state(int run, int auto_threshold)
+{
+	char buffer[50];
+
+	/* restore the original state */
+	memset(buffer, 0, sizeof(buffer));
+	snprintf(buffer, sizeof(buffer) - 1, "%d\n", run);
+	if (write_file(ksm_run_file, buffer, sizeof(buffer))) {
+		printf("write file %s failed\n", ksm_run_file);
+		exit(1);
+	}
+
+	memset(buffer, 0, sizeof(buffer));
+	snprintf(buffer, sizeof(buffer) - 1, "%d\n", auto_threshold);
+	if (write_file(ksm_auto_threshold_file, buffer, sizeof(buffer))) {
+		printf("write file %s failed\n", ksm_run_file);
+		exit(1);
+	}
+}
+
+void set_ksmd_run_mode(char *mode)
+{
+	if (write_file(ksm_run_file, mode, 2)) {
+		printf("Failed: write 1 to %s\n", ksm_auto_threshold_file);
+		exit(1);
+	}
+}
+
+static inline void wait_ksmpages_converged(int final_pages)
+{
+	int pages_sharing;
+	char buffer[50];
+
+	for (;;) {
+		if (read_file(ksm_pages_sharing_file, buffer, sizeof(buffer))) {
+			printf("read file %s failed\n", ksm_pages_sharing_file);
+			exit(1);
+		}
+
+		pages_sharing = atoi(buffer);
+		if (pages_sharing >= final_pages)
+			break;
+	}
+}
+
+void print_shape(int shape_type)
+{
+	switch (shape_type) {
+	case SHAPE_FULL:
+		printf("Now the shape of memory area is full-samepages:\n");
+		printf("[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]\n\n");
+		break;
+	case SHAPE_SPARSE:
+		printf("Now the shape of memory area is sparse-samepages:\n");
+		printf("[xx]          [xx]          [xx]   \n\n");
+		break;
+	}
+}
+
+void print_ksmd_cpu_comsuption(void)
+{
+	system("(ps x| grep \"ksmd\" | grep -v grep | awk \'{print $1}\' |"
+	       " xargs -i cat /proc/{}/stat) | awk \'{print \"ksm current "
+		   "cpu total slice: \"  $14+$15+$16+$17}\'");
+}
+
+void test_ksmd_performance(char *madvise_area, int shape_type)
+{
+	struct timeval tv_start, tv_end;
+
+	make_samepage_ares(madvise_area, TOTAL_MADVISE_SIZE, shape_type);
+	print_shape(shape_type);
+
+	/********* Start to time ksmd's normal-run mode **********/
+	printf("Start to test normal-run ksmd...\n");
+
+	print_ksmd_cpu_comsuption();
+
+	set_ksmd_run_mode(KSM_CLEAR_MODE);
+	set_ksmd_run_mode(KSM_NORMAL_MODE);
+
+	gettimeofday(&tv_start, NULL);
+
+	wait_ksmpages_converged(final_pages[shape_type]);
+
+	gettimeofday(&tv_end, NULL);
+	printf("ksm normal-run's merging time: %lf seconds\n",
+	       ((tv_end.tv_sec * 1000000 + tv_end.tv_usec) -
+	       (tv_start.tv_sec * 1000000 + tv_start.tv_usec))/1000000.0);
+
+	/******* Start to time ksmd's auto-run mode **********/
+	print_ksmd_cpu_comsuption();
+
+	printf("Start to test auto-run ksmd...\n");
+	set_ksmd_run_mode(KSM_CLEAR_MODE);
+	set_ksmd_run_mode(KSM_AUTO_MODE);
+	if (write_file(ksm_auto_threshold_file, "99\n", 2))
+		printf("Failed: write 1 to %s\n", ksm_auto_threshold_file);
+
+	gettimeofday(&tv_start, NULL);
+
+	wait_ksmpages_converged(shape_type);
+
+	gettimeofday(&tv_end, NULL);
+	printf("ksm auto-run's merging time: %lf seconds\n",
+		((tv_end.tv_sec * 1000000 + tv_end.tv_usec) -
+		(tv_start.tv_sec * 1000000 + tv_start.tv_usec))/1000000.0);
+
+	print_ksmd_cpu_comsuption();
+}
+
+int main(int argc, char **argv)
+{
+	char *madvise_area;
+	int orig_run, orig_auto_threshold;
+
+	/* Get the original state of ksm */
+	get_orig_info(&orig_run, &orig_auto_threshold);
+	printf("Now we mmap 300MB anouymous memory for testing.\n"
+		"There are two type of TEST which have different shape of\n"
+		"samepage areas.\n"
+		"Note: the test requires no other MERGEABLE-madvised vm areas\n"
+		"in system than the areas our testing process allocs.\n");
+	madvise_area = mmap_and_madvise(TOTAL_MADVISE_SIZE, MADV_MERGEABLE);
+	if (!madvise_area) {
+		printf("madvise failed\n");
+		exit(1);
+	}
+
+	printf("\n****************** TEST 1 ******************\n");
+	test_ksmd_performance(madvise_area, SHAPE_FULL);
+	printf("\n****************** TEST 2 ******************\n");
+	test_ksmd_performance(madvise_area, SHAPE_SPARSE);
+
+	/* Restore the original state */
+	restore_orig_state(orig_run, orig_auto_threshold);
+
+	return 0;
+}
-- 
2.37.1.377.g679aad9e82


From f704cb44fc956468eef4e684a9cfa2a08fd9b15b Mon Sep 17 00:00:00 2001
From: xu xin <cgel.zte@gmail.com>
Date: Mon, 22 Aug 2022 05:36:53 +0000
Subject: [PATCH 12/12] ksm: count allocated ksm rmap_items for each process
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

KSM can save memory by merging identical pages, but also can consume
additional memory, because it needs to generate rmap_items to save
each scanned page's brief rmap information. Some of these pages may
be merged, but some may not be abled to be merged after being checked
several times, which are unprofitable memory consumed.

The information about whether KSM save memory or consume memory in
system-wide range can be determined by the comprehensive calculation
of pages_sharing, pages_shared, pages_unshared and pages_volatile.
A simple approximate calculation:

	profit ≈ pages_sharing * sizeof(page) - (all_rmap_items) *
	         sizeof(rmap_item);

where all_rmap_items equals to the sum of pages_sharing, pages_shared,
pages_unshared and pages_volatile.

But we cannot calculate this kind of ksm profit inner single-process wide
because the information of ksm rmap_item's number of a process is lacked.
For user applications, if this kind of information could be obtained,
it helps upper users know how beneficial the ksm-policy (like madvise)
they are using brings, and then optimize their app code. For example,
one application madvise 1000 pages as MERGEABLE, while only a few pages
are really merged, then it's not cost-efficient.

So we add a new interface /proc/<pid>/ksm_alloced_items for each
process to indicate the total allocated ksm rmap_items of this process.

Signed-off-by: xu xin <xu.xin16@zte.com.cn>
Reviewed-by: Xiaokai Ran <ran.xiaokai@zte.com.cn>
Reviewed-by: Yang Yang <yang.yang29@zte.com.cn>
Signed-off-by: CGEL ZTE <cgel.zte@gmail.com>
---
 fs/proc/base.c           | 15 +++++++++++++++
 include/linux/mm_types.h |  5 +++++
 mm/ksm.c                 |  2 ++
 3 files changed, 22 insertions(+)

diff --git a/fs/proc/base.c b/fs/proc/base.c
index 93f7e3d97..b63179814 100644
--- a/fs/proc/base.c
+++ b/fs/proc/base.c
@@ -3196,6 +3196,19 @@ static int proc_pid_ksm_merging_pages(struct seq_file *m, struct pid_namespace *
 
 	return 0;
 }
+static int proc_pid_ksm_rmp_items(struct seq_file *m, struct pid_namespace *ns,
+				struct pid *pid, struct task_struct *task)
+{
+	struct mm_struct *mm;
+
+	mm = get_task_mm(task);
+	if (mm) {
+		seq_printf(m, "%lu\n", mm->ksm_rmp_items);
+		mmput(mm);
+	}
+
+	return 0;
+}
 #endif /* CONFIG_KSM */
 
 #ifdef CONFIG_STACKLEAK_METRICS
@@ -3331,6 +3344,7 @@ static const struct pid_entry tgid_base_stuff[] = {
 #endif
 #ifdef CONFIG_KSM
 	ONE("ksm_merging_pages",  S_IRUSR, proc_pid_ksm_merging_pages),
+	ONE("ksm_rmp_items",  S_IRUSR, proc_pid_ksm_rmp_items),
 #endif
 };
 
@@ -3668,6 +3682,7 @@ static const struct pid_entry tid_base_stuff[] = {
 #endif
 #ifdef CONFIG_KSM
 	ONE("ksm_merging_pages",  S_IRUSR, proc_pid_ksm_merging_pages),
+	ONE("ksm_rmp_items",  S_IRUSR, proc_pid_ksm_rmp_items),
 #endif
 };
 
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index c29ab4c0c..a0a55cfeb 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -666,6 +666,11 @@ struct mm_struct {
 		 * merging.
 		 */
 		unsigned long ksm_merging_pages;
+		/*
+		 * Represent how many pages are checked for ksm merging
+		 * including merged and not merged.
+		 */
+		unsigned long ksm_rmp_items;
 #endif
 	} __randomize_layout;
 
diff --git a/mm/ksm.c b/mm/ksm.c
index d41733556..05fcefc82 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -421,6 +421,7 @@ static inline struct rmap_item *alloc_rmap_item(void)
 static inline void free_rmap_item(struct rmap_item *rmap_item)
 {
 	ksm_rmap_items--;
+	rmap_item->mm->ksm_rmp_items--;
 	rmap_item->mm = NULL;	/* debug safety */
 	kmem_cache_free(rmap_item_cache, rmap_item);
 }
@@ -2255,6 +2256,7 @@ static struct rmap_item *get_next_rmap_item(struct mm_slot *mm_slot,
 	if (rmap_item) {
 		/* It has already been zeroed */
 		rmap_item->mm = mm_slot->mm;
+		rmap_item->mm->ksm_rmp_items++;
 		rmap_item->address = addr;
 		rmap_item->rmap_list = *rmap_list;
 		*rmap_list = rmap_item;
-- 
2.37.1.377.g679aad9e82

