From ec95319dce2e1f86115530aec71102a427080bef Mon Sep 17 00:00:00 2001
From: Paolo Valente <paolo.valente@linaro.org>
Date: Mon, 18 Jan 2021 11:44:07 +0100
Subject: [PATCH 27/29] block, bfq, DEBUG: logs and BUG_ONs for stable merging

Signed-off-by: Paolo Valente <paolo.valente@linaro.org>
---
 block/bfq-iosched.c | 129 ++++++++++++++++++++++++++++++++++++++++----
 1 file changed, 118 insertions(+), 11 deletions(-)

diff --git a/block/bfq-iosched.c b/block/bfq-iosched.c
index 378718c60..ea933016c 100644
--- a/block/bfq-iosched.c
+++ b/block/bfq-iosched.c
@@ -1099,6 +1099,8 @@ bfq_bfqq_resume_state(struct bfq_queue *bfqq, struct bfq_data *bfqd,
 	bfqq->inject_limit = bic->saved_inject_limit;
 	bfqq->decrease_time_jif = bic->saved_decrease_time_jif;
 
+	BFQ_BUG_ON(bic->saved_weight == 0);
+
 	bfqq->entity.new_weight = bic->saved_weight;
 	bfqq->ttime = bic->saved_ttime;
 	bfqq->io_start_time = bic->saved_io_start_time;
@@ -2987,6 +2989,8 @@ bfq_setup_cooperator(struct bfq_data *bfqd, struct bfq_queue *bfqq,
 {
 	struct bfq_queue *in_service_bfqq, *new_bfqq;
 
+	BFQ_BUG_ON(!bic);
+
 	/*
 	 * Check delayed stable merge for rotational or non-queueing
 	 * devs. For this branch to be executed, bfqq must not be
@@ -3006,9 +3010,16 @@ bfq_setup_cooperator(struct bfq_data *bfqd, struct bfq_queue *bfqq,
 			int proc_ref = min(bfqq_process_refs(bfqq),
 					   bfqq_process_refs(stable_merge_bfqq));
 
+			bfq_log_bfqq(bfqd, bfqq,
+				     "checking late stable merging");
+
+			BFQ_BUG_ON(stable_merge_bfqq->ref < 1 + proc_ref);
 			/* deschedule stable merge, because done or aborted here */
 			bfq_put_stable_ref(stable_merge_bfqq);
 
+			BFQ_BUG_ON(proc_ref > 0 &&
+				   bfqq_process_refs(stable_merge_bfqq) < proc_ref);
+
 			bic->stable_merge_bfqq = NULL;
 
 			if (!idling_boosts_thr_without_issues(bfqd, bfqq) &&
@@ -3017,12 +3028,23 @@ bfq_setup_cooperator(struct bfq_data *bfqd, struct bfq_queue *bfqq,
 				struct bfq_queue *new_bfqq =
 					bfq_setup_merge(bfqq, stable_merge_bfqq);
 
+				if (!new_bfqq)
+					bfq_log_bfqq(bfqd, bfqq,
+					     "merging already occurred");
+				else
+					bfq_log_bfqq(bfqd, bfqq,
+						     "late stable merging with %p",
+						     new_bfqq);
+
 				bic->stably_merged = true;
 				if (new_bfqq && new_bfqq->bic)
 					new_bfqq->bic->stably_merged = true;
 				return new_bfqq;
-			} else
+			} else {
+				bfq_log_bfqq(bfqd, bfqq,
+					     "no late stable merging");
 				return NULL;
+			}
 		}
 	}
 
@@ -3139,6 +3161,7 @@ static void bfq_bfqq_save_state(struct bfq_queue *bfqq)
 	bic->saved_decrease_time_jif = bfqq->decrease_time_jif;
 
 	bic->saved_weight = bfqq->entity.orig_weight;
+	BFQ_BUG_ON(bic->saved_weight == 0);
 	bic->saved_ttime = bfqq->ttime;
 	bic->saved_has_short_ttime = bfq_bfqq_has_short_ttime(bfqq);
 	bic->saved_IO_bound = bfq_bfqq_IO_bound(bfqq);
@@ -3170,6 +3193,7 @@ static void bfq_bfqq_save_state(struct bfq_queue *bfqq)
 		bic->saved_last_wr_start_finish = bfqq->last_wr_start_finish;
 		bic->saved_wr_cur_max_time = bfqq->wr_cur_max_time;
 	}
+
 	BFQ_BUG_ON(time_is_after_jiffies(bfqq->last_wr_start_finish));
 	bfq_log_bfqq(bfqq->bfqd, bfqq,
 		     "bic %p wr_coeff %d start_finish %lu max_time %lu",
@@ -3328,6 +3352,7 @@ bfq_merge_bfqqs(struct bfq_data *bfqd, struct bfq_io_cq *bic,
 	bfqq->bic = NULL;
 
 	bfq_reassign_last_bfqq(bfqq, new_bfqq);
+
 	/*
 	 * move task_list_node from its current list to that of new_bfqq
 	 */
@@ -5674,14 +5699,12 @@ static struct request *bfq_dispatch_request(struct blk_mq_hw_ctx *hctx)
  * Scheduler lock must be held here. Recall not to use bfqq after calling
  * this function on it.
  */
-void bfq_put_queue(struct bfq_queue *bfqq)
+void __bfq_put_queue(struct bfq_queue *bfqq)
 {
 	struct bfq_queue *item;
 	struct hlist_node *n;
 	struct bfq_group *bfqg = bfqq_group(bfqq);
 
-	assert_spin_locked(&bfqq->bfqd->lock);
-
 	BFQ_BUG_ON(bfqq->ref <= 0);
 
 	if (bfqq->bfqd)
@@ -5773,8 +5796,23 @@ void bfq_put_queue(struct bfq_queue *bfqq)
 
 static void bfq_put_stable_ref(struct bfq_queue *bfqq)
 {
+	BFQ_BUG_ON(bfqq->stable_ref <= 0);
 	bfqq->stable_ref--;
-	bfq_put_queue(bfqq);
+	__bfq_put_queue(bfqq);
+}
+
+/*
+ * Task holds one reference to the queue, dropped when task exits.  Each rq
+ * in-flight on this queue also holds a reference, dropped when rq is freed.
+ *
+ * Scheduler lock must be held here. Recall not to use bfqq after calling
+ * this function on it.
+ */
+void bfq_put_queue(struct bfq_queue *bfqq)
+{
+	assert_spin_locked(&bfqq->bfqd->lock);
+
+	__bfq_put_queue(bfqq);
 }
 
 static void bfq_put_cooperator(struct bfq_queue *bfqq)
@@ -5840,6 +5878,7 @@ static void bfq_exit_icq(struct io_cq *icq)
 	if (bic->stable_merge_bfqq) {
 		struct bfq_data *bfqd = bic->stable_merge_bfqq->bfqd;
 
+		BFQ_BUG_ON(bic->stable_merge_bfqq == bic_to_bfqq(bic, false));
 		/*
 		 * bfqd is NULL if scheduler already exited, and in
 		 * that case this is the last time bfqq is accessed.
@@ -5848,6 +5887,9 @@ static void bfq_exit_icq(struct io_cq *icq)
 			unsigned long flags;
 
 			spin_lock_irqsave(&bfqd->lock, flags);
+			BFQ_BUG_ON(bic->stable_merge_bfqq ==
+				   bic_to_bfqq(bic, true) &&
+				   bic->stable_merge_bfqq->ref == 1);
 			bfq_put_stable_ref(bic->stable_merge_bfqq);
 			spin_unlock_irqrestore(&bfqd->lock, flags);
 		} else {
@@ -6047,13 +6089,27 @@ bfq_do_early_stable_merge(struct bfq_data *bfqd, struct bfq_queue *bfqq,
 	struct bfq_queue *new_bfqq =
 		bfq_setup_merge(bfqq, last_bfqq_created);
 
-	if (!new_bfqq)
+	if (!new_bfqq) {
+		bfq_log_bfqq(bfqd, bfqq, "no new_bfqq found for stable merging");
 		return bfqq;
+	}
 
 	if (new_bfqq->bic)
 		new_bfqq->bic->stably_merged = true;
 	bic->stably_merged = true;
+	BFQ_BUG_ON(new_bfqq == bfqq);
+
+	bfq_log_bfqq(bfqd, bfqq,
+		     "stably merging %lu + %lu <= %lu",
+		     last_bfqq_created->creation_time,
+		     bfqd->bfq_burst_interval,
+		     bfqq->creation_time);
+	BFQ_BUG_ON(bfqq->entity.weight == 0);
+	BFQ_BUG_ON(new_bfqq->entity.weight == 0);
+	BFQ_BUG_ON(bfqq->entity.new_weight == 0);
+	BFQ_BUG_ON(new_bfqq->entity.new_weight == 0);
 
+	BFQ_BUG_ON(bfqq->ref != 1);
 	/*
 	 * Reusing merge functions. This implies that
 	 * bfqq->bic must be set too, for
@@ -6063,6 +6119,12 @@ bfq_do_early_stable_merge(struct bfq_data *bfqd, struct bfq_queue *bfqq,
 	bfqq->bic = bic;
 	bfq_merge_bfqqs(bfqd, bic, bfqq, new_bfqq);
 
+	BFQ_BUG_ON(bic->saved_weight == 0);
+	BFQ_BUG_ON(new_bfqq->entity.weight == 0);
+	BFQ_BUG_ON(new_bfqq->entity.new_weight == 0);
+	bfq_log_bfqq(bfqd, new_bfqq,
+		     "stably merged with new queue");
+
 	return new_bfqq;
 }
 
@@ -6147,11 +6209,28 @@ static struct bfq_queue *bfq_do_or_sched_stable_merge(struct bfq_data *bfqd,
 			bfqq->creation_time) ||
 		bfqq->entity.parent != last_bfqq_created->entity.parent ||
 		bfqq->ioprio != last_bfqq_created->ioprio ||
-		bfqq->ioprio_class != last_bfqq_created->ioprio_class)
+		bfqq->ioprio_class != last_bfqq_created->ioprio_class) {
+		if (!last_bfqq_created)
+			bfq_log_bfqq(bfqd, bfqq, "no last bfqq created");
+
+		if (last_bfqq_created &&
+		    !time_after_eq(last_bfqq_created->creation_time +
+				   bfqd->bfq_burst_interval,
+				   bfqq->creation_time))
+			bfq_log_bfqq(bfqd, bfqq,
+				     "not merging stably %d > %d",
+				     jiffies_to_msecs(bfqq->creation_time -
+						      last_bfqq_created->creation_time),
+				     jiffies_to_msecs(bfqd->bfq_burst_interval));
+
 		*source_bfqq = bfqq;
-	else if (time_after_eq(last_bfqq_created->creation_time +
+		bfq_log_bfqq(bfqd, bfqq, "set as last bfqq created %lu",
+			     bfqq->creation_time);
+	} else if (time_after_eq(last_bfqq_created->creation_time +
 				 bfqd->bfq_burst_interval,
 				 bfqq->creation_time)) {
+		BFQ_BUG_ON(last_bfqq_created == bic_to_bfqq(bic, false));
+
 		if (likely(bfqd->nonrot_with_queueing))
 			/*
 			 * With this type of drive, leaving
@@ -6163,6 +6242,11 @@ static struct bfq_queue *bfq_do_or_sched_stable_merge(struct bfq_data *bfqd,
 							 bic,
 							 last_bfqq_created);
 		else { /* schedule tentative stable merge */
+			BFQ_BUG_ON(last_bfqq_created == bfqq);
+			BFQ_BUG_ON(last_bfqq_created ==
+				   bic_to_bfqq(bic, true));
+			BFQ_BUG_ON(last_bfqq_created ==
+				   bic_to_bfqq(bic, false));
 			/*
 			 * get reference on last_bfqq_created,
 			 * to prevent it from being freed,
@@ -6178,6 +6262,8 @@ static struct bfq_queue *bfq_do_or_sched_stable_merge(struct bfq_data *bfqd,
 			 * Record the bfqq to merge to.
 			 */
 			bic->stable_merge_bfqq = last_bfqq_created;
+			bfq_log_bfqq(bfqd, bfqq, "scheduled stable merge with bfq%d",
+				     bfq_get_first_task_pid(last_bfqq_created));
 		}
 	}
 
@@ -6220,13 +6306,16 @@ static struct bfq_queue *bfq_get_queue(struct bfq_data *bfqd,
 		bfq_init_bfqq(bfqd, bfqq, bic, current->pid,
 			      is_sync);
 		bfq_init_entity(&bfqq->entity, bfqg);
-		bfq_log_bfqq(bfqd, bfqq, "allocated");
+		bfq_log_bfqq(bfqd, bfqq, "allocated at time %lu",
+			     bfqq->creation_time);
 	} else {
 		bfqq = &bfqd->oom_bfqq;
 		bfq_log_bfqq(bfqd, bfqq, "using oom bfqq");
 		goto out;
 	}
 
+	BFQ_BUG_ON(!bfqq);
+
 	/*
 	 * Pin the queue now that it's allocated, scheduler exit will
 	 * prune it.
@@ -6248,8 +6337,13 @@ static struct bfq_queue *bfq_get_queue(struct bfq_data *bfqd,
 	bfqq->proc_ref++; /* get a process reference to this queue */
 	bfqq->ref++; /* get a process reference to this queue */
 
-	if (bfqq != &bfqd->oom_bfqq && is_sync && !respawn)
+	bfq_log_bfqq(bfqd, bfqq, "initial refs: %p, %d", bfqq, bfqq->ref);
+
+	if (bfqq != &bfqd->oom_bfqq && is_sync && !respawn) {
+		BFQ_BUG_ON(bfqq == bic_to_bfqq(bic, false));
+
 		bfqq = bfq_do_or_sched_stable_merge(bfqd, bfqq, bic);
+	}
 
 	bfq_log_bfqq(bfqd, bfqq, "at end: %p, %d", bfqq, bfqq->ref);
 	rcu_read_unlock();
@@ -6519,6 +6613,8 @@ static bool __bfq_insert_request(struct bfq_data *bfqd, struct request *rq)
 						 RQ_BIC(rq));
 	bool waiting, idle_timer_disabled = false;
 	BFQ_BUG_ON(!bfqq);
+	BFQ_BUG_ON(bfqq->entity.weight == 0);
+	BFQ_BUG_ON(bfqq->entity.new_weight == 0);
 	BFQ_BUG_ON(new_bfqq == &bfqd->oom_bfqq);
 
 	assert_spin_locked(&bfqd->lock);
@@ -6642,6 +6738,7 @@ static void bfq_insert_request(struct blk_mq_hw_ctx *hctx, struct request *rq,
 	bfqq = bfq_init_rq(rq);
 	BFQ_BUG_ON(!bfqq && !(at_head || blk_rq_is_passthrough(rq)));
 	BFQ_BUG_ON(bfqq && bic_to_bfqq(RQ_BIC(rq), rq_is_sync(rq)) != bfqq);
+	BFQ_BUG_ON(bfqq->entity.weight == 0);
 
 	/*
 	 * Reqs with at_head or passthrough flags set are to be put
@@ -7281,7 +7378,7 @@ static struct bfq_queue *bfq_get_bfqq_handle_split(struct bfq_data *bfqd,
 		bfq_put_queue(bfqq);
 
 	bfqq = bfq_get_queue(bfqd, bio, is_sync, bic, split);
-	BFQ_BUG_ON(!hlist_unhashed(&bfqq->burst_list_node));
+	BFQ_BUG_ON(split && !hlist_unhashed(&bfqq->burst_list_node));
 
 	bic_set_bfqq(bic, bfqq, is_sync);
 	if (split && is_sync) {
@@ -7416,6 +7513,9 @@ static struct bfq_queue *bfq_init_rq(struct request *rq)
 	bfqq = bfq_get_bfqq_handle_split(bfqd, bic, bio, false, is_sync,
 					 &new_queue);
 
+	BFQ_BUG_ON(bfqq->entity.weight == 0);
+	BFQ_BUG_ON(bfqq->entity.new_weight == 0);
+
 	if (likely(!new_queue)) {
 		/* If the queue was seeky for too long, break it apart. */
 		if (bfq_bfqq_coop(bfqq) && bfq_bfqq_split_coop(bfqq) &&
@@ -7437,6 +7537,9 @@ static struct bfq_queue *bfq_init_rq(struct request *rq)
 				bfqq = bfq_get_bfqq_handle_split(bfqd, bic, bio,
 								 true, is_sync,
 								 NULL);
+				BFQ_BUG_ON(bfqq->entity.weight == 0);
+				BFQ_BUG_ON(bfqq->entity.new_weight == 0);
+
 				bfqq->waker_bfqq = old_bfqq->waker_bfqq;
 				BFQ_BUG_ON(bfqq->waker_bfqq == bfqq);
 				bfqq->tentative_waker_bfqq = NULL;
@@ -7462,6 +7565,8 @@ static struct bfq_queue *bfq_init_rq(struct request *rq)
 				bfqq_already_existing = true;
 
 			BFQ_BUG_ON(!bfqq);
+			BFQ_BUG_ON(bfqq->entity.weight == 0);
+			BFQ_BUG_ON(bfqq->entity.new_weight == 0);
 		}
 	}
 
@@ -7492,6 +7597,8 @@ static struct bfq_queue *bfq_init_rq(struct request *rq)
 			 */
 			bfq_bfqq_resume_state(bfqq, bfqd, bic,
 					      bfqq_already_existing);
+			BFQ_BUG_ON(bfqq->entity.weight == 0);
+			BFQ_BUG_ON(bfqq->entity.new_weight == 0);
 		}
 	}
 
-- 
2.31.1.362.g311531c9de

