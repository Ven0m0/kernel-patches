From ad00569b8da6eff213c95693af93ba20a20bc732 Mon Sep 17 00:00:00 2001
From: Ankur Arora <ankur.a.arora@oracle.com>
Date: Wed, 20 Dec 2023 13:38:40 -0800
Subject: [PATCH 19/30] sched: default preemption policy for PREEMPT_AUTO

Add resched_opt_translate() which determines the particular
need-resched flag based on scheduling policy.

Preemption models other than PREEMPT_AUTO: continue to use
tif_resched(NR_now).

PREEMPT_AUTO:  use tif_resched(NR_lazy) to mark for exit-to-user
by default.

Note that the target task might be running in userspace or in the
kernel. Allow both to run to timeslice completion.

Cc: Ingo Molnar <mingo@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Juri Lelli <juri.lelli@redhat.com>
Cc: Vincent Guittot <vincent.guittot@linaro.org>
Originally-by: Thomas Gleixner <tglx@linutronix.de>
Link: https://lore.kernel.org/lkml/87jzshhexi.ffs@tglx/
Signed-off-by: Ankur Arora <ankur.a.arora@oracle.com>
---
 kernel/sched/core.c  | 31 +++++++++++++++++++++++++------
 kernel/sched/sched.h | 12 +++++++++++-
 2 files changed, 36 insertions(+), 7 deletions(-)

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index ec7ccafaf..0302ae20c 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -1032,20 +1032,39 @@ void wake_up_q(struct wake_q_head *head)
 }
 
 /*
- * resched_curr - mark rq's current task 'to be rescheduled now'.
+ * For preemption models other than PREEMPT_AUTO: always schedule
+ * eagerly.
  *
- * On UP this means the setting of the need_resched flag, on SMP it
- * might also involve a cross-CPU call to trigger the scheduler on
- * the target CPU.
+ * For PREEMPT_AUTO: allow everything, whether running in user or
+ * kernel context, to finish its time quanta, and mark for
+ * rescheduling at the next exit to user.
  */
-void resched_curr(struct rq *rq)
+static resched_t resched_opt_translate(struct task_struct *curr,
+				       enum resched_opt opt)
+{
+	if (!IS_ENABLED(CONFIG_PREEMPT_AUTO))
+		return NR_now;
+
+	return NR_lazy;
+}
+
+/*
+ * __resched_curr - mark rq's current task 'to be rescheduled now'.
+ *
+ * On UP this means the setting of the appropriate need_resched flag.
+ * On SMP, in addition it might also involve a cross-CPU call to
+ * trigger the scheduler on the target CPU.
+ */
+void __resched_curr(struct rq *rq, enum resched_opt opt)
 {
 	struct task_struct *curr = rq->curr;
-	resched_t rs = NR_now;
+	resched_t rs;
 	int cpu;
 
 	lockdep_assert_rq_held(rq);
 
+	rs = resched_opt_translate(curr, opt);
+
 	/*
 	 * TIF_NEED_RESCHED is the higher priority bit, so if it is already
 	 * set, nothing more to be done. So, the only combinations we want to
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index ed656a4c5..d6fe7449c 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -2462,7 +2462,17 @@ extern void init_sched_fair_class(void);
 
 extern void reweight_task(struct task_struct *p, int prio);
 
-extern void resched_curr(struct rq *rq);
+enum resched_opt {
+	RESCHED_DEFAULT,
+};
+
+extern void __resched_curr(struct rq *rq, enum resched_opt opt);
+
+static inline void resched_curr(struct rq *rq)
+{
+	__resched_curr(rq, RESCHED_DEFAULT);
+}
+
 extern void resched_cpu(int cpu);
 
 extern struct rt_bandwidth def_rt_bandwidth;
-- 
2.43.0.232.ge79552d197

