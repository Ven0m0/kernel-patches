From 34684d712ffdd561429ed64b7dcf3c127ebd0e2e Mon Sep 17 00:00:00 2001
From: Piotr Gorski <lucjan.lucjanov@gmail.com>
Date: Sun, 16 Oct 2022 12:35:30 +0200
Subject: [PATCH 29/29] lrng-6.0: merge changes from dev tree

Signed-off-by: Piotr Gorski <lucjan.lucjanov@gmail.com>
---
 drivers/char/lrng/Kconfig         |  7 ++++
 drivers/char/lrng/lrng_drng_mgr.c | 70 ++++++++++++++++++++++---------
 drivers/char/lrng/lrng_es_mgr.c   | 41 ++++--------------
 drivers/char/lrng/lrng_es_mgr.h   |  2 +-
 4 files changed, 67 insertions(+), 53 deletions(-)

diff --git a/drivers/char/lrng/Kconfig b/drivers/char/lrng/Kconfig
index 508dc8f48..9d74117bc 100644
--- a/drivers/char/lrng/Kconfig
+++ b/drivers/char/lrng/Kconfig
@@ -890,6 +890,13 @@ config LRNG_RUNTIME_MAX_WO_RESEED_CONFIG
 	  operations without a reseed that has full entropy. The
 	  interface is lrng_drng.max_wo_reseed.
 
+config LRNG_RUNTIME_FORCE_SEEDING_DISABLE
+	bool "Enable runtime configuration of force seeding"
+	help
+	  When enabling this option, the LRNG provides an interface
+	  allowing the disabling of the force seeding when the DRNG
+	  is not fully seeded but entropy is available.
+
 config LRNG_TEST_CPU_ES_COMPRESSION
 	bool "Force CPU ES compression operation"
 	help
diff --git a/drivers/char/lrng/lrng_drng_mgr.c b/drivers/char/lrng/lrng_drng_mgr.c
index c1f743221..8939f1777 100644
--- a/drivers/char/lrng/lrng_drng_mgr.c
+++ b/drivers/char/lrng/lrng_drng_mgr.c
@@ -85,6 +85,13 @@ MODULE_PARM_DESC(max_wo_reseed,
 		 "Maximum number of DRNG generate operation without full reseed\n");
 #endif
 
+static bool force_seeding = true;
+#ifdef CONFIG_LRNG_RUNTIME_FORCE_SEEDING_DISABLE
+module_param(force_seeding, bool, 0444);
+MODULE_PARM_DESC(force_seeding,
+		 "Allow disabling of the forced seeding when insufficient entropy is availabe\n");
+#endif
+
 /* Wait queue to wait until the LRNG is initialized - can freely be used */
 DECLARE_WAIT_QUEUE_HEAD(lrng_init_wait);
 
@@ -118,11 +125,13 @@ struct lrng_drng *lrng_drng_node_instance(void)
 
 void lrng_drng_reset(struct lrng_drng *drng)
 {
-	atomic_set(&drng->requests, LRNG_DRNG_RESEED_THRESH);
+	/* Ensure reseed during next call */
+	atomic_set(&drng->requests, 1);
 	atomic_set(&drng->requests_since_fully_seeded, 0);
 	drng->last_seeded = jiffies;
 	drng->fully_seeded = false;
-	drng->force_reseed = true;
+	/* Do not set force, as this flag is used for the emergency reseeding */
+	drng->force_reseed = false;
 	pr_debug("reset DRNG\n");
 }
 
@@ -248,7 +257,7 @@ static u32 lrng_drng_seed_es_nolock(struct lrng_drng *drng)
 			   collected_seedbuf;
 	u32 collected_entropy = 0;
 	unsigned int i, num_es_delivered = 0;
-	bool force = lrng_state_min_seeded() > LRNG_FORCE_FULLY_SEEDED_ATTEMPT;
+	bool forced = drng->force_reseed;
 
 	for_each_lrng_es(i)
 		collected_seedbuf.e_bits[i] = 0;
@@ -261,7 +270,8 @@ static u32 lrng_drng_seed_es_nolock(struct lrng_drng *drng)
 			pr_debug("Force fully seeding level by repeatedly pull entropy from available entropy sources\n");
 
 		lrng_fill_seed_buffer(&seedbuf,
-			lrng_get_seed_entropy_osr(drng->fully_seeded), force);
+			lrng_get_seed_entropy_osr(drng->fully_seeded),
+				      forced && !drng->fully_seeded);
 
 		collected_entropy += lrng_entropy_rate_eb(&seedbuf);
 
@@ -293,9 +303,8 @@ static u32 lrng_drng_seed_es_nolock(struct lrng_drng *drng)
 	 * the entire operation is atomic which means that the DRNG is not
 	 * producing data while this is ongoing.
 	 */
-	} while (force &&
-		 num_es_delivered >= (lrng_ntg1_2022_compliant() ? 2 : 1) &&
-		 !drng->fully_seeded);
+	} while (force_seeding && forced && !drng->fully_seeded &&
+		 num_es_delivered >= (lrng_ntg1_2022_compliant() ? 2 : 1));
 
 	memzero_explicit(&seedbuf, sizeof(seedbuf));
 
@@ -331,7 +340,7 @@ static void lrng_drng_seed(struct lrng_drng *drng)
 	}
 }
 
-static void _lrng_drng_seed_work(struct lrng_drng *drng, u32 node)
+static void lrng_drng_seed_work_one(struct lrng_drng *drng, u32 node)
 {
 	pr_debug("reseed triggered by system events for DRNG on NUMA node %d\n",
 		 node);
@@ -345,7 +354,7 @@ static void _lrng_drng_seed_work(struct lrng_drng *drng, u32 node)
 /*
  * DRNG reseed trigger: Kernel thread handler triggered by the schedule_work()
  */
-void lrng_drng_seed_work(struct work_struct *dummy)
+static void __lrng_drng_seed_work(bool force)
 {
 	struct lrng_drng **lrng_drng = lrng_drng_instances();
 	u32 node;
@@ -355,25 +364,32 @@ void lrng_drng_seed_work(struct work_struct *dummy)
 			struct lrng_drng *drng = lrng_drng[node];
 
 			if (drng && !drng->fully_seeded) {
-				_lrng_drng_seed_work(drng, node);
-				goto out;
+				drng->force_reseed |= force;
+				lrng_drng_seed_work_one(drng, node);
+				return;
 			}
 		}
 	} else {
 		if (!lrng_drng_init.fully_seeded) {
-			_lrng_drng_seed_work(&lrng_drng_init, 0);
-			goto out;
+			lrng_drng_init.force_reseed |= force;
+			lrng_drng_seed_work_one(&lrng_drng_init, 0);
+			return;
 		}
 	}
 
 	if (!lrng_drng_pr.fully_seeded) {
-		_lrng_drng_seed_work(&lrng_drng_pr, 0);
-		goto out;
+		lrng_drng_pr.force_reseed |= force;
+		lrng_drng_seed_work_one(&lrng_drng_pr, 0);
+		return;
 	}
 
 	lrng_pool_all_numa_nodes_seeded(true);
+}
+
+void lrng_drng_seed_work(struct work_struct *dummy)
+{
+	__lrng_drng_seed_work(false);
 
-out:
 	/* Allow the seeding operation to be called again */
 	lrng_pool_unlock();
 }
@@ -577,9 +593,25 @@ void lrng_reset(void)
 
 /******************* Generic LRNG kernel output interfaces ********************/
 
+static void lrng_force_fully_seeded(void)
+{
+	static unsigned int ctr = 0;
+
+	if (lrng_pool_all_numa_nodes_seeded_get())
+		return;
+
+	if (ctr++ < LRNG_FORCE_FULLY_SEEDED_ATTEMPT)
+		return;
+
+	lrng_pool_lock();
+	__lrng_drng_seed_work(true);
+	lrng_pool_unlock();
+	ctr = 0;
+}
+
 static int lrng_drng_sleep_while_not_all_nodes_seeded(unsigned int nonblock)
 {
-	lrng_es_add_entropy();
+	lrng_force_fully_seeded();
 	if (lrng_pool_all_numa_nodes_seeded_get())
 		return 0;
 	if (nonblock)
@@ -591,7 +623,7 @@ static int lrng_drng_sleep_while_not_all_nodes_seeded(unsigned int nonblock)
 
 int lrng_drng_sleep_while_nonoperational(int nonblock)
 {
-	lrng_es_add_entropy();
+	lrng_force_fully_seeded();
 	if (likely(lrng_state_operational()))
 		return 0;
 	if (nonblock)
@@ -602,7 +634,7 @@ int lrng_drng_sleep_while_nonoperational(int nonblock)
 
 int lrng_drng_sleep_while_non_min_seeded(void)
 {
-	lrng_es_add_entropy();
+	lrng_force_fully_seeded();
 	if (likely(lrng_state_min_seeded()))
 		return 0;
 	return wait_event_interruptible(lrng_init_wait,
diff --git a/drivers/char/lrng/lrng_es_mgr.c b/drivers/char/lrng/lrng_es_mgr.c
index 0c3797e34..5625d5734 100644
--- a/drivers/char/lrng/lrng_es_mgr.c
+++ b/drivers/char/lrng/lrng_es_mgr.c
@@ -28,8 +28,8 @@ struct lrng_state {
 	bool perform_seedwork;		/* Can seed work be performed? */
 	bool lrng_operational;		/* Is DRNG operational? */
 	bool lrng_fully_seeded;		/* Is DRNG fully seeded? */
+	bool lrng_min_seeded;		/* Is DRNG minimally seeded? */
 	bool all_online_numa_node_seeded;/* All NUMA DRNGs seeded? */
-	unsigned char lrng_min_seeded;	/* Is DRNG minimally seeded? */
 
 	/*
 	 * To ensure that external entropy providers cannot dominate the
@@ -154,7 +154,7 @@ void lrng_reset_state(void)
 	}
 	lrng_state.lrng_operational = false;
 	lrng_state.lrng_fully_seeded = false;
-	lrng_state.lrng_min_seeded = 0;
+	lrng_state.lrng_min_seeded = false;
 	lrng_state.all_online_numa_node_seeded = false;
 	pr_debug("reset LRNG\n");
 }
@@ -165,12 +165,6 @@ void lrng_pool_all_numa_nodes_seeded(bool set)
 	lrng_state.all_online_numa_node_seeded = set;
 	if (set)
 		wake_up_all(&lrng_init_wait);
-	/*
-	 * Once all DRNGs are fully seeded, the forced seeding is not needed
-	 * any more. Thus, set the min_seeded level below the
-	 * LRNG_FORCE_FULLY_SEEDED_ATTEMPT threshold.
-	 */
-	lrng_state.lrng_min_seeded = 1;
 }
 
 bool lrng_pool_all_numa_nodes_seeded_get(void)
@@ -179,7 +173,7 @@ bool lrng_pool_all_numa_nodes_seeded_get(void)
 }
 
 /* Return boolean whether LRNG reached minimally seed level */
-unsigned int lrng_state_min_seeded(void)
+bool lrng_state_min_seeded(void)
 {
 	return lrng_state.lrng_min_seeded;
 }
@@ -340,8 +334,6 @@ void lrng_init_ops(struct entropy_buf *eb)
 	if (state->lrng_fully_seeded) {
 		lrng_set_operational();
 		lrng_set_entropy_thresh(requested_bits);
-
-		state->lrng_min_seeded = 1;
 	} else if (lrng_fully_seeded(state->all_online_numa_node_seeded,
 				     seed_bits, eb)) {
 		if (state->can_invalidate)
@@ -349,13 +341,7 @@ void lrng_init_ops(struct entropy_buf *eb)
 
 		state->lrng_fully_seeded = true;
 		lrng_set_operational();
-
-		/*
-		 * Reset min-seeded trigger to allow it being counted up for
-		 * the next DRNG. This gives other entropy sources time to
-		 * collect entropy to seed the DRNG as well.
-		 */
-		state->lrng_min_seeded = 1;
+		state->lrng_min_seeded = true;
 		pr_info("LRNG fully seeded with %u bits of entropy\n",
 			seed_bits);
 		lrng_set_entropy_thresh(requested_bits);
@@ -366,7 +352,7 @@ void lrng_init_ops(struct entropy_buf *eb)
 			if (state->can_invalidate)
 				invalidate_batched_entropy();
 
-			state->lrng_min_seeded++;
+			state->lrng_min_seeded = true;
 			pr_info("LRNG minimally seeded with %u bits of entropy\n",
 				seed_bits);
 			lrng_set_entropy_thresh(requested_bits);
@@ -441,9 +427,6 @@ early_initcall(lrng_rand_initialize);
 /* Interface requesting a reseed of the DRNG */
 void lrng_es_add_entropy(void)
 {
-	struct lrng_state *state = &lrng_state;
-	u32 avail_entropy;
-
 	/*
 	 * Once all DRNGs are fully seeded, the system-triggered arrival of
 	 * entropy will not cause any reseeding any more.
@@ -451,17 +434,9 @@ void lrng_es_add_entropy(void)
 	if (likely(lrng_state.all_online_numa_node_seeded))
 		return;
 
-	/*
-	 * Only trigger the DRNG reseed if we have collected entropy. If
-	 * we have several min-seeded entropy requests without reaching fully
-	 * seeded, we force the seeding with the available entropy.
-	 */
-	state->lrng_min_seeded++;
-	avail_entropy = lrng_avail_entropy();
-	if ((state->lrng_min_seeded < 5 &&
-	    (avail_entropy <
-	     atomic_read_u32(&lrng_state.boot_entropy_thresh))) ||
-	    avail_entropy == 0)
+	/* Only trigger the DRNG reseed if we have collected entropy. */
+	if (lrng_avail_entropy() <
+	    atomic_read_u32(&lrng_state.boot_entropy_thresh))
 		return;
 
 	/* Ensure that the seeding only occurs once at any given time. */
diff --git a/drivers/char/lrng/lrng_es_mgr.h b/drivers/char/lrng/lrng_es_mgr.h
index 6304728d8..9d4a5599f 100644
--- a/drivers/char/lrng/lrng_es_mgr.h
+++ b/drivers/char/lrng/lrng_es_mgr.h
@@ -25,7 +25,7 @@ extern struct lrng_es_cb *lrng_es[];
 
 bool lrng_ntg1_2022_compliant(void);
 bool lrng_pool_all_numa_nodes_seeded_get(void);
-unsigned int lrng_state_min_seeded(void);
+bool lrng_state_min_seeded(void);
 void lrng_debug_report_seedlevel(const char *name);
 int lrng_rand_initialize(void);
 bool lrng_state_operational(void);
-- 
2.38.0.rc1.6.g4fd6c5e444

