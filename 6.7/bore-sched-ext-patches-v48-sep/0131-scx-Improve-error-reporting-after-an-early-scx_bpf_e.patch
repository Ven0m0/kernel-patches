From 177fb81c51e88ecdcf119ff3046d809af11eda15 Mon Sep 17 00:00:00 2001
From: Tejun Heo <tj@kernel.org>
Date: Tue, 27 Feb 2024 15:28:31 -1000
Subject: [PATCH 131/132] scx: Improve error reporting after an early
 scx_bpf_error()

If scx_bpf_error() is triggered while a BPF scheduler is being loaded,
depending on the point of failure, it can make ops_state transition fail and
thus make loading fail with -EBUSY, which isn't very descriptive.

There was already a workaround for a specific case where ops.init() triggers
scx_bpf_error() which works by just reporting success so that the usual exit
path report the error with all the details.

There's no reason to restrict this to ops.init() failure. These early
scx_bpf_error()s always make the ops_state transitions fail and we can
always finish loading with success and let the exit path report the faliure.
---
 kernel/sched/ext.c | 23 ++++++++++-------------
 1 file changed, 10 insertions(+), 13 deletions(-)

diff --git a/kernel/sched/ext.c b/kernel/sched/ext.c
index b74d1a0bc..0282c5288 100644
--- a/kernel/sched/ext.c
+++ b/kernel/sched/ext.c
@@ -3684,17 +3684,6 @@ static int scx_ops_enable(struct sched_ext_ops *ops)
 			ret = ops_sanitize_err("init", ret);
 			goto err_disable_unlock_cpus;
 		}
-
-		/*
-		 * Exit early if ops.init() triggered scx_bpf_error(). Not
-		 * strictly necessary as we'll fail transitioning into ENABLING
-		 * later but that'd be after calling ops.init_task() on all
-		 * tasks and with -EBUSY which isn't very intuitive. Let's exit
-		 * early with success so that the condition is notified through
-		 * ops.exit() like other scx_bpf_error() invocations.
-		 */
-		if (atomic_read(&scx_exit_kind) != SCX_EXIT_NONE)
-			goto err_disable_unlock_cpus;
 	}
 
 	for (i = SCX_OPI_CPU_HOTPLUG_BEGIN; i < SCX_OPI_CPU_HOTPLUG_END; i++)
@@ -3818,11 +3807,17 @@ static int scx_ops_enable(struct sched_ext_ops *ops)
 	/*
 	 * From here on, the disable path must assume that tasks have ops
 	 * enabled and need to be recovered.
+	 *
+	 * Transition to ENABLING fails iff the BPF scheduler has already
+	 * triggered scx_bpf_error(). Returning an error code here would lose
+	 * the recorded error information. Exit indicating success so that the
+	 * error is notified through ops.exit() with all the details.
 	 */
 	if (!scx_ops_tryset_enable_state(SCX_OPS_ENABLING, SCX_OPS_PREPPING)) {
 		preempt_enable();
 		spin_unlock_irq(&scx_tasks_lock);
-		ret = -EBUSY;
+		WARN_ON_ONCE(atomic_read(&scx_exit_kind) == SCX_EXIT_NONE);
+		ret = 0;
 		goto err_disable_unlock_all;
 	}
 
@@ -3856,8 +3851,10 @@ static int scx_ops_enable(struct sched_ext_ops *ops)
 	cpus_read_unlock();
 	percpu_up_write(&scx_fork_rwsem);
 
+	/* see above ENABLING transition for the explanation on exiting with 0 */
 	if (!scx_ops_tryset_enable_state(SCX_OPS_ENABLED, SCX_OPS_ENABLING)) {
-		ret = -EBUSY;
+		WARN_ON_ONCE(atomic_read(&scx_exit_kind) == SCX_EXIT_NONE);
+		ret = 0;
 		goto err_disable;
 	}
 
-- 
2.43.0.232.ge79552d197

