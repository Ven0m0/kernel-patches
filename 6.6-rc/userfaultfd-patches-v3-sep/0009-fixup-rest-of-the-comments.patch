From 084b4809761ea96b3a38efa37d080aee8d8785d4 Mon Sep 17 00:00:00 2001
From: Suren Baghdasaryan <surenb@google.com>
Date: Thu, 21 Sep 2023 22:02:21 +0000
Subject: [PATCH 09/10] fixup: rest of the comments

Signed-off-by: Suren Baghdasaryan <surenb@google.com>
---
 include/linux/userfaultfd_k.h | 25 ++++++++-----------
 mm/huge_memory.c              | 47 ++++++++++++++++-------------------
 mm/userfaultfd.c              | 25 +++----------------
 3 files changed, 36 insertions(+), 61 deletions(-)

diff --git a/include/linux/userfaultfd_k.h b/include/linux/userfaultfd_k.h
index 2bc807dc3..9ea2c43ad 100644
--- a/include/linux/userfaultfd_k.h
+++ b/include/linux/userfaultfd_k.h
@@ -94,21 +94,16 @@ extern long uffd_wp_range(struct vm_area_struct *vma,
 			  unsigned long start, unsigned long len, bool enable_wp);
 
 /* remap_pages */
-extern void double_pt_lock(spinlock_t *ptl1, spinlock_t *ptl2);
-extern void double_pt_unlock(spinlock_t *ptl1, spinlock_t *ptl2);
-extern ssize_t remap_pages(struct mm_struct *dst_mm,
-			   struct mm_struct *src_mm,
-			   unsigned long dst_start,
-			   unsigned long src_start,
-			   unsigned long len, __u64 flags);
-extern int remap_pages_huge_pmd(struct mm_struct *dst_mm,
-				struct mm_struct *src_mm,
-				pmd_t *dst_pmd, pmd_t *src_pmd,
-				pmd_t dst_pmdval,
-				struct vm_area_struct *dst_vma,
-				struct vm_area_struct *src_vma,
-				unsigned long dst_addr,
-				unsigned long src_addr);
+void double_pt_lock(spinlock_t *ptl1, spinlock_t *ptl2);
+void double_pt_unlock(spinlock_t *ptl1, spinlock_t *ptl2);
+ssize_t remap_pages(struct mm_struct *dst_mm, struct mm_struct *src_mm,
+		    unsigned long dst_start, unsigned long src_start,
+		    unsigned long len, __u64 flags);
+int remap_pages_huge_pmd(struct mm_struct *dst_mm, struct mm_struct *src_mm,
+			 pmd_t *dst_pmd, pmd_t *src_pmd, pmd_t dst_pmdval,
+			 struct vm_area_struct *dst_vma,
+			 struct vm_area_struct *src_vma,
+			 unsigned long dst_addr, unsigned long src_addr);
 
 /* mm helpers */
 static inline bool is_mergeable_vm_userfaultfd_ctx(struct vm_area_struct *vma,
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index 4f3650e73..48ed14dfb 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -1942,17 +1942,15 @@ int change_huge_pmd(struct mmu_gather *tlb, struct vm_area_struct *vma,
  * moving the page, -EAGAIN if it needs to be repeated by the caller,
  * or other errors in case of failure.
  */
-int remap_pages_huge_pmd(struct mm_struct *dst_mm,
-			 struct mm_struct *src_mm,
-			 pmd_t *dst_pmd, pmd_t *src_pmd,
-			 pmd_t dst_pmdval,
+int remap_pages_huge_pmd(struct mm_struct *dst_mm, struct mm_struct *src_mm,
+			 pmd_t *dst_pmd, pmd_t *src_pmd, pmd_t dst_pmdval,
 			 struct vm_area_struct *dst_vma,
 			 struct vm_area_struct *src_vma,
-			 unsigned long dst_addr,
-			 unsigned long src_addr)
+			 unsigned long dst_addr, unsigned long src_addr)
 {
 	pmd_t _dst_pmd, src_pmdval;
 	struct page *src_page;
+	struct folio *src_folio;
 	struct anon_vma *src_anon_vma, *dst_anon_vma;
 	spinlock_t *src_ptl, *dst_ptl;
 	pgtable_t src_pgtable, dst_pgtable = NULL;
@@ -1970,20 +1968,19 @@ int remap_pages_huge_pmd(struct mm_struct *dst_mm,
 	BUG_ON(dst_addr & ~HPAGE_PMD_MASK);
 
 	src_page = pmd_page(src_pmdval);
-	BUG_ON(!PageHead(src_page));
-	BUG_ON(!PageAnon(src_page));
-	if (unlikely(page_mapcount(src_page) != 1)) {
+	if (unlikely(!PageAnonExclusive(src_page))) {
 		spin_unlock(src_ptl);
 		return -EBUSY;
 	}
+	src_folio = page_folio(src_page);
 
-	get_page(src_page);
+	folio_get(src_folio);
 	spin_unlock(src_ptl);
 
 	if (dst_mm != src_mm) {
 		dst_pgtable = pte_alloc_one(dst_mm);
 		if (unlikely(!dst_pgtable)) {
-			put_page(src_page);
+			folio_put(src_folio);
 			return -ENOMEM;
 		}
 	}
@@ -1993,17 +1990,17 @@ int remap_pages_huge_pmd(struct mm_struct *dst_mm,
 	mmu_notifier_invalidate_range_start(&range);
 
 	/* block all concurrent rmap walks */
-	lock_page(src_page);
+	folio_lock(src_folio);
 
 	/*
 	 * split_huge_page walks the anon_vma chain without the page
 	 * lock. Serialize against it with the anon_vma lock, the page
 	 * lock is not enough.
 	 */
-	src_anon_vma = folio_get_anon_vma(page_folio(src_page));
+	src_anon_vma = folio_get_anon_vma(src_folio);
 	if (!src_anon_vma) {
-		unlock_page(src_page);
-		put_page(src_page);
+		folio_unlock(src_folio);
+		folio_put(src_folio);
 		mmu_notifier_invalidate_range_end(&range);
 		if (dst_pgtable)
 			pte_free(dst_mm, dst_pgtable);
@@ -2015,29 +2012,29 @@ int remap_pages_huge_pmd(struct mm_struct *dst_mm,
 	double_pt_lock(src_ptl, dst_ptl);
 	if (unlikely(!pmd_same(*src_pmd, src_pmdval) ||
 		     !pmd_same(*dst_pmd, dst_pmdval) ||
-		     page_mapcount(src_page) != 1)) {
+		     folio_mapcount(src_folio) != 1)) {
 		double_pt_unlock(src_ptl, dst_ptl);
 		anon_vma_unlock_write(src_anon_vma);
 		put_anon_vma(src_anon_vma);
-		unlock_page(src_page);
-		put_page(src_page);
+		folio_unlock(src_folio);
+		folio_put(src_folio);
 		mmu_notifier_invalidate_range_end(&range);
 		if (dst_pgtable)
 			pte_free(dst_mm, dst_pgtable);
 		return -EAGAIN;
 	}
 
-	BUG_ON(!PageHead(src_page));
-	BUG_ON(!PageAnon(src_page));
+	BUG_ON(!folio_test_head(src_folio));
+	BUG_ON(!folio_test_anon(src_folio));
 	/* the PT lock is enough to keep the page pinned now */
-	put_page(src_page);
+	folio_put(src_folio);
 
 	dst_anon_vma = (void *) dst_vma->anon_vma + PAGE_MAPPING_ANON;
-	WRITE_ONCE(src_page->mapping, (struct address_space *) dst_anon_vma);
-	WRITE_ONCE(src_page->index, linear_page_index(dst_vma, dst_addr));
+	WRITE_ONCE(src_folio->mapping, (struct address_space *) dst_anon_vma);
+	WRITE_ONCE(src_folio->index, linear_page_index(dst_vma, dst_addr));
 
 	src_pmdval = pmdp_huge_clear_flush(src_vma, src_addr, src_pmd);
-	_dst_pmd = mk_huge_pmd(src_page, dst_vma->vm_page_prot);
+	_dst_pmd = mk_huge_pmd(src_folio->page, dst_vma->vm_page_prot);
 	_dst_pmd = maybe_pmd_mkwrite(pmd_mkdirty(_dst_pmd), dst_vma);
 	set_pmd_at(dst_mm, dst_addr, dst_pmd, _dst_pmd);
 
@@ -2059,7 +2056,7 @@ int remap_pages_huge_pmd(struct mm_struct *dst_mm,
 	put_anon_vma(src_anon_vma);
 
 	/* unblock rmap walks */
-	unlock_page(src_page);
+	folio_unlock(src_folio);
 
 	mmu_notifier_invalidate_range_end(&range);
 	return 0;
diff --git a/mm/userfaultfd.c b/mm/userfaultfd.c
index 7b0353fe3..3e1158716 100644
--- a/mm/userfaultfd.c
+++ b/mm/userfaultfd.c
@@ -970,6 +970,7 @@ static int remap_pages_pte(struct mm_struct *dst_mm,
 
 			folio = vm_normal_folio(src_vma, src_addr, orig_src_pte);
 			if (!folio || !folio_test_anon(folio) ||
+			    folio_test_large(folio) ||
 			    folio_estimated_sharers(folio) != 1) {
 				spin_unlock(src_ptl);
 				err = -EBUSY;
@@ -1015,6 +1016,7 @@ static int remap_pages_pte(struct mm_struct *dst_mm,
 
 		if (!pte_same(*src_pte, orig_src_pte) ||
 		    !pte_same(*dst_pte, orig_dst_pte) ||
+		    folio_test_large(src_folio) ||
 		    folio_estimated_sharers(src_folio) != 1) {
 			double_pt_unlock(dst_ptl, src_ptl);
 			err = -EAGAIN;
@@ -1031,10 +1033,7 @@ static int remap_pages_pte(struct mm_struct *dst_mm,
 		WRITE_ONCE(src_folio->index, linear_page_index(dst_vma,
 							      dst_addr));
 
-		if (!pte_same(ptep_clear_flush(src_vma, src_addr, src_pte),
-			      orig_src_pte))
-			BUG_ON(1);
-
+		orig_src_pte = ptep_clear_flush(src_vma, src_addr, src_pte);
 		orig_dst_pte = mk_pte(&src_folio->page, dst_vma->vm_page_prot);
 		orig_dst_pte = maybe_mkwrite(pte_mkdirty(orig_dst_pte),
 					     dst_vma);
@@ -1057,9 +1056,6 @@ static int remap_pages_pte(struct mm_struct *dst_mm,
 		src_folio = NULL;
 
 	} else {
-		struct swap_info_struct *si;
-		int swap_count;
-
 		entry = pte_to_swp_entry(orig_src_pte);
 		if (non_swap_entry(entry)) {
 			if (is_migration_entry(entry)) {
@@ -1074,20 +1070,7 @@ static int remap_pages_pte(struct mm_struct *dst_mm,
 			goto out;
 		}
 
-		/*
-		 * COUNT_CONTINUE to be returned is fine here, no need
-		 * of follow all swap continuation to check against
-		 * number 1.
-		 */
-		si = get_swap_device(entry);
-		if (!si) {
-			err = -EBUSY;
-			goto out;
-		}
-
-		swap_count = swap_swapcount(si, entry);
-		put_swap_device(si);
-		if (swap_count != 1) {
+		if (!pte_swp_exclusive(orig_src_pte)) {
 			err = -EBUSY;
 			goto out;
 		}
-- 
2.42.0

